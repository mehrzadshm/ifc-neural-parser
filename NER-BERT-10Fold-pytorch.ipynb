{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a7db75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# print(sys.executable)\n",
    "\n",
    "# data_path= Path(\"/home/mehrzad/repos/beslog/1stpaper-ifcner/data\")\n",
    "# display(os.listdir(data_path ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0654aa4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>highlight</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all</td>\n",
       "      <td>B_quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slab</td>\n",
       "      <td>B_built_obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>highlight all slab</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pick</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23631</th>\n",
       "      <td>modeled</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23632</th>\n",
       "      <td>within</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23633</th>\n",
       "      <td>room</td>\n",
       "      <td>B_loc_space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23634</th>\n",
       "      <td>100</td>\n",
       "      <td>B_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23635</th>\n",
       "      <td>contained in level six , print the total quant...</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23636 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   token          tag\n",
       "0                                              highlight            O\n",
       "1                                                    all   B_quantity\n",
       "2                                                   slab  B_built_obj\n",
       "3                                     highlight all slab     sentence\n",
       "4                                                   pick            O\n",
       "...                                                  ...          ...\n",
       "23631                                            modeled            O\n",
       "23632                                             within            O\n",
       "23633                                               room  B_loc_space\n",
       "23634                                                100       B_name\n",
       "23635  contained in level six , print the total quant...     sentence\n",
       "\n",
       "[23636 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(data_path / 'ifcner-paper-data-revised.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce456b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 2380 tagged data_sentences found ###\n",
      "\n",
      "highlight all slab \n",
      " ['O', 'B_quantity', 'B_built_obj'] \n",
      "\n",
      "pick each plates items \n",
      " ['O', 'B_quantity', 'B_built_obj', 'O'] \n",
      "\n",
      "find 61 railings \n",
      " ['O', 'B_quantity', 'B_built_obj'] \n",
      "\n",
      "show me 100 doorway objects \n",
      " ['O', 'O', 'B_quantity', 'B_built_obj', 'O'] \n",
      "\n",
      "for 61 staircases \n",
      " ['O', 'B_quantity', 'B_built_obj'] \n",
      "\n",
      "for 8 footings objects \n",
      " ['O', 'B_quantity', 'B_built_obj', 'O'] \n",
      "\n",
      "find me column \n",
      " ['O', 'O', 'B_built_obj'] \n",
      "\n",
      "choose staircases objects \n",
      " ['O', 'B_built_obj', 'O'] \n",
      "\n",
      "show two beam \n",
      " ['O', 'B_quantity', 'B_built_obj'] \n",
      "\n",
      "find 5 beams instances \n",
      " ['O', 'B_quantity', 'B_built_obj', 'O'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence_idx=df[df['tag'] == 'sentence' ].index\n",
    "data_sentences=[df['token'][idx] for idx in sentence_idx]\n",
    "\n",
    "data_tags=[]\n",
    "for i in range(len(sentence_idx)):\n",
    "    if i==0:\n",
    "        data_tags.append(df['tag'][0:sentence_idx[i]].to_list())\n",
    "    else:\n",
    "        data_tags.append(df['tag'][sentence_idx[i-1]+1 :sentence_idx[i]].to_list())\n",
    "\n",
    "        \n",
    "        \n",
    "if len(data_sentences)==len(data_tags):\n",
    "    print('### %d tagged data_sentences found ###\\n' % (len(data_tags)))\n",
    "\n",
    "\n",
    "for s,t in zip(data_sentences[:10], data_tags[:10]) :\n",
    "    print(s,'\\n', t, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf8e4f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>highlight all slab</td>\n",
       "      <td>O,B_quantity,B_built_obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pick each plates items</td>\n",
       "      <td>O,B_quantity,B_built_obj,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>find 61 railings</td>\n",
       "      <td>O,B_quantity,B_built_obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>show me 100 doorway objects</td>\n",
       "      <td>O,O,B_quantity,B_built_obj,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for 61 staircases</td>\n",
       "      <td>O,B_quantity,B_built_obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>contained inside level four give me the number...</td>\n",
       "      <td>O,O,B_loc_level,B_number,O,O,O,O,O,B_mep_obj,I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>contained inside floor ten what is the number ...</td>\n",
       "      <td>O,O,B_loc_level,B_number,O,O,O,O,O,O,O,B_mep_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>contained in level 1 , give me the total numbe...</td>\n",
       "      <td>O,O,B_loc_level,B_number,O,O,O,O,O,O,O,O,O,B_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>at story 8 find me the quantity of stack termi...</td>\n",
       "      <td>O,B_loc_level,B_number,O,O,O,O,O,B_mep_obj,I_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>contained in level six , print the total quant...</td>\n",
       "      <td>O,O,B_loc_level,B_number,O,O,O,O,O,O,B_mep_obj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0                                    highlight all slab   \n",
       "1                                pick each plates items   \n",
       "2                                      find 61 railings   \n",
       "3                           show me 100 doorway objects   \n",
       "4                                     for 61 staircases   \n",
       "...                                                 ...   \n",
       "2375  contained inside level four give me the number...   \n",
       "2376  contained inside floor ten what is the number ...   \n",
       "2377  contained in level 1 , give me the total numbe...   \n",
       "2378  at story 8 find me the quantity of stack termi...   \n",
       "2379  contained in level six , print the total quant...   \n",
       "\n",
       "                                            word_labels  \n",
       "0                              O,B_quantity,B_built_obj  \n",
       "1                            O,B_quantity,B_built_obj,O  \n",
       "2                              O,B_quantity,B_built_obj  \n",
       "3                          O,O,B_quantity,B_built_obj,O  \n",
       "4                              O,B_quantity,B_built_obj  \n",
       "...                                                 ...  \n",
       "2375  O,O,B_loc_level,B_number,O,O,O,O,O,B_mep_obj,I...  \n",
       "2376  O,O,B_loc_level,B_number,O,O,O,O,O,O,O,B_mep_o...  \n",
       "2377  O,O,B_loc_level,B_number,O,O,O,O,O,O,O,O,O,B_m...  \n",
       "2378  O,B_loc_level,B_number,O,O,O,O,O,B_mep_obj,I_m...  \n",
       "2379  O,O,B_loc_level,B_number,O,O,O,O,O,O,B_mep_obj...  \n",
       "\n",
       "[2380 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'sentence': data_sentences, 'tags':data_tags})\n",
    "\n",
    "data['word_labels'] = data['tags'].transform(lambda x: ','.join(x))\n",
    "data = data.drop(columns=['tags'])\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3980f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B_quantity': 1,\n",
       " 'B_built_obj': 2,\n",
       " 'I_built_obj': 3,\n",
       " 'B_mep_obj': 4,\n",
       " 'I_mep_obj': 5,\n",
       " 'B_ordinal': 6,\n",
       " 'B_loc_level': 7,\n",
       " 'I_ordinal': 8,\n",
       " 'B_number': 9,\n",
       " 'B_loc_space': 10,\n",
       " 'I_loc_space': 11,\n",
       " 'B_name': 12}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_labels=[tag for tag in list(df['tag'].unique()) if type(tag)==str and tag!='sentence']\n",
    "id2label={idx:tag for idx,tag in enumerate(tags_labels)}\n",
    "label2id={tag:idx for idx,tag in enumerate(tags_labels)}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1267b93c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 2 coverings items\n",
      "O,B_quantity,B_built_obj,O\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[41].sentence)\n",
    "print(data.iloc[41].word_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a8f27",
   "metadata": {},
   "source": [
    "# Model utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6cecc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 15:23:25.086745: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 15:23:25.175325: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-06 15:23:25.552331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-06 15:23:25.552410: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-06 15:23:25.552415: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
    "from transformers import AutoTokenizer, DistilBertModel, DistilBertForTokenClassification, AutoModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from seqeval.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f2a3ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879cba16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]  \n",
    "        word_labels = self.data.word_labels[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "#         labels.insert(len(labels),\"O\") # add outside label for [SEP] token\n",
    "        labels.append(\"O\") # add outside label for [SEP] token\n",
    "\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "            \n",
    "            # truncate\n",
    "            tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "            labels = labels[:maxlen]\n",
    "        else:\n",
    "            # pad\n",
    "            tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "            labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        \n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21949549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train & Valid functions for token classification \n",
    "\n",
    "\n",
    "def train(epoch, training_loader):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss: {train_loss}\")\n",
    "    print(f\"Training accuracy: {tr_accuracy}\")\n",
    "    \n",
    "    return train_loss \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions, eval_loss \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bd500",
   "metadata": {},
   "source": [
    "# \n",
    "# Tune BERT \n",
    "### (checkpoint: bert-base-uncased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504fc0d",
   "metadata": {},
   "source": [
    "# \n",
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "294a69ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare train_data, val_data, and test_data to train/validate/test BERT base model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "n_splits = 10  \n",
    "seeds = [0, 42, 123]\n",
    "\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    print(\"\\n\"*3+\"#\"*30,f\"\\t  Running KFold with seed {seed}\\t\", \"#\"*30+\"\\n\")\n",
    "    \n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for i, (not_test_idx, test_idx) in enumerate(kf.split(data)):\n",
    "        test_data = data.iloc[test_idx]\n",
    "#         print(len(test_idx))\n",
    "        \n",
    "        # Remaining data can be used for training and validation\n",
    "        not_test_data = data.iloc[not_test_idx]\n",
    "        \n",
    "        # Manually split the remaining data into training and validation sets\n",
    "        val_size = len(test_data)\n",
    "        val_data = not_test_data.iloc[:val_size]\n",
    "        train_data = not_test_data.iloc[val_size:]\n",
    "        \n",
    "        print(\"\\n\"+\"*\"*10, f'\\tCROSS-VAL iteration with fold {i+1}\\t', \"*\"*10)\n",
    "        print(\"Train size:\", len(train_data))\n",
    "        print(\"Validation size:\", len(val_data))\n",
    "        print(\"Test size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7d8f7d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "############################## \t  Running KFold with seed 0\t ##############################\n",
      "\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 1/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.6291918754577637\n",
      "Training loss per 100 training steps: 0.9296663006638536\n",
      "Training loss per 100 training steps: 0.7727601694971767\n",
      "Training loss: 0.6924620354000259\n",
      "Training accuracy: 0.8100276369498324\n",
      "Validation loss per 100 evaluation steps: 0.11872684955596924\n",
      "Validation Loss: 0.13942825868725778\n",
      "Validation Accuracy: 0.9735600892563688\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6925\n",
      "\t - Validation loss: 0.1394\n",
      "Validation loss decreased (inf --> 0.139428).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.15880201756954193\n",
      "Training loss per 100 training steps: 0.09269946767478296\n",
      "Training loss per 100 training steps: 0.0951721203601479\n",
      "Training loss: 0.08715763395386082\n",
      "Training accuracy: 0.9820838870676559\n",
      "Validation loss per 100 evaluation steps: 0.015149544924497604\n",
      "Validation Loss: 0.01866477127186954\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0872\n",
      "\t - Validation loss: 0.0187\n",
      "Validation loss decreased (0.139428 --> 0.018665).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.014494798146188259\n",
      "Training loss per 100 training steps: 0.020466801258597043\n",
      "Training loss per 100 training steps: 0.02893047355838231\n",
      "Training loss: 0.027349718678116548\n",
      "Training accuracy: 0.9959595049061847\n",
      "Validation loss per 100 evaluation steps: 0.004589218646287918\n",
      "Validation Loss: 0.006128903036005795\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0273\n",
      "\t - Validation loss: 0.0061\n",
      "Validation loss decreased (0.018665 --> 0.006129).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.008115451782941818\n",
      "Training loss per 100 training steps: 0.008542514931742507\n",
      "Training loss per 100 training steps: 0.016033585192589322\n",
      "Training loss: 0.01500171549547808\n",
      "Training accuracy: 0.9984286992054521\n",
      "Validation loss per 100 evaluation steps: 0.0026729004457592964\n",
      "Validation Loss: 0.004714087765508642\n",
      "Validation Accuracy: 0.9994949494949494\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0150\n",
      "\t - Validation loss: 0.0047\n",
      "Validation loss decreased (0.006129 --> 0.004714).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006529001984745264\n",
      "Training loss per 100 training steps: 0.006008735046454585\n",
      "Training loss per 100 training steps: 0.012376176187564708\n",
      "Training loss: 0.011472999357947093\n",
      "Training accuracy: 0.9987082179785417\n",
      "Validation loss per 100 evaluation steps: 0.0018089697696268559\n",
      "Validation Loss: 0.003001841815421358\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0115\n",
      "\t - Validation loss: 0.0030\n",
      "Validation loss decreased (0.004714 --> 0.003002).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.00399886816740036\n",
      "Training loss per 100 training steps: 0.004257401749998848\n",
      "Training loss per 100 training steps: 0.008928268641668988\n",
      "Training loss: 0.008326027285065032\n",
      "Training accuracy: 0.9989234773930304\n",
      "Validation loss per 100 evaluation steps: 0.001490316935814917\n",
      "Validation Loss: 0.002357938870166739\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0083\n",
      "\t - Validation loss: 0.0024\n",
      "Validation loss decreased (0.003002 --> 0.002358).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0031695952638983727\n",
      "Training loss per 100 training steps: 0.0035471109797864564\n",
      "Training loss per 100 training steps: 0.008044615909758381\n",
      "Training loss: 0.007392290129009322\n",
      "Training accuracy: 0.9988851782064748\n",
      "Validation loss per 100 evaluation steps: 0.0011839399812743068\n",
      "Validation Loss: 0.0018292284318401169\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0074\n",
      "\t - Validation loss: 0.0018\n",
      "Validation loss decreased (0.002358 --> 0.001829).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0032292280811816454\n",
      "Training loss per 100 training steps: 0.003012256808625073\n",
      "Training loss per 100 training steps: 0.005796146396644858\n",
      "Training loss: 0.005349197294347833\n",
      "Training accuracy: 0.999331996069285\n",
      "Validation loss per 100 evaluation steps: 0.0009531576652079821\n",
      "Validation Loss: 0.0015701564659442132\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 8/100\n",
      "\t - Training loss: 0.0053\n",
      "\t - Validation loss: 0.0016\n",
      "Validation loss decreased (0.001829 --> 0.001570).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.002327128080651164\n",
      "Training loss per 100 training steps: 0.004060862089119999\n",
      "Training loss per 100 training steps: 0.0051693734075799955\n",
      "Training loss: 0.004748793831975551\n",
      "Training accuracy: 0.9992979106195687\n",
      "Validation loss per 100 evaluation steps: 0.0008396135526709259\n",
      "Validation Loss: 0.0012711843873451775\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 9/100\n",
      "\t - Training loss: 0.0047\n",
      "\t - Validation loss: 0.0013\n",
      "Validation loss decreased (0.001570 --> 0.001271).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.001990174874663353\n",
      "Training loss per 100 training steps: 0.001908946503991132\n",
      "Training loss per 100 training steps: 0.0039497364502960805\n",
      "Training loss: 0.0036870327456795587\n",
      "Training accuracy: 0.9994460476491437\n",
      "Validation loss per 100 evaluation steps: 0.0007115834741853178\n",
      "Validation Loss: 0.0010510803947302823\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 10/100\n",
      "\t - Training loss: 0.0037\n",
      "\t - Validation loss: 0.0011\n",
      "Validation loss decreased (0.001271 --> 0.001051).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.002117534400895238\n",
      "Training loss per 100 training steps: 0.0018348839891253795\n",
      "Training loss per 100 training steps: 0.003466320234821155\n",
      "Training loss: 0.0033620068876311464\n",
      "Training accuracy: 0.9995767070093894\n",
      "Validation loss per 100 evaluation steps: 0.000611180264968425\n",
      "Validation Loss: 0.0008417533807611714\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 11/100\n",
      "\t - Training loss: 0.0034\n",
      "\t - Validation loss: 0.0008\n",
      "Validation loss decreased (0.001051 --> 0.000842).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.001687319832853973\n",
      "Training loss per 100 training steps: 0.0017976217590834908\n",
      "Training loss per 100 training steps: 0.003345753513369246\n",
      "Training loss: 0.003274397965141048\n",
      "Training accuracy: 0.9995614453476114\n",
      "Validation loss per 100 evaluation steps: 0.0009043410536833107\n",
      "Validation Loss: 0.0011707611032761634\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 12/100\n",
      "\t - Training loss: 0.0033\n",
      "\t - Validation loss: 0.0012\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0010298063280060887\n",
      "Validation Loss: 0.006998118681076448\n",
      "Validation Accuracy: 0.9986394557823128\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 2/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.4328322410583496\n",
      "Training loss per 100 training steps: 0.935474042550172\n",
      "Training loss per 100 training steps: 0.7855016174008004\n",
      "Training loss: 0.7117441519781822\n",
      "Training accuracy: 0.8091281535778871\n",
      "Validation loss per 100 evaluation steps: 0.1273823231458664\n",
      "Validation Loss: 0.15622821878641843\n",
      "Validation Accuracy: 0.9714191131680987\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.7117\n",
      "\t - Validation loss: 0.1562\n",
      "Validation loss decreased (0.000842 --> 0.156228).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.14316792786121368\n",
      "Training loss per 100 training steps: 0.10163324915499676\n",
      "Training loss per 100 training steps: 0.10371319001623944\n",
      "Training loss: 0.09466866154943694\n",
      "Training accuracy: 0.9808749915663416\n",
      "Validation loss per 100 evaluation steps: 0.015257145278155804\n",
      "Validation Loss: 0.020149661274626852\n",
      "Validation Accuracy: 0.9993055555555554\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0947\n",
      "\t - Validation loss: 0.0201\n",
      "Validation loss decreased (0.156228 --> 0.020150).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.020299086347222328\n",
      "Training loss per 100 training steps: 0.021506324041597913\n",
      "Training loss per 100 training steps: 0.031964293231640885\n",
      "Training loss: 0.03000626851953253\n",
      "Training accuracy: 0.9955945609712645\n",
      "Validation loss per 100 evaluation steps: 0.00568688428029418\n",
      "Validation Loss: 0.008762932359240949\n",
      "Validation Accuracy: 0.9993055555555554\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0300\n",
      "\t - Validation loss: 0.0088\n",
      "Validation loss decreased (0.020150 --> 0.008763).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009349512867629528\n",
      "Training loss per 100 training steps: 0.00975288703834804\n",
      "Training loss per 100 training steps: 0.017464200186482932\n",
      "Training loss: 0.016250640094209807\n",
      "Training accuracy: 0.9978504417785274\n",
      "Validation loss per 100 evaluation steps: 0.003138085827231407\n",
      "Validation Loss: 0.004982298158574849\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0163\n",
      "\t - Validation loss: 0.0050\n",
      "Validation loss decreased (0.008763 --> 0.004982).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006056800950318575\n",
      "Training loss per 100 training steps: 0.00629856692405768\n",
      "Training loss per 100 training steps: 0.013661832231286895\n",
      "Training loss: 0.01267211909499802\n",
      "Training accuracy: 0.9981634155296452\n",
      "Validation loss per 100 evaluation steps: 0.002267507603392005\n",
      "Validation Loss: 0.004083424651374419\n",
      "Validation Accuracy: 0.9994791666666667\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0127\n",
      "\t - Validation loss: 0.0041\n",
      "Validation loss decreased (0.004982 --> 0.004083).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005244550760835409\n",
      "Training loss per 100 training steps: 0.004682203939202988\n",
      "Training loss per 100 training steps: 0.009465422558908662\n",
      "Training loss: 0.008743203738156487\n",
      "Training accuracy: 0.9988180355379493\n",
      "Validation loss per 100 evaluation steps: 0.0016852413536980748\n",
      "Validation Loss: 0.002436167048290372\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0087\n",
      "\t - Validation loss: 0.0024\n",
      "Validation loss decreased (0.004083 --> 0.002436).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0035707459319382906\n",
      "Training loss per 100 training steps: 0.0036507088098545917\n",
      "Training loss per 100 training steps: 0.007905691456679829\n",
      "Training loss: 0.007272741610591276\n",
      "Training accuracy: 0.9988354437695294\n",
      "Validation loss per 100 evaluation steps: 0.0013118436327204108\n",
      "Validation Loss: 0.0018893689149990678\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0073\n",
      "\t - Validation loss: 0.0019\n",
      "Validation loss decreased (0.002436 --> 0.001889).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0030878582037985325\n",
      "Training loss per 100 training steps: 0.0029565785990769765\n",
      "Training loss per 100 training steps: 0.007110197337423058\n",
      "Training loss: 0.006732292541306654\n",
      "Training accuracy: 0.9990404886100978\n",
      "Validation loss per 100 evaluation steps: 0.0012404527515172958\n",
      "Validation Loss: 0.0017555025153948615\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 8/100\n",
      "\t - Training loss: 0.0067\n",
      "\t - Validation loss: 0.0018\n",
      "Validation loss decreased (0.001889 --> 0.001756).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0032650528009980917\n",
      "Training loss per 100 training steps: 0.0037754720934473052\n",
      "Training loss per 100 training steps: 0.0055840442603481795\n",
      "Training loss: 0.005333912677225508\n",
      "Training accuracy: 0.9993300676299725\n",
      "Validation loss per 100 evaluation steps: 0.0009628241532482207\n",
      "Validation Loss: 0.0018431703482444087\n",
      "Validation Accuracy: 0.9994791666666667\n",
      "*****\n",
      "Epoch 9/100\n",
      "\t - Training loss: 0.0053\n",
      "\t - Validation loss: 0.0018\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0008067921735346317\n",
      "Validation Loss: 0.0027502347084616\n",
      "Validation Accuracy: 0.9995057720057721\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 3/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.5691399574279785\n",
      "Training loss per 100 training steps: 0.8879670190191505\n",
      "Training loss per 100 training steps: 0.7427176513259683\n",
      "Training loss: 0.672055909864041\n",
      "Training accuracy: 0.8171750524767799\n",
      "Validation loss per 100 evaluation steps: 0.16219131648540497\n",
      "Validation Loss: 0.14847240236898263\n",
      "Validation Accuracy: 0.9668293095747986\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6721\n",
      "\t - Validation loss: 0.1485\n",
      "Validation loss decreased (0.001756 --> 0.148472).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.190728098154068\n",
      "Training loss per 100 training steps: 0.10893416653691541\n",
      "Training loss per 100 training steps: 0.11314264097394634\n",
      "Training loss: 0.10334337391585362\n",
      "Training accuracy: 0.9767810208118163\n",
      "Validation loss per 100 evaluation steps: 0.027359986677765846\n",
      "Validation Loss: 0.024233827576972546\n",
      "Validation Accuracy: 0.9972969672571123\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.1033\n",
      "\t - Validation loss: 0.0242\n",
      "Validation loss decreased (0.148472 --> 0.024234).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.01584829017519951\n",
      "Training loss per 100 training steps: 0.022565616225584013\n",
      "Training loss per 100 training steps: 0.03278569980010168\n",
      "Training loss: 0.03103723785519099\n",
      "Training accuracy: 0.9948721648310557\n",
      "Validation loss per 100 evaluation steps: 0.005872388835996389\n",
      "Validation Loss: 0.00791229992173612\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0310\n",
      "\t - Validation loss: 0.0079\n",
      "Validation loss decreased (0.024234 --> 0.007912).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.008230628445744514\n",
      "Training loss per 100 training steps: 0.010883738438939989\n",
      "Training loss per 100 training steps: 0.019511412159627796\n",
      "Training loss: 0.018139018495214963\n",
      "Training accuracy: 0.9975998613245003\n",
      "Validation loss per 100 evaluation steps: 0.0031444949563592672\n",
      "Validation Loss: 0.004813136738569786\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0181\n",
      "\t - Validation loss: 0.0048\n",
      "Validation loss decreased (0.007912 --> 0.004813).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0073302690871059895\n",
      "Training loss per 100 training steps: 0.0079588159264093\n",
      "Training loss per 100 training steps: 0.01411263276220517\n",
      "Training loss: 0.013357477065981874\n",
      "Training accuracy: 0.9980749919375814\n",
      "Validation loss per 100 evaluation steps: 0.0023840670473873615\n",
      "Validation Loss: 0.0036941590427886696\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0134\n",
      "\t - Validation loss: 0.0037\n",
      "Validation loss decreased (0.004813 --> 0.003694).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004824458621442318\n",
      "Training loss per 100 training steps: 0.00615821319221897\n",
      "Training loss per 100 training steps: 0.011370091570485661\n",
      "Training loss: 0.01038447380390707\n",
      "Training accuracy: 0.998346578208772\n",
      "Validation loss per 100 evaluation steps: 0.0016117756022140384\n",
      "Validation Loss: 0.0026394347310997545\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0104\n",
      "\t - Validation loss: 0.0026\n",
      "Validation loss decreased (0.003694 --> 0.002639).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0034877995494753122\n",
      "Training loss per 100 training steps: 0.0037869508124629757\n",
      "Training loss per 100 training steps: 0.008807523362570215\n",
      "Training loss: 0.008026343984568507\n",
      "Training accuracy: 0.9987071948662278\n",
      "Validation loss per 100 evaluation steps: 0.0013260106788948178\n",
      "Validation Loss: 0.001949378203911086\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0080\n",
      "\t - Validation loss: 0.0019\n",
      "Validation loss decreased (0.002639 --> 0.001949).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.01251982618123293\n",
      "Training loss per 100 training steps: 0.0028627103166931336\n",
      "Training loss per 100 training steps: 0.007667156776751563\n",
      "Training loss: 0.006967158741102468\n",
      "Training accuracy: 0.9985756057458307\n",
      "Validation loss per 100 evaluation steps: 0.0010423518251627684\n",
      "Validation Loss: 0.0017052835590826967\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 8/100\n",
      "\t - Training loss: 0.0070\n",
      "\t - Validation loss: 0.0017\n",
      "Validation loss decreased (0.001949 --> 0.001705).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0024924403987824917\n",
      "Training loss per 100 training steps: 0.002548959377074227\n",
      "Training loss per 100 training steps: 0.0072529074256377874\n",
      "Training loss: 0.006584451957938394\n",
      "Training accuracy: 0.9987750766968737\n",
      "Validation loss per 100 evaluation steps: 0.0009161639609374106\n",
      "Validation Loss: 0.0031310100253904237\n",
      "Validation Accuracy: 0.9994444444444445\n",
      "*****\n",
      "Epoch 9/100\n",
      "\t - Training loss: 0.0066\n",
      "\t - Validation loss: 0.0031\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0011423785472288728\n",
      "Validation Loss: 0.002922050822720242\n",
      "Validation Accuracy: 0.9997076023391813\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 4/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.6258764266967773\n",
      "Training loss per 100 training steps: 0.8294489145426467\n",
      "Training loss per 100 training steps: 0.6977634779108104\n",
      "Training loss: 0.6295575410941568\n",
      "Training accuracy: 0.8288137524995973\n",
      "Validation loss per 100 evaluation steps: 0.11437142640352249\n",
      "Validation Loss: 0.11839533975968758\n",
      "Validation Accuracy: 0.9803558658162043\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6296\n",
      "\t - Validation loss: 0.1184\n",
      "Validation loss decreased (0.001705 --> 0.118395).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.09889018535614014\n",
      "Training loss per 100 training steps: 0.08247327829462171\n",
      "Training loss per 100 training steps: 0.09313097762509216\n",
      "Training loss: 0.08531883610960316\n",
      "Training accuracy: 0.9829132305929107\n",
      "Validation loss per 100 evaluation steps: 0.015277101658284664\n",
      "Validation Loss: 0.017454594490118325\n",
      "Validation Accuracy: 0.9986645299145299\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0853\n",
      "\t - Validation loss: 0.0175\n",
      "Validation loss decreased (0.118395 --> 0.017455).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.019104480743408203\n",
      "Training loss per 100 training steps: 0.020580916667799695\n",
      "Training loss per 100 training steps: 0.029942469635459396\n",
      "Training loss: 0.028118591220509418\n",
      "Training accuracy: 0.995585618140276\n",
      "Validation loss per 100 evaluation steps: 0.004834109917283058\n",
      "Validation Loss: 0.00741242979420349\n",
      "Validation Accuracy: 0.9994444444444445\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0281\n",
      "\t - Validation loss: 0.0074\n",
      "Validation loss decreased (0.017455 --> 0.007412).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.00783628597855568\n",
      "Training loss per 100 training steps: 0.00995623837179034\n",
      "Training loss per 100 training steps: 0.017090354017468532\n",
      "Training loss: 0.015831322782915554\n",
      "Training accuracy: 0.9980119289754656\n",
      "Validation loss per 100 evaluation steps: 0.0027114388067275286\n",
      "Validation Loss: 0.003773780136058728\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0158\n",
      "\t - Validation loss: 0.0038\n",
      "Validation loss decreased (0.007412 --> 0.003774).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005381232593208551\n",
      "Training loss per 100 training steps: 0.0054595596710275305\n",
      "Training loss per 100 training steps: 0.011390016474459894\n",
      "Training loss: 0.010667713030296214\n",
      "Training accuracy: 0.998545256428483\n",
      "Validation loss per 100 evaluation steps: 0.0018932846141979098\n",
      "Validation Loss: 0.0028814781825834265\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0107\n",
      "\t - Validation loss: 0.0029\n",
      "Validation loss decreased (0.003774 --> 0.002881).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004883654415607452\n",
      "Training loss per 100 training steps: 0.0038597087023115838\n",
      "Training loss per 100 training steps: 0.00949256625999488\n",
      "Training loss: 0.008738591367997104\n",
      "Training accuracy: 0.9989816898599168\n",
      "Validation loss per 100 evaluation steps: 0.0014545716112479568\n",
      "Validation Loss: 0.00261786324554123\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0087\n",
      "\t - Validation loss: 0.0026\n",
      "Validation loss decreased (0.002881 --> 0.002618).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.003969288431107998\n",
      "Training loss per 100 training steps: 0.0035726393833479817\n",
      "Training loss per 100 training steps: 0.008319598337663199\n",
      "Training loss: 0.007664620908595496\n",
      "Training accuracy: 0.9988305557415726\n",
      "Validation loss per 100 evaluation steps: 0.0011682191397994757\n",
      "Validation Loss: 0.001985077844195378\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0077\n",
      "\t - Validation loss: 0.0020\n",
      "Validation loss decreased (0.002618 --> 0.001985).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0034144981764256954\n",
      "Training loss per 100 training steps: 0.0035294417250385083\n",
      "Training loss per 100 training steps: 0.009474440775487331\n",
      "Training loss: 0.008532385510087264\n",
      "Training accuracy: 0.9984092998802983\n",
      "Validation loss per 100 evaluation steps: 0.001141912303864956\n",
      "Validation Loss: 0.0019895411018903057\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 8/100\n",
      "\t - Training loss: 0.0085\n",
      "\t - Validation loss: 0.0020\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0014930105535313487\n",
      "Validation Loss: 0.0077384075052881\n",
      "Validation Accuracy: 0.998780487804878\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 5/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.7748236656188965\n",
      "Training loss per 100 training steps: 0.9755435491552448\n",
      "Training loss per 100 training steps: 0.7963685124964264\n",
      "Training loss: 0.7213961883690678\n",
      "Training accuracy: 0.8023215018200196\n",
      "Validation loss per 100 evaluation steps: 0.14741279184818268\n",
      "Validation Loss: 0.1791664432734251\n",
      "Validation Accuracy: 0.9678249702928782\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.7214\n",
      "\t - Validation loss: 0.1792\n",
      "Validation loss decreased (0.001985 --> 0.179166).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.1588210165500641\n",
      "Training loss per 100 training steps: 0.11366366039924693\n",
      "Training loss per 100 training steps: 0.11377567805312759\n",
      "Training loss: 0.10399300112788167\n",
      "Training accuracy: 0.979175316567497\n",
      "Validation loss per 100 evaluation steps: 0.016396857798099518\n",
      "Validation Loss: 0.022140003104383747\n",
      "Validation Accuracy: 0.9989236111111112\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.1040\n",
      "\t - Validation loss: 0.0221\n",
      "Validation loss decreased (0.179166 --> 0.022140).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.025621363893151283\n",
      "Training loss per 100 training steps: 0.024421963974427762\n",
      "Training loss per 100 training steps: 0.03195535337357824\n",
      "Training loss: 0.030020166980885284\n",
      "Training accuracy: 0.9955767755417383\n",
      "Validation loss per 100 evaluation steps: 0.0073599014431238174\n",
      "Validation Loss: 0.009593477740418166\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0300\n",
      "\t - Validation loss: 0.0096\n",
      "Validation loss decreased (0.022140 --> 0.009593).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.010715022683143616\n",
      "Training loss per 100 training steps: 0.010314760925617106\n",
      "Training loss per 100 training steps: 0.018651717358653373\n",
      "Training loss: 0.017433302972011833\n",
      "Training accuracy: 0.9979041601165518\n",
      "Validation loss per 100 evaluation steps: 0.003152614226564765\n",
      "Validation Loss: 0.00484524123215427\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0174\n",
      "\t - Validation loss: 0.0048\n",
      "Validation loss decreased (0.009593 --> 0.004845).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.007798857521265745\n",
      "Training loss per 100 training steps: 0.006881904767568011\n",
      "Training loss per 100 training steps: 0.01311750834418544\n",
      "Training loss: 0.012035216862226234\n",
      "Training accuracy: 0.9984509117346113\n",
      "Validation loss per 100 evaluation steps: 0.002089828485623002\n",
      "Validation Loss: 0.0036109651535904657\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0120\n",
      "\t - Validation loss: 0.0036\n",
      "Validation loss decreased (0.004845 --> 0.003611).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005843109451234341\n",
      "Training loss per 100 training steps: 0.007106727053697156\n",
      "Training loss per 100 training steps: 0.012367254556318865\n",
      "Training loss: 0.011244189526353563\n",
      "Training accuracy: 0.9980725245894044\n",
      "Validation loss per 100 evaluation steps: 0.0016468791291117668\n",
      "Validation Loss: 0.012303135501376043\n",
      "Validation Accuracy: 0.9979166666666668\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0112\n",
      "\t - Validation loss: 0.0123\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0016202032566070557\n",
      "Validation Loss: 0.005647411493312878\n",
      "Validation Accuracy: 0.9990196078431371\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 6/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.5941038131713867\n",
      "Training loss per 100 training steps: 0.9113053195547349\n",
      "Training loss per 100 training steps: 0.7797828828220936\n",
      "Training loss: 0.7032026439404288\n",
      "Training accuracy: 0.8092414213434976\n",
      "Validation loss per 100 evaluation steps: 0.17540694773197174\n",
      "Validation Loss: 0.16472557404388985\n",
      "Validation Accuracy: 0.9712112433766474\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.7032\n",
      "\t - Validation loss: 0.1647\n",
      "Validation loss decreased (0.003611 --> 0.164726).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.16235065460205078\n",
      "Training loss per 100 training steps: 0.1082322939879971\n",
      "Training loss per 100 training steps: 0.11272304499549653\n",
      "Training loss: 0.1024960563322451\n",
      "Training accuracy: 0.9799026658244648\n",
      "Validation loss per 100 evaluation steps: 0.019970441237092018\n",
      "Validation Loss: 0.02080801877503594\n",
      "Validation Accuracy: 0.9993055555555554\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.1025\n",
      "\t - Validation loss: 0.0208\n",
      "Validation loss decreased (0.164726 --> 0.020808).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.015543783083558083\n",
      "Training loss per 100 training steps: 0.022287085467931067\n",
      "Training loss per 100 training steps: 0.031053460835576502\n",
      "Training loss: 0.029180619601520293\n",
      "Training accuracy: 0.9961338104465194\n",
      "Validation loss per 100 evaluation steps: 0.00627494789659977\n",
      "Validation Loss: 0.00950127817923203\n",
      "Validation Accuracy: 0.9989583333333333\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0292\n",
      "\t - Validation loss: 0.0095\n",
      "Validation loss decreased (0.020808 --> 0.009501).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.007836589589715004\n",
      "Training loss per 100 training steps: 0.013134683385528255\n",
      "Training loss per 100 training steps: 0.01820493199334327\n",
      "Training loss: 0.016851018483265295\n",
      "Training accuracy: 0.9980142790335628\n",
      "Validation loss per 100 evaluation steps: 0.0030516411643475294\n",
      "Validation Loss: 0.005109236955953141\n",
      "Validation Accuracy: 0.9994791666666667\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0169\n",
      "\t - Validation loss: 0.0051\n",
      "Validation loss decreased (0.009501 --> 0.005109).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.00627867691218853\n",
      "Training loss per 100 training steps: 0.005876984228241709\n",
      "Training loss per 100 training steps: 0.011757195465016499\n",
      "Training loss: 0.011054761792893107\n",
      "Training accuracy: 0.9988267946463179\n",
      "Validation loss per 100 evaluation steps: 0.002159171737730503\n",
      "Validation Loss: 0.002902962996934851\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0111\n",
      "\t - Validation loss: 0.0029\n",
      "Validation loss decreased (0.005109 --> 0.002903).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004172534216195345\n",
      "Training loss per 100 training steps: 0.004256536954746462\n",
      "Training loss per 100 training steps: 0.01098799351741796\n",
      "Training loss: 0.010150079107686815\n",
      "Training accuracy: 0.9984501944716314\n",
      "Validation loss per 100 evaluation steps: 0.0015187724493443966\n",
      "Validation Loss: 0.003293978354971235\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0102\n",
      "\t - Validation loss: 0.0033\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0018232831498607993\n",
      "Validation Loss: 0.012020263280525493\n",
      "Validation Accuracy: 0.9981529769665362\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 7/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.5175740718841553\n",
      "Training loss per 100 training steps: 0.8960560358101779\n",
      "Training loss per 100 training steps: 0.7469067345581838\n",
      "Training loss: 0.6750540379591349\n",
      "Training accuracy: 0.8164387610736609\n",
      "Validation loss per 100 evaluation steps: 0.120186947286129\n",
      "Validation Loss: 0.1551071720197797\n",
      "Validation Accuracy: 0.9650184858595974\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6751\n",
      "\t - Validation loss: 0.1551\n",
      "Validation loss decreased (0.002903 --> 0.155107).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.16569240391254425\n",
      "Training loss per 100 training steps: 0.11054308094674407\n",
      "Training loss per 100 training steps: 0.10741231775383896\n",
      "Training loss: 0.09773281765632144\n",
      "Training accuracy: 0.980607452360676\n",
      "Validation loss per 100 evaluation steps: 0.022916555404663086\n",
      "Validation Loss: 0.022433211887255312\n",
      "Validation Accuracy: 0.9972680652680652\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0977\n",
      "\t - Validation loss: 0.0224\n",
      "Validation loss decreased (0.155107 --> 0.022433).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.02542008087038994\n",
      "Training loss per 100 training steps: 0.026390643827248327\n",
      "Training loss per 100 training steps: 0.034204661327214975\n",
      "Training loss: 0.0320377248895018\n",
      "Training accuracy: 0.9950308719087676\n",
      "Validation loss per 100 evaluation steps: 0.006514959502965212\n",
      "Validation Loss: 0.010577391976645837\n",
      "Validation Accuracy: 0.9988125\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0320\n",
      "\t - Validation loss: 0.0106\n",
      "Validation loss decreased (0.022433 --> 0.010577).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.011522321961820126\n",
      "Training loss per 100 training steps: 0.011620388068904234\n",
      "Training loss per 100 training steps: 0.018277310929608655\n",
      "Training loss: 0.01699104924987563\n",
      "Training accuracy: 0.9982351614377278\n",
      "Validation loss per 100 evaluation steps: 0.0032355852890759706\n",
      "Validation Loss: 0.004400537450176974\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0170\n",
      "\t - Validation loss: 0.0044\n",
      "Validation loss decreased (0.010577 --> 0.004401).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0075088730081915855\n",
      "Training loss per 100 training steps: 0.0068869500301114404\n",
      "Training loss per 100 training steps: 0.012790216799056278\n",
      "Training loss: 0.011877427463607565\n",
      "Training accuracy: 0.9985565573398736\n",
      "Validation loss per 100 evaluation steps: 0.0022092994768172503\n",
      "Validation Loss: 0.003331584791885689\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0119\n",
      "\t - Validation loss: 0.0033\n",
      "Validation loss decreased (0.004401 --> 0.003332).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005723976064473391\n",
      "Training loss per 100 training steps: 0.005411082740393605\n",
      "Training loss per 100 training steps: 0.009020532011077623\n",
      "Training loss: 0.008376586043565464\n",
      "Training accuracy: 0.998869399362971\n",
      "Validation loss per 100 evaluation steps: 0.0016617424553260207\n",
      "Validation Loss: 0.004325189784867689\n",
      "Validation Accuracy: 0.9993333333333333\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0084\n",
      "\t - Validation loss: 0.0043\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.002356748329475522\n",
      "Validation Loss: 0.0031504576812343052\n",
      "Validation Accuracy: 0.9996376811594203\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 8/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.6116130352020264\n",
      "Training loss per 100 training steps: 0.923894796188515\n",
      "Training loss per 100 training steps: 0.7655333144896066\n",
      "Training loss: 0.6942631562216943\n",
      "Training accuracy: 0.8068966590152301\n",
      "Validation loss per 100 evaluation steps: 0.16672277450561523\n",
      "Validation Loss: 0.1850792732089758\n",
      "Validation Accuracy: 0.9664676239016096\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6943\n",
      "\t - Validation loss: 0.1851\n",
      "Validation loss decreased (0.003332 --> 0.185079).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.18300193548202515\n",
      "Training loss per 100 training steps: 0.12300672771243176\n",
      "Training loss per 100 training steps: 0.11913632373534032\n",
      "Training loss: 0.10861783133459692\n",
      "Training accuracy: 0.9760598459882074\n",
      "Validation loss per 100 evaluation steps: 0.027016781270503998\n",
      "Validation Loss: 0.02977402533094088\n",
      "Validation Accuracy: 0.9977146464646464\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.1086\n",
      "\t - Validation loss: 0.0298\n",
      "Validation loss decreased (0.185079 --> 0.029774).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.03896712884306908\n",
      "Training loss per 100 training steps: 0.027886992624711872\n",
      "Training loss per 100 training steps: 0.03429696450603023\n",
      "Training loss: 0.03216336514339039\n",
      "Training accuracy: 0.9950532877008225\n",
      "Validation loss per 100 evaluation steps: 0.008932475931942463\n",
      "Validation Loss: 0.011527517794941862\n",
      "Validation Accuracy: 0.9993055555555554\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0322\n",
      "\t - Validation loss: 0.0115\n",
      "Validation loss decreased (0.029774 --> 0.011528).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.010690481401979923\n",
      "Training loss per 100 training steps: 0.01233055467929433\n",
      "Training loss per 100 training steps: 0.018896004903264603\n",
      "Training loss: 0.017682569655159318\n",
      "Training accuracy: 0.99774877056279\n",
      "Validation loss per 100 evaluation steps: 0.0038069782312959433\n",
      "Validation Loss: 0.005384739251652112\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0177\n",
      "\t - Validation loss: 0.0054\n",
      "Validation loss decreased (0.011528 --> 0.005385).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.007342283148318529\n",
      "Training loss per 100 training steps: 0.006395040370413278\n",
      "Training loss per 100 training steps: 0.013071491180302862\n",
      "Training loss: 0.012182268702440715\n",
      "Training accuracy: 0.9985763972576364\n",
      "Validation loss per 100 evaluation steps: 0.002491484396159649\n",
      "Validation Loss: 0.003607100353110582\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0122\n",
      "\t - Validation loss: 0.0036\n",
      "Validation loss decreased (0.005385 --> 0.003607).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009624234400689602\n",
      "Training loss per 100 training steps: 0.004740732949051895\n",
      "Training loss per 100 training steps: 0.009093898796796132\n",
      "Training loss: 0.00842559034055678\n",
      "Training accuracy: 0.999010294561183\n",
      "Validation loss per 100 evaluation steps: 0.0017219650326296687\n",
      "Validation Loss: 0.0029783698574950297\n",
      "Validation Accuracy: 0.9993589743589744\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0084\n",
      "\t - Validation loss: 0.0030\n",
      "Validation loss decreased (0.003607 --> 0.002978).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0042872647754848\n",
      "Training loss per 100 training steps: 0.003442783181850642\n",
      "Training loss per 100 training steps: 0.009496385732605424\n",
      "Training loss: 0.008698731651549236\n",
      "Training accuracy: 0.9984454649410188\n",
      "Validation loss per 100 evaluation steps: 0.001380615751259029\n",
      "Validation Loss: 0.014276349769594769\n",
      "Validation Accuracy: 0.9952574086194775\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0087\n",
      "\t - Validation loss: 0.0143\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0018211051356047392\n",
      "Validation Loss: 0.0035530486066515246\n",
      "Validation Accuracy: 0.9996376811594203\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 9/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.588125467300415\n",
      "Training loss per 100 training steps: 0.9131967237975338\n",
      "Training loss per 100 training steps: 0.7513894660778306\n",
      "Training loss: 0.680616712150704\n",
      "Training accuracy: 0.8181802428431322\n",
      "Validation loss per 100 evaluation steps: 0.23360812664031982\n",
      "Validation Loss: 0.164627823792398\n",
      "Validation Accuracy: 0.9611350304088996\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6806\n",
      "\t - Validation loss: 0.1646\n",
      "Validation loss decreased (0.002978 --> 0.164628).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.13237597048282623\n",
      "Training loss per 100 training steps: 0.10745457232477937\n",
      "Training loss per 100 training steps: 0.11023368364413134\n",
      "Training loss: 0.10107886626486894\n",
      "Training accuracy: 0.9786525123022617\n",
      "Validation loss per 100 evaluation steps: 0.021620741114020348\n",
      "Validation Loss: 0.02612293700221926\n",
      "Validation Accuracy: 0.993337174582308\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.1011\n",
      "\t - Validation loss: 0.0261\n",
      "Validation loss decreased (0.164628 --> 0.026123).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.020980531349778175\n",
      "Training loss per 100 training steps: 0.020651646654610292\n",
      "Training loss per 100 training steps: 0.02974264332514942\n",
      "Training loss: 0.029829971543161058\n",
      "Training accuracy: 0.995170863073156\n",
      "Validation loss per 100 evaluation steps: 0.0067055379040539265\n",
      "Validation Loss: 0.011285650602076203\n",
      "Validation Accuracy: 0.9971168196143864\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0298\n",
      "\t - Validation loss: 0.0113\n",
      "Validation loss decreased (0.026123 --> 0.011286).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.010249350219964981\n",
      "Training loss per 100 training steps: 0.010680726208346019\n",
      "Training loss per 100 training steps: 0.018741166462371155\n",
      "Training loss: 0.01775099547039874\n",
      "Training accuracy: 0.9974792661783916\n",
      "Validation loss per 100 evaluation steps: 0.003377351211383939\n",
      "Validation Loss: 0.0071522107697092\n",
      "Validation Accuracy: 0.998668714797747\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0178\n",
      "\t - Validation loss: 0.0072\n",
      "Validation loss decreased (0.011286 --> 0.007152).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0074670580215752125\n",
      "Training loss per 100 training steps: 0.006740295044653634\n",
      "Training loss per 100 training steps: 0.012829946459442451\n",
      "Training loss: 0.011896986149431464\n",
      "Training accuracy: 0.9984912125620236\n",
      "Validation loss per 100 evaluation steps: 0.002224390394985676\n",
      "Validation Loss: 0.003598954804086437\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0119\n",
      "\t - Validation loss: 0.0036\n",
      "Validation loss decreased (0.007152 --> 0.003599).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.00621405802667141\n",
      "Training loss per 100 training steps: 0.00403998160301385\n",
      "Training loss per 100 training steps: 0.010039629975324543\n",
      "Training loss: 0.00927170244057295\n",
      "Training accuracy: 0.998635861325396\n",
      "Validation loss per 100 evaluation steps: 0.0016807552892714739\n",
      "Validation Loss: 0.003118229965912178\n",
      "Validation Accuracy: 0.9994949494949494\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0093\n",
      "\t - Validation loss: 0.0031\n",
      "Validation loss decreased (0.003599 --> 0.003118).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004065678454935551\n",
      "Training loss per 100 training steps: 0.004357155866570549\n",
      "Training loss per 100 training steps: 0.00932987721924165\n",
      "Training loss: 0.008600635091116762\n",
      "Training accuracy: 0.9983121426235333\n",
      "Validation loss per 100 evaluation steps: 0.0014446629211306572\n",
      "Validation Loss: 0.003453686988602082\n",
      "Validation Accuracy: 0.9989247311827957\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0086\n",
      "\t - Validation loss: 0.0035\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0016678078100085258\n",
      "Validation Loss: 0.006379487030790188\n",
      "Validation Accuracy: 0.9981671554252199\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 10/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.4544782638549805\n",
      "Training loss per 100 training steps: 0.926475298581737\n",
      "Training loss per 100 training steps: 0.7647985704057846\n",
      "Training loss: 0.6920369382978988\n",
      "Training accuracy: 0.8106350578244111\n",
      "Validation loss per 100 evaluation steps: 0.10932880640029907\n",
      "Validation Loss: 0.15793669453511636\n",
      "Validation Accuracy: 0.9693131215096223\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6920\n",
      "\t - Validation loss: 0.1579\n",
      "Validation loss decreased (0.003118 --> 0.157937).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.14460699260234833\n",
      "Training loss per 100 training steps: 0.10794848046901792\n",
      "Training loss per 100 training steps: 0.10812401986073944\n",
      "Training loss: 0.09846008542784247\n",
      "Training accuracy: 0.9793253962985385\n",
      "Validation loss per 100 evaluation steps: 0.017817502841353416\n",
      "Validation Loss: 0.02241179164654265\n",
      "Validation Accuracy: 0.9981150793650795\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0985\n",
      "\t - Validation loss: 0.0224\n",
      "Validation loss decreased (0.157937 --> 0.022412).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.02313968539237976\n",
      "Training loss per 100 training steps: 0.023906442221475414\n",
      "Training loss per 100 training steps: 0.030220750385700768\n",
      "Training loss: 0.028336648426229964\n",
      "Training accuracy: 0.9959017862332987\n",
      "Validation loss per 100 evaluation steps: 0.0051954397931694984\n",
      "Validation Loss: 0.007876620666744808\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0283\n",
      "\t - Validation loss: 0.0079\n",
      "Validation loss decreased (0.022412 --> 0.007877).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.007743383292108774\n",
      "Training loss per 100 training steps: 0.012310745219912121\n",
      "Training loss per 100 training steps: 0.018890581562864914\n",
      "Training loss: 0.017525926000485588\n",
      "Training accuracy: 0.9977478014159876\n",
      "Validation loss per 100 evaluation steps: 0.0029490466695278883\n",
      "Validation Loss: 0.009256058333752057\n",
      "Validation Accuracy: 0.9988492063492064\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0175\n",
      "\t - Validation loss: 0.0093\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.004310991149395704\n",
      "Validation Loss: 0.010969462208837892\n",
      "Validation Accuracy: 0.9974548863140867\n",
      "\n",
      "\n",
      "\n",
      "############################## \t  Running KFold with seed 42\t ##############################\n",
      "\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 1/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.5784223079681396\n",
      "Training loss per 100 training steps: 0.887034324283647\n",
      "Training loss per 100 training steps: 0.7270654726829102\n",
      "Training loss: 0.6559548939601714\n",
      "Training accuracy: 0.8228687657861492\n",
      "Validation loss per 100 evaluation steps: 0.09525921940803528\n",
      "Validation Loss: 0.15064017195254564\n",
      "Validation Accuracy: 0.9667101558005186\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6560\n",
      "\t - Validation loss: 0.1506\n",
      "Validation loss decreased (0.007877 --> 0.150640).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.18451188504695892\n",
      "Training loss per 100 training steps: 0.10271487422840725\n",
      "Training loss per 100 training steps: 0.09938487950805111\n",
      "Training loss: 0.09057245257960148\n",
      "Training accuracy: 0.9807384213610449\n",
      "Validation loss per 100 evaluation steps: 0.014995829202234745\n",
      "Validation Loss: 0.02119157751246045\n",
      "Validation Accuracy: 0.9980907217959647\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0906\n",
      "\t - Validation loss: 0.0212\n",
      "Validation loss decreased (0.150640 --> 0.021192).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.018523961305618286\n",
      "Training loss per 100 training steps: 0.022696638309240045\n",
      "Training loss per 100 training steps: 0.0310732941884566\n",
      "Training loss: 0.02930707802424724\n",
      "Training accuracy: 0.9953848325134742\n",
      "Validation loss per 100 evaluation steps: 0.005593337118625641\n",
      "Validation Loss: 0.008070219362465044\n",
      "Validation Accuracy: 0.9992753623188406\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0293\n",
      "\t - Validation loss: 0.0081\n",
      "Validation loss decreased (0.021192 --> 0.008070).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.00830337405204773\n",
      "Training loss per 100 training steps: 0.010358311618576841\n",
      "Training loss per 100 training steps: 0.018382770362639085\n",
      "Training loss: 0.017170509347934744\n",
      "Training accuracy: 0.9979484484866211\n",
      "Validation loss per 100 evaluation steps: 0.0031446311622858047\n",
      "Validation Loss: 0.004046741465572268\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0172\n",
      "\t - Validation loss: 0.0040\n",
      "Validation loss decreased (0.008070 --> 0.004047).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.007331854663789272\n",
      "Training loss per 100 training steps: 0.006358948663006177\n",
      "Training loss per 100 training steps: 0.013027857255830026\n",
      "Training loss: 0.012049689222745472\n",
      "Training accuracy: 0.9983599535533584\n",
      "Validation loss per 100 evaluation steps: 0.002140042372047901\n",
      "Validation Loss: 0.013922666612779721\n",
      "Validation Accuracy: 0.9973694347122338\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0120\n",
      "\t - Validation loss: 0.0139\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.002863011322915554\n",
      "Validation Loss: 0.007119622667475293\n",
      "Validation Accuracy: 0.9987654320987654\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 2/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.5068840980529785\n",
      "Training loss per 100 training steps: 0.853969656004764\n",
      "Training loss per 100 training steps: 0.7193350222202676\n",
      "Training loss: 0.6534913664041948\n",
      "Training accuracy: 0.8244882171297326\n",
      "Validation loss per 100 evaluation steps: 0.15155568718910217\n",
      "Validation Loss: 0.15402728940049806\n",
      "Validation Accuracy: 0.9663463500978601\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6535\n",
      "\t - Validation loss: 0.1540\n",
      "Validation loss decreased (0.004047 --> 0.154027).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.17359843850135803\n",
      "Training loss per 100 training steps: 0.0996726477094511\n",
      "Training loss per 100 training steps: 0.10199790369181787\n",
      "Training loss: 0.09285010067166902\n",
      "Training accuracy: 0.980649632169779\n",
      "Validation loss per 100 evaluation steps: 0.01908501610159874\n",
      "Validation Loss: 0.024691895814612508\n",
      "Validation Accuracy: 0.9968992342782665\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0929\n",
      "\t - Validation loss: 0.0247\n",
      "Validation loss decreased (0.154027 --> 0.024692).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.020278947427868843\n",
      "Training loss per 100 training steps: 0.021270768444911384\n",
      "Training loss per 100 training steps: 0.031734981126990636\n",
      "Training loss: 0.029816840757701954\n",
      "Training accuracy: 0.9957076970583235\n",
      "Validation loss per 100 evaluation steps: 0.004743493627756834\n",
      "Validation Loss: 0.007889123319182545\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0298\n",
      "\t - Validation loss: 0.0079\n",
      "Validation loss decreased (0.024692 --> 0.007889).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009770816192030907\n",
      "Training loss per 100 training steps: 0.012431246378357606\n",
      "Training loss per 100 training steps: 0.019000856377258526\n",
      "Training loss: 0.01765193114205882\n",
      "Training accuracy: 0.9977529967163715\n",
      "Validation loss per 100 evaluation steps: 0.002526636002585292\n",
      "Validation Loss: 0.007801398506853729\n",
      "Validation Accuracy: 0.9988034188034188\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0177\n",
      "\t - Validation loss: 0.0078\n",
      "Validation loss decreased (0.007889 --> 0.007801).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006129165180027485\n",
      "Training loss per 100 training steps: 0.007674381171473035\n",
      "Training loss per 100 training steps: 0.01407978213067857\n",
      "Training loss: 0.012887819724924424\n",
      "Training accuracy: 0.9982279713520689\n",
      "Validation loss per 100 evaluation steps: 0.001739530242048204\n",
      "Validation Loss: 0.0036192949085185927\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0129\n",
      "\t - Validation loss: 0.0036\n",
      "Validation loss decreased (0.007801 --> 0.003619).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005805241409689188\n",
      "Training loss per 100 training steps: 0.004939829505343765\n",
      "Training loss per 100 training steps: 0.010638938401825726\n",
      "Training loss: 0.009682325810143146\n",
      "Training accuracy: 0.9986664408508654\n",
      "Validation loss per 100 evaluation steps: 0.0013319718418642879\n",
      "Validation Loss: 0.0023424669886784005\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0097\n",
      "\t - Validation loss: 0.0023\n",
      "Validation loss decreased (0.003619 --> 0.002342).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004138758406043053\n",
      "Training loss per 100 training steps: 0.004995858679424123\n",
      "Training loss per 100 training steps: 0.009880664158353017\n",
      "Training loss: 0.008948329237422772\n",
      "Training accuracy: 0.9985105838202076\n",
      "Validation loss per 100 evaluation steps: 0.001186869922094047\n",
      "Validation Loss: 0.0024295720388181506\n",
      "Validation Accuracy: 0.9993333333333333\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0089\n",
      "\t - Validation loss: 0.0024\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0013636734802275896\n",
      "Validation Loss: 0.0015287549215524147\n",
      "Validation Accuracy: 1.0\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 3/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.558560848236084\n",
      "Training loss per 100 training steps: 0.8847266759465237\n",
      "Training loss per 100 training steps: 0.7318530143493444\n",
      "Training loss: 0.6614147923698946\n",
      "Training accuracy: 0.8205335600805074\n",
      "Validation loss per 100 evaluation steps: 0.13601957261562347\n",
      "Validation Loss: 0.14086578333129485\n",
      "Validation Accuracy: 0.9715659740945904\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6614\n",
      "\t - Validation loss: 0.1409\n",
      "Validation loss decreased (0.002342 --> 0.140866).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.16219878196716309\n",
      "Training loss per 100 training steps: 0.09748238814754946\n",
      "Training loss per 100 training steps: 0.09709620409974115\n",
      "Training loss: 0.08907218756420272\n",
      "Training accuracy: 0.9823085971520923\n",
      "Validation loss per 100 evaluation steps: 0.016809476539492607\n",
      "Validation Loss: 0.018387577884520095\n",
      "Validation Accuracy: 0.9993055555555554\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0891\n",
      "\t - Validation loss: 0.0184\n",
      "Validation loss decreased (0.140866 --> 0.018388).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.02251911722123623\n",
      "Training loss per 100 training steps: 0.020143499602517573\n",
      "Training loss per 100 training steps: 0.028672394706445992\n",
      "Training loss: 0.02769562343581572\n",
      "Training accuracy: 0.9955443151906676\n",
      "Validation loss per 100 evaluation steps: 0.004737888928502798\n",
      "Validation Loss: 0.0065535608873081705\n",
      "Validation Accuracy: 0.9993055555555554\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0277\n",
      "\t - Validation loss: 0.0066\n",
      "Validation loss decreased (0.018388 --> 0.006554).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0083113769069314\n",
      "Training loss per 100 training steps: 0.008751413137144825\n",
      "Training loss per 100 training steps: 0.017345268919887902\n",
      "Training loss: 0.01632713812242943\n",
      "Training accuracy: 0.9982118648774804\n",
      "Validation loss per 100 evaluation steps: 0.002534241182729602\n",
      "Validation Loss: 0.00430338135920465\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0163\n",
      "\t - Validation loss: 0.0043\n",
      "Validation loss decreased (0.006554 --> 0.004303).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006133719347417355\n",
      "Training loss per 100 training steps: 0.005703580657960755\n",
      "Training loss per 100 training steps: 0.011781381140810563\n",
      "Training loss: 0.01114052057583198\n",
      "Training accuracy: 0.9986427245079595\n",
      "Validation loss per 100 evaluation steps: 0.001808231812901795\n",
      "Validation Loss: 0.006312003446510062\n",
      "Validation Accuracy: 0.9989741161616161\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0111\n",
      "\t - Validation loss: 0.0063\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.002259189961478114\n",
      "Validation Loss: 0.01006875600432977\n",
      "Validation Accuracy: 0.9971975308641974\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 4/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.5455799102783203\n",
      "Training loss per 100 training steps: 0.9052436337022498\n",
      "Training loss per 100 training steps: 0.7772744785419744\n",
      "Training loss: 0.7082409118967397\n",
      "Training accuracy: 0.8087363722722276\n",
      "Validation loss per 100 evaluation steps: 0.14361391961574554\n",
      "Validation Loss: 0.15522828636070093\n",
      "Validation Accuracy: 0.972274629112635\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.7082\n",
      "\t - Validation loss: 0.1552\n",
      "Validation loss decreased (0.004303 --> 0.155228).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.2270313948392868\n",
      "Training loss per 100 training steps: 0.11276886006356171\n",
      "Training loss per 100 training steps: 0.11672823323372436\n",
      "Training loss: 0.10758116396394472\n",
      "Training accuracy: 0.9757336650297141\n",
      "Validation loss per 100 evaluation steps: 0.038270361721515656\n",
      "Validation Loss: 0.0292623868988206\n",
      "Validation Accuracy: 0.9985809178743961\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.1076\n",
      "\t - Validation loss: 0.0293\n",
      "Validation loss decreased (0.155228 --> 0.029262).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.03708359971642494\n",
      "Training loss per 100 training steps: 0.024885812396238938\n",
      "Training loss per 100 training steps: 0.03361919459965618\n",
      "Training loss: 0.03188405579793416\n",
      "Training accuracy: 0.9948246500345397\n",
      "Validation loss per 100 evaluation steps: 0.010446286760270596\n",
      "Validation Loss: 0.011117280515221258\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0319\n",
      "\t - Validation loss: 0.0111\n",
      "Validation loss decreased (0.029262 --> 0.011117).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.016986705362796783\n",
      "Training loss per 100 training steps: 0.012794998142462556\n",
      "Training loss per 100 training steps: 0.019750826648061177\n",
      "Training loss: 0.01848345436644936\n",
      "Training accuracy: 0.9973510145481798\n",
      "Validation loss per 100 evaluation steps: 0.004655693657696247\n",
      "Validation Loss: 0.006707754719536751\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0185\n",
      "\t - Validation loss: 0.0067\n",
      "Validation loss decreased (0.011117 --> 0.006708).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009648443199694157\n",
      "Training loss per 100 training steps: 0.008203213824660029\n",
      "Training loss per 100 training steps: 0.013999708573709227\n",
      "Training loss: 0.012989228188271532\n",
      "Training accuracy: 0.9982099474648168\n",
      "Validation loss per 100 evaluation steps: 0.0025691273622214794\n",
      "Validation Loss: 0.0037255324268092712\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0130\n",
      "\t - Validation loss: 0.0037\n",
      "Validation loss decreased (0.006708 --> 0.003726).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.021176880225539207\n",
      "Training loss per 100 training steps: 0.006221351794677206\n",
      "Training loss per 100 training steps: 0.011122738735157237\n",
      "Training loss: 0.01022525311705946\n",
      "Training accuracy: 0.9983905132107529\n",
      "Validation loss per 100 evaluation steps: 0.0017983601428568363\n",
      "Validation Loss: 0.0029390486907990027\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0102\n",
      "\t - Validation loss: 0.0029\n",
      "Validation loss decreased (0.003726 --> 0.002939).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004771523177623749\n",
      "Training loss per 100 training steps: 0.003750748954261515\n",
      "Training loss per 100 training steps: 0.007266271342778236\n",
      "Training loss: 0.006780391628462665\n",
      "Training accuracy: 0.9989364912524631\n",
      "Validation loss per 100 evaluation steps: 0.001327729900367558\n",
      "Validation Loss: 0.0018617347329078864\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0068\n",
      "\t - Validation loss: 0.0019\n",
      "Validation loss decreased (0.002939 --> 0.001862).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.003656733315438032\n",
      "Training loss per 100 training steps: 0.0027040152425536574\n",
      "Training loss per 100 training steps: 0.0055893665163393195\n",
      "Training loss: 0.005253071186500562\n",
      "Training accuracy: 0.9991498899362686\n",
      "Validation loss per 100 evaluation steps: 0.0011359861819073558\n",
      "Validation Loss: 0.0015750869361606116\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 8/100\n",
      "\t - Training loss: 0.0053\n",
      "\t - Validation loss: 0.0016\n",
      "Validation loss decreased (0.001862 --> 0.001575).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.003224762389436364\n",
      "Training loss per 100 training steps: 0.0027997385961750503\n",
      "Training loss per 100 training steps: 0.006684048031804277\n",
      "Training loss: 0.006116406785660744\n",
      "Training accuracy: 0.9989410946254933\n",
      "Validation loss per 100 evaluation steps: 0.0010877669556066394\n",
      "Validation Loss: 0.00331226168879463\n",
      "Validation Accuracy: 0.9995098039215686\n",
      "*****\n",
      "Epoch 9/100\n",
      "\t - Training loss: 0.0061\n",
      "\t - Validation loss: 0.0033\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0011531010968610644\n",
      "Validation Loss: 0.006041477657466506\n",
      "Validation Accuracy: 0.9993589743589744\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 5/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.565819263458252\n",
      "Training loss per 100 training steps: 0.8635430797786996\n",
      "Training loss per 100 training steps: 0.7120038541172867\n",
      "Training loss: 0.6422702779977763\n",
      "Training accuracy: 0.8306499737249617\n",
      "Validation loss per 100 evaluation steps: 0.08242253959178925\n",
      "Validation Loss: 0.1275570755203565\n",
      "Validation Accuracy: 0.9739570261964248\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6423\n",
      "\t - Validation loss: 0.1276\n",
      "Validation loss decreased (0.001575 --> 0.127557).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.13334719836711884\n",
      "Training loss per 100 training steps: 0.09195442055121507\n",
      "Training loss per 100 training steps: 0.09566181957888514\n",
      "Training loss: 0.08755568186791629\n",
      "Training accuracy: 0.9821546726307848\n",
      "Validation loss per 100 evaluation steps: 0.01625135727226734\n",
      "Validation Loss: 0.019535238513102134\n",
      "Validation Accuracy: 0.9977777777777778\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0876\n",
      "\t - Validation loss: 0.0195\n",
      "Validation loss decreased (0.127557 --> 0.019535).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.023012731224298477\n",
      "Training loss per 100 training steps: 0.02092996355846967\n",
      "Training loss per 100 training steps: 0.029446014659525593\n",
      "Training loss: 0.027706445638919955\n",
      "Training accuracy: 0.9955806526372346\n",
      "Validation loss per 100 evaluation steps: 0.0052731516771018505\n",
      "Validation Loss: 0.007767974181721608\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0277\n",
      "\t - Validation loss: 0.0078\n",
      "Validation loss decreased (0.019535 --> 0.007768).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.008030874654650688\n",
      "Training loss per 100 training steps: 0.010718588336914926\n",
      "Training loss per 100 training steps: 0.019774555686203326\n",
      "Training loss: 0.018298069170691825\n",
      "Training accuracy: 0.997671299983425\n",
      "Validation loss per 100 evaluation steps: 0.0029183728620409966\n",
      "Validation Loss: 0.004467768629547208\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0183\n",
      "\t - Validation loss: 0.0045\n",
      "Validation loss decreased (0.007768 --> 0.004468).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0065103261731565\n",
      "Training loss per 100 training steps: 0.006541035057386697\n",
      "Training loss per 100 training steps: 0.013079311910655294\n",
      "Training loss: 0.012051555154915555\n",
      "Training accuracy: 0.9985397363466642\n",
      "Validation loss per 100 evaluation steps: 0.002033290220424533\n",
      "Validation Loss: 0.003055610907419274\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0121\n",
      "\t - Validation loss: 0.0031\n",
      "Validation loss decreased (0.004468 --> 0.003056).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004811025690287352\n",
      "Training loss per 100 training steps: 0.004089380300944984\n",
      "Training loss per 100 training steps: 0.010026834959590539\n",
      "Training loss: 0.009187854236547499\n",
      "Training accuracy: 0.9986740810888458\n",
      "Validation loss per 100 evaluation steps: 0.0014651130186393857\n",
      "Validation Loss: 0.0023679252713918685\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0092\n",
      "\t - Validation loss: 0.0024\n",
      "Validation loss decreased (0.003056 --> 0.002368).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.003511477028951049\n",
      "Training loss per 100 training steps: 0.005170989790839134\n",
      "Training loss per 100 training steps: 0.009774918105587622\n",
      "Training loss: 0.009169388799673776\n",
      "Training accuracy: 0.9982892011193728\n",
      "Validation loss per 100 evaluation steps: 0.0012862314470112324\n",
      "Validation Loss: 0.004082451671517144\n",
      "Validation Accuracy: 0.9991666666666668\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0092\n",
      "\t - Validation loss: 0.0041\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.001968225697055459\n",
      "Validation Loss: 0.004954196259495803\n",
      "Validation Accuracy: 0.998748347801236\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 6/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.6436593532562256\n",
      "Training loss per 100 training steps: 0.9168290269404354\n",
      "Training loss per 100 training steps: 0.7460076381540417\n",
      "Training loss: 0.6728749622379532\n",
      "Training accuracy: 0.8200649781759138\n",
      "Validation loss per 100 evaluation steps: 0.13094426691532135\n",
      "Validation Loss: 0.12696420792490243\n",
      "Validation Accuracy: 0.975039227577677\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6729\n",
      "\t - Validation loss: 0.1270\n",
      "Validation loss decreased (0.002368 --> 0.126964).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.10624677687883377\n",
      "Training loss per 100 training steps: 0.0880613676502858\n",
      "Training loss per 100 training steps: 0.09518704722306473\n",
      "Training loss: 0.08723898214374144\n",
      "Training accuracy: 0.981863324315107\n",
      "Validation loss per 100 evaluation steps: 0.020326199010014534\n",
      "Validation Loss: 0.018379303502539794\n",
      "Validation Accuracy: 0.9983730158730159\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0872\n",
      "\t - Validation loss: 0.0184\n",
      "Validation loss decreased (0.126964 --> 0.018379).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.03890596702694893\n",
      "Training loss per 100 training steps: 0.02384521802057429\n",
      "Training loss per 100 training steps: 0.03276132619870243\n",
      "Training loss: 0.030914279632270336\n",
      "Training accuracy: 0.9947830798889438\n",
      "Validation loss per 100 evaluation steps: 0.007318481802940369\n",
      "Validation Loss: 0.0077419183255794145\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0309\n",
      "\t - Validation loss: 0.0077\n",
      "Validation loss decreased (0.018379 --> 0.007742).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.01201637927442789\n",
      "Training loss per 100 training steps: 0.008634293956755855\n",
      "Training loss per 100 training steps: 0.017120666416195123\n",
      "Training loss: 0.015975778471451534\n",
      "Training accuracy: 0.9980739287044912\n",
      "Validation loss per 100 evaluation steps: 0.0035110770259052515\n",
      "Validation Loss: 0.007662768273924788\n",
      "Validation Accuracy: 0.9978938692480359\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0160\n",
      "\t - Validation loss: 0.0077\n",
      "Validation loss decreased (0.007742 --> 0.007663).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0053270123898983\n",
      "Training loss per 100 training steps: 0.007355751649541135\n",
      "Training loss per 100 training steps: 0.013241778835607924\n",
      "Training loss: 0.012125755702301922\n",
      "Training accuracy: 0.9986693476134687\n",
      "Validation loss per 100 evaluation steps: 0.002386139240115881\n",
      "Validation Loss: 0.0029663888019664836\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0121\n",
      "\t - Validation loss: 0.0030\n",
      "Validation loss decreased (0.007663 --> 0.002966).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004319916013628244\n",
      "Training loss per 100 training steps: 0.0044590450309235415\n",
      "Training loss per 100 training steps: 0.00953153044735985\n",
      "Training loss: 0.008773876101702075\n",
      "Training accuracy: 0.9989385330750058\n",
      "Validation loss per 100 evaluation steps: 0.0017556729726493359\n",
      "Validation Loss: 0.0023531277780421077\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0088\n",
      "\t - Validation loss: 0.0024\n",
      "Validation loss decreased (0.002966 --> 0.002353).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0047841910272836685\n",
      "Training loss per 100 training steps: 0.003308882821572594\n",
      "Training loss per 100 training steps: 0.00758260277746273\n",
      "Training loss: 0.006998301024388271\n",
      "Training accuracy: 0.9991333150076248\n",
      "Validation loss per 100 evaluation steps: 0.001471014809794724\n",
      "Validation Loss: 0.0028798217012081296\n",
      "Validation Accuracy: 0.9994047619047619\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0070\n",
      "\t - Validation loss: 0.0029\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.001501303631812334\n",
      "Validation Loss: 0.00977503642012986\n",
      "Validation Accuracy: 0.9979591836734694\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 7/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.722349166870117\n",
      "Training loss per 100 training steps: 0.9702593334535561\n",
      "Training loss per 100 training steps: 0.7945983803168458\n",
      "Training loss: 0.7123130601869911\n",
      "Training accuracy: 0.805005790118606\n",
      "Validation loss per 100 evaluation steps: 0.20918864011764526\n",
      "Validation Loss: 0.17926224383215109\n",
      "Validation Accuracy: 0.9634655335363573\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.7123\n",
      "\t - Validation loss: 0.1793\n",
      "Validation loss decreased (0.002353 --> 0.179262).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.2467641979455948\n",
      "Training loss per 100 training steps: 0.11065819934194926\n",
      "Training loss per 100 training steps: 0.10477194023221287\n",
      "Training loss: 0.09553482091570852\n",
      "Training accuracy: 0.9801047382653018\n",
      "Validation loss per 100 evaluation steps: 0.024388387799263\n",
      "Validation Loss: 0.022490833443589507\n",
      "Validation Accuracy: 0.9969203270388615\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0955\n",
      "\t - Validation loss: 0.0225\n",
      "Validation loss decreased (0.179262 --> 0.022491).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.02012476697564125\n",
      "Training loss per 100 training steps: 0.021853386585849642\n",
      "Training loss per 100 training steps: 0.0307895982248792\n",
      "Training loss: 0.029245900764998767\n",
      "Training accuracy: 0.9953835271995973\n",
      "Validation loss per 100 evaluation steps: 0.008199550211429596\n",
      "Validation Loss: 0.007775812731900563\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0292\n",
      "\t - Validation loss: 0.0078\n",
      "Validation loss decreased (0.022491 --> 0.007776).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009658592753112316\n",
      "Training loss per 100 training steps: 0.009185906142309899\n",
      "Training loss per 100 training steps: 0.016702055517556286\n",
      "Training loss: 0.01565004646789846\n",
      "Training accuracy: 0.9980184131441161\n",
      "Validation loss per 100 evaluation steps: 0.0034593543969094753\n",
      "Validation Loss: 0.005753426090814173\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0157\n",
      "\t - Validation loss: 0.0058\n",
      "Validation loss decreased (0.007776 --> 0.005753).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006264514289796352\n",
      "Training loss per 100 training steps: 0.005947612753912511\n",
      "Training loss per 100 training steps: 0.012359855360634144\n",
      "Training loss: 0.011406711283132058\n",
      "Training accuracy: 0.998627360894144\n",
      "Validation loss per 100 evaluation steps: 0.002281437162309885\n",
      "Validation Loss: 0.003898974669088299\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0114\n",
      "\t - Validation loss: 0.0039\n",
      "Validation loss decreased (0.005753 --> 0.003899).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.00589281041175127\n",
      "Training loss per 100 training steps: 0.005152251325907315\n",
      "Training loss per 100 training steps: 0.010587299886085463\n",
      "Training loss: 0.00979834669533757\n",
      "Training accuracy: 0.9985954420312911\n",
      "Validation loss per 100 evaluation steps: 0.001741866348311305\n",
      "Validation Loss: 0.004185951466206461\n",
      "Validation Accuracy: 0.9983538587848934\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0098\n",
      "\t - Validation loss: 0.0042\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0022141430526971817\n",
      "Validation Loss: 0.007231829545344226\n",
      "Validation Accuracy: 0.998684546615581\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 8/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.508493185043335\n",
      "Training loss per 100 training steps: 0.8852300623265823\n",
      "Training loss per 100 training steps: 0.7516636929627675\n",
      "Training loss: 0.6793808156640089\n",
      "Training accuracy: 0.8167658754913113\n",
      "Validation loss per 100 evaluation steps: 0.14751271903514862\n",
      "Validation Loss: 0.1760829746723175\n",
      "Validation Accuracy: 0.96137296345831\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6794\n",
      "\t - Validation loss: 0.1761\n",
      "Validation loss decreased (0.003899 --> 0.176083).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.19799000024795532\n",
      "Training loss per 100 training steps: 0.1117413760817582\n",
      "Training loss per 100 training steps: 0.11011629450639979\n",
      "Training loss: 0.10023332438079499\n",
      "Training accuracy: 0.9794048582259973\n",
      "Validation loss per 100 evaluation steps: 0.018707996234297752\n",
      "Validation Loss: 0.025241982735072572\n",
      "Validation Accuracy: 0.9953231093746522\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.1002\n",
      "\t - Validation loss: 0.0252\n",
      "Validation loss decreased (0.176083 --> 0.025242).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.029932180419564247\n",
      "Training loss per 100 training steps: 0.022538641762762966\n",
      "Training loss per 100 training steps: 0.030907983896299382\n",
      "Training loss: 0.02890912286092003\n",
      "Training accuracy: 0.9960906951132982\n",
      "Validation loss per 100 evaluation steps: 0.0056805298663675785\n",
      "Validation Loss: 0.008488663355819881\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0289\n",
      "\t - Validation loss: 0.0085\n",
      "Validation loss decreased (0.025242 --> 0.008489).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.010965044610202312\n",
      "Training loss per 100 training steps: 0.010486348797244454\n",
      "Training loss per 100 training steps: 0.017777835720899835\n",
      "Training loss: 0.01635799866498393\n",
      "Training accuracy: 0.9979515079816214\n",
      "Validation loss per 100 evaluation steps: 0.00281520769931376\n",
      "Validation Loss: 0.004577551421243697\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0164\n",
      "\t - Validation loss: 0.0046\n",
      "Validation loss decreased (0.008489 --> 0.004578).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006524724420160055\n",
      "Training loss per 100 training steps: 0.007182648071170886\n",
      "Training loss per 100 training steps: 0.014605922581609431\n",
      "Training loss: 0.01340692988381635\n",
      "Training accuracy: 0.9981572720929914\n",
      "Validation loss per 100 evaluation steps: 0.0019561995286494493\n",
      "Validation Loss: 0.00435133904684335\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0134\n",
      "\t - Validation loss: 0.0044\n",
      "Validation loss decreased (0.004578 --> 0.004351).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006881863344460726\n",
      "Training loss per 100 training steps: 0.005595294975371349\n",
      "Training loss per 100 training steps: 0.011066475376922322\n",
      "Training loss: 0.01044670638076554\n",
      "Training accuracy: 0.9983996319724885\n",
      "Validation loss per 100 evaluation steps: 0.0015796921215951443\n",
      "Validation Loss: 0.006490195554215461\n",
      "Validation Accuracy: 0.9987012987012986\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0104\n",
      "\t - Validation loss: 0.0065\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0016937401378527284\n",
      "Validation Loss: 0.00469805250565211\n",
      "Validation Accuracy: 0.9993055555555556\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 9/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.4661049842834473\n",
      "Training loss per 100 training steps: 0.8816185977936971\n",
      "Training loss per 100 training steps: 0.7315411226666388\n",
      "Training loss: 0.6568662032109349\n",
      "Training accuracy: 0.8278477225927192\n",
      "Validation loss per 100 evaluation steps: 0.11264551430940628\n",
      "Validation Loss: 0.1428023196135958\n",
      "Validation Accuracy: 0.9709094005377575\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6569\n",
      "\t - Validation loss: 0.1428\n",
      "Validation loss decreased (0.004351 --> 0.142802).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.12057653814554214\n",
      "Training loss per 100 training steps: 0.10134752276399643\n",
      "Training loss per 100 training steps: 0.10071466909489822\n",
      "Training loss: 0.09189156088351953\n",
      "Training accuracy: 0.9808156948370944\n",
      "Validation loss per 100 evaluation steps: 0.013890359550714493\n",
      "Validation Loss: 0.023299291939474644\n",
      "Validation Accuracy: 0.9946690371306187\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0919\n",
      "\t - Validation loss: 0.0233\n",
      "Validation loss decreased (0.142802 --> 0.023299).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.021895315498113632\n",
      "Training loss per 100 training steps: 0.023480863932815222\n",
      "Training loss per 100 training steps: 0.030781847306652302\n",
      "Training loss: 0.028656590512773694\n",
      "Training accuracy: 0.9959225699345904\n",
      "Validation loss per 100 evaluation steps: 0.005341064650565386\n",
      "Validation Loss: 0.011913029403270532\n",
      "Validation Accuracy: 0.9988839285714286\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0287\n",
      "\t - Validation loss: 0.0119\n",
      "Validation loss decreased (0.023299 --> 0.011913).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009088273160159588\n",
      "Training loss per 100 training steps: 0.010157370780788289\n",
      "Training loss per 100 training steps: 0.0181480709796966\n",
      "Training loss: 0.016825579556816517\n",
      "Training accuracy: 0.9977444512139495\n",
      "Validation loss per 100 evaluation steps: 0.002947253407910466\n",
      "Validation Loss: 0.008532908865405867\n",
      "Validation Accuracy: 0.9989741161616161\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0168\n",
      "\t - Validation loss: 0.0085\n",
      "Validation loss decreased (0.011913 --> 0.008533).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006937470752745867\n",
      "Training loss per 100 training steps: 0.007196801486378997\n",
      "Training loss per 100 training steps: 0.01365878438317583\n",
      "Training loss: 0.012634522562353489\n",
      "Training accuracy: 0.9983552800722694\n",
      "Validation loss per 100 evaluation steps: 0.002022775821387768\n",
      "Validation Loss: 0.01896060082168939\n",
      "Validation Accuracy: 0.9960132307294663\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0126\n",
      "\t - Validation loss: 0.0190\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.002755973022431135\n",
      "Validation Loss: 0.007099395340386157\n",
      "Validation Accuracy: 0.9990065451145396\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 10/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.5345356464385986\n",
      "Training loss per 100 training steps: 0.8717613373652543\n",
      "Training loss per 100 training steps: 0.7423103535501518\n",
      "Training loss: 0.6742453732598228\n",
      "Training accuracy: 0.8195583327460453\n",
      "Validation loss per 100 evaluation steps: 0.1955256313085556\n",
      "Validation Loss: 0.15873296322921912\n",
      "Validation Accuracy: 0.9733758263544026\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6742\n",
      "\t - Validation loss: 0.1587\n",
      "Validation loss decreased (0.008533 --> 0.158733).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.16806046664714813\n",
      "Training loss per 100 training steps: 0.11152817285850201\n",
      "Training loss per 100 training steps: 0.11200823911942949\n",
      "Training loss: 0.10233178846694592\n",
      "Training accuracy: 0.9785191729901179\n",
      "Validation loss per 100 evaluation steps: 0.02364169806241989\n",
      "Validation Loss: 0.024551077264671525\n",
      "Validation Accuracy: 0.9971507936507937\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.1023\n",
      "\t - Validation loss: 0.0246\n",
      "Validation loss decreased (0.158733 --> 0.024551).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.027007771655917168\n",
      "Training loss per 100 training steps: 0.024668694870306714\n",
      "Training loss per 100 training steps: 0.03388405686235102\n",
      "Training loss: 0.03158284576234071\n",
      "Training accuracy: 0.9953601579612102\n",
      "Validation loss per 100 evaluation steps: 0.007988715544342995\n",
      "Validation Loss: 0.008251712804970642\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0316\n",
      "\t - Validation loss: 0.0083\n",
      "Validation loss decreased (0.024551 --> 0.008252).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.011762565933167934\n",
      "Training loss per 100 training steps: 0.011043717609810651\n",
      "Training loss per 100 training steps: 0.018457774954398546\n",
      "Training loss: 0.017190635064421145\n",
      "Training accuracy: 0.9978528503534543\n",
      "Validation loss per 100 evaluation steps: 0.004439173731952906\n",
      "Validation Loss: 0.005107191069206844\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0172\n",
      "\t - Validation loss: 0.0051\n",
      "Validation loss decreased (0.008252 --> 0.005107).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.008015134371817112\n",
      "Training loss per 100 training steps: 0.00690615264062613\n",
      "Training loss per 100 training steps: 0.012660095427620841\n",
      "Training loss: 0.011704651806151354\n",
      "Training accuracy: 0.9985153999331593\n",
      "Validation loss per 100 evaluation steps: 0.002783762291073799\n",
      "Validation Loss: 0.002956949806927393\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0117\n",
      "\t - Validation loss: 0.0030\n",
      "Validation loss decreased (0.005107 --> 0.002957).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004235710483044386\n",
      "Training loss per 100 training steps: 0.004937557266139895\n",
      "Training loss per 100 training steps: 0.010387546037652748\n",
      "Training loss: 0.009775846235908004\n",
      "Training accuracy: 0.9985615474393874\n",
      "Validation loss per 100 evaluation steps: 0.0022058712784200907\n",
      "Validation Loss: 0.008211080524294328\n",
      "Validation Accuracy: 0.9983488984674328\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0098\n",
      "\t - Validation loss: 0.0082\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.002360850339755416\n",
      "Validation Loss: 0.0037308908057942366\n",
      "Validation Accuracy: 0.9996794871794871\n",
      "\n",
      "\n",
      "\n",
      "############################## \t  Running KFold with seed 123\t ##############################\n",
      "\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 1/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.460801601409912\n",
      "Training loss per 100 training steps: 0.8565665616257356\n",
      "Training loss per 100 training steps: 0.7070978119302151\n",
      "Training loss: 0.6379641001777989\n",
      "Training accuracy: 0.8290463819096188\n",
      "Validation loss per 100 evaluation steps: 0.08374311774969101\n",
      "Validation Loss: 0.11444206386804581\n",
      "Validation Accuracy: 0.981663631950023\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6380\n",
      "\t - Validation loss: 0.1144\n",
      "Validation loss decreased (0.002957 --> 0.114442).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.10985136777162552\n",
      "Training loss per 100 training steps: 0.08874962846794636\n",
      "Training loss per 100 training steps: 0.09109866204880067\n",
      "Training loss: 0.08420191322523757\n",
      "Training accuracy: 0.9836844926419223\n",
      "Validation loss per 100 evaluation steps: 0.01806521601974964\n",
      "Validation Loss: 0.02010029477532953\n",
      "Validation Accuracy: 0.9984722222222222\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0842\n",
      "\t - Validation loss: 0.0201\n",
      "Validation loss decreased (0.114442 --> 0.020100).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.04746340215206146\n",
      "Training loss per 100 training steps: 0.020225499687476618\n",
      "Training loss per 100 training steps: 0.028855044237194368\n",
      "Training loss: 0.027748184865575377\n",
      "Training accuracy: 0.9955366945798592\n",
      "Validation loss per 100 evaluation steps: 0.0060771554708480835\n",
      "Validation Loss: 0.007322592187362412\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0277\n",
      "\t - Validation loss: 0.0073\n",
      "Validation loss decreased (0.020100 --> 0.007323).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.008495526388287544\n",
      "Training loss per 100 training steps: 0.010350346479952187\n",
      "Training loss per 100 training steps: 0.01747875764215393\n",
      "Training loss: 0.01672678145759997\n",
      "Training accuracy: 0.997625486380235\n",
      "Validation loss per 100 evaluation steps: 0.002699110424146056\n",
      "Validation Loss: 0.008503902887847895\n",
      "Validation Accuracy: 0.9988888888888888\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0167\n",
      "\t - Validation loss: 0.0085\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0042327092960476875\n",
      "Validation Loss: 0.010589689086191355\n",
      "Validation Accuracy: 0.998263888888889\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 2/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.6632838249206543\n",
      "Training loss per 100 training steps: 0.9303094909922911\n",
      "Training loss per 100 training steps: 0.7597583306221226\n",
      "Training loss: 0.6819339147886309\n",
      "Training accuracy: 0.8116340455849209\n",
      "Validation loss per 100 evaluation steps: 0.1620178073644638\n",
      "Validation Loss: 0.14479823149740695\n",
      "Validation Accuracy: 0.9711072631731738\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6819\n",
      "\t - Validation loss: 0.1448\n",
      "Validation loss decreased (0.007323 --> 0.144798).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.11519405245780945\n",
      "Training loss per 100 training steps: 0.09119851333965169\n",
      "Training loss per 100 training steps: 0.09831508052586323\n",
      "Training loss: 0.08994522671990034\n",
      "Training accuracy: 0.9810320353798027\n",
      "Validation loss per 100 evaluation steps: 0.02087225764989853\n",
      "Validation Loss: 0.02178400239596764\n",
      "Validation Accuracy: 0.9982291666666666\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0899\n",
      "\t - Validation loss: 0.0218\n",
      "Validation loss decreased (0.144798 --> 0.021784).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.019972868263721466\n",
      "Training loss per 100 training steps: 0.019609422639639367\n",
      "Training loss per 100 training steps: 0.0294214889397891\n",
      "Training loss: 0.027681325327511094\n",
      "Training accuracy: 0.9963239395767319\n",
      "Validation loss per 100 evaluation steps: 0.0061260671354830265\n",
      "Validation Loss: 0.007346177702614417\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0277\n",
      "\t - Validation loss: 0.0073\n",
      "Validation loss decreased (0.021784 --> 0.007346).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.00898632314056158\n",
      "Training loss per 100 training steps: 0.0086459919745748\n",
      "Training loss per 100 training steps: 0.018179608858769656\n",
      "Training loss: 0.016778739053802956\n",
      "Training accuracy: 0.997885305823123\n",
      "Validation loss per 100 evaluation steps: 0.003129407996311784\n",
      "Validation Loss: 0.004513048667771121\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0168\n",
      "\t - Validation loss: 0.0045\n",
      "Validation loss decreased (0.007346 --> 0.004513).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0076324050314724445\n",
      "Training loss per 100 training steps: 0.005684187580453287\n",
      "Training loss per 100 training steps: 0.01258960740168148\n",
      "Training loss: 0.01156597611095224\n",
      "Training accuracy: 0.9982760778720964\n",
      "Validation loss per 100 evaluation steps: 0.0021270550787448883\n",
      "Validation Loss: 0.003398328222101554\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0116\n",
      "\t - Validation loss: 0.0034\n",
      "Validation loss decreased (0.004513 --> 0.003398).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005023448262363672\n",
      "Training loss per 100 training steps: 0.004109432404436688\n",
      "Training loss per 100 training steps: 0.010989672273851524\n",
      "Training loss: 0.010091838408300668\n",
      "Training accuracy: 0.9982242290442237\n",
      "Validation loss per 100 evaluation steps: 0.0017312128329649568\n",
      "Validation Loss: 0.003437211874794836\n",
      "Validation Accuracy: 0.9991666666666668\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0101\n",
      "\t - Validation loss: 0.0034\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0026223640888929367\n",
      "Validation Loss: 0.004134239467869823\n",
      "Validation Accuracy: 0.9993055555555556\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 3/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.7251224517822266\n",
      "Training loss per 100 training steps: 0.9851046211943768\n",
      "Training loss per 100 training steps: 0.7962552230453017\n",
      "Training loss: 0.7137096097865024\n",
      "Training accuracy: 0.8041570295770417\n",
      "Validation loss per 100 evaluation steps: 0.11300574988126755\n",
      "Validation Loss: 0.14495756942778826\n",
      "Validation Accuracy: 0.9716107536188875\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.7137\n",
      "\t - Validation loss: 0.1450\n",
      "Validation loss decreased (0.003398 --> 0.144958).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.17659702897071838\n",
      "Training loss per 100 training steps: 0.10739395094316194\n",
      "Training loss per 100 training steps: 0.10816987065033089\n",
      "Training loss: 0.0984216158262634\n",
      "Training accuracy: 0.9778343336649927\n",
      "Validation loss per 100 evaluation steps: 0.019953753799200058\n",
      "Validation Loss: 0.023914927888351183\n",
      "Validation Accuracy: 0.9976844532279315\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0984\n",
      "\t - Validation loss: 0.0239\n",
      "Validation loss decreased (0.144958 --> 0.023915).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.019939523190259933\n",
      "Training loss per 100 training steps: 0.02101527603970158\n",
      "Training loss per 100 training steps: 0.03226637521026591\n",
      "Training loss: 0.030544434760172826\n",
      "Training accuracy: 0.9951377339101489\n",
      "Validation loss per 100 evaluation steps: 0.0063389078713953495\n",
      "Validation Loss: 0.00842745479506751\n",
      "Validation Accuracy: 0.9992753623188406\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0305\n",
      "\t - Validation loss: 0.0084\n",
      "Validation loss decreased (0.023915 --> 0.008427).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.017527814954519272\n",
      "Training loss per 100 training steps: 0.010778347705721412\n",
      "Training loss per 100 training steps: 0.020414560667206694\n",
      "Training loss: 0.01885304968811947\n",
      "Training accuracy: 0.9972034511355072\n",
      "Validation loss per 100 evaluation steps: 0.0029712822288274765\n",
      "Validation Loss: 0.0050228852468232315\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0189\n",
      "\t - Validation loss: 0.0050\n",
      "Validation loss decreased (0.008427 --> 0.005023).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009096283465623856\n",
      "Training loss per 100 training steps: 0.006721761543303728\n",
      "Training loss per 100 training steps: 0.01329585202316295\n",
      "Training loss: 0.012305393754387228\n",
      "Training accuracy: 0.9981175682090032\n",
      "Validation loss per 100 evaluation steps: 0.0021382232662290335\n",
      "Validation Loss: 0.0036854409573910136\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0123\n",
      "\t - Validation loss: 0.0037\n",
      "Validation loss decreased (0.005023 --> 0.003685).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005168505012989044\n",
      "Training loss per 100 training steps: 0.0046600008136731125\n",
      "Training loss per 100 training steps: 0.00983525433378359\n",
      "Training loss: 0.009273171046271357\n",
      "Training accuracy: 0.9986413555446697\n",
      "Validation loss per 100 evaluation steps: 0.0016193906776607037\n",
      "Validation Loss: 0.0029353682902486375\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0093\n",
      "\t - Validation loss: 0.0029\n",
      "Validation loss decreased (0.003685 --> 0.002935).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.003595861839130521\n",
      "Training loss per 100 training steps: 0.003574932140464166\n",
      "Training loss per 100 training steps: 0.008890288051991579\n",
      "Training loss: 0.008196169217488877\n",
      "Training accuracy: 0.9988586807184531\n",
      "Validation loss per 100 evaluation steps: 0.001313334796577692\n",
      "Validation Loss: 0.004125640605343506\n",
      "Validation Accuracy: 0.9994791666666667\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0082\n",
      "\t - Validation loss: 0.0041\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0014433965552598238\n",
      "Validation Loss: 0.002339939170633443\n",
      "Validation Accuracy: 0.9997222222222223\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 4/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.643587827682495\n",
      "Training loss per 100 training steps: 0.9098963419547176\n",
      "Training loss per 100 training steps: 0.7714351170617549\n",
      "Training loss: 0.6985806426769045\n",
      "Training accuracy: 0.81228749602983\n",
      "Validation loss per 100 evaluation steps: 0.25341659784317017\n",
      "Validation Loss: 0.18540044464170932\n",
      "Validation Accuracy: 0.9518400521388231\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6986\n",
      "\t - Validation loss: 0.1854\n",
      "Validation loss decreased (0.002935 --> 0.185400).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.18043875694274902\n",
      "Training loss per 100 training steps: 0.11812844107130377\n",
      "Training loss per 100 training steps: 0.11463971009746712\n",
      "Training loss: 0.10433010548791465\n",
      "Training accuracy: 0.9776665878802573\n",
      "Validation loss per 100 evaluation steps: 0.02025429531931877\n",
      "Validation Loss: 0.02313259510944287\n",
      "Validation Accuracy: 0.9993055555555554\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.1043\n",
      "\t - Validation loss: 0.0231\n",
      "Validation loss decreased (0.185400 --> 0.023133).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.020333759486675262\n",
      "Training loss per 100 training steps: 0.02726904636636229\n",
      "Training loss per 100 training steps: 0.03319264942344593\n",
      "Training loss: 0.030982190109163272\n",
      "Training accuracy: 0.9954966152569065\n",
      "Validation loss per 100 evaluation steps: 0.0068802726455032825\n",
      "Validation Loss: 0.007591571686013291\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0310\n",
      "\t - Validation loss: 0.0076\n",
      "Validation loss decreased (0.023133 --> 0.007592).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0094886040315032\n",
      "Training loss per 100 training steps: 0.01015096990446938\n",
      "Training loss per 100 training steps: 0.01590494969535378\n",
      "Training loss: 0.014988936155157931\n",
      "Training accuracy: 0.9988339074097999\n",
      "Validation loss per 100 evaluation steps: 0.0035269183572381735\n",
      "Validation Loss: 0.0046141910211493576\n",
      "Validation Accuracy: 0.9994949494949494\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0150\n",
      "\t - Validation loss: 0.0046\n",
      "Validation loss decreased (0.007592 --> 0.004614).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.007787853479385376\n",
      "Training loss per 100 training steps: 0.005976852965495079\n",
      "Training loss per 100 training steps: 0.01332763564513431\n",
      "Training loss: 0.012435922433403046\n",
      "Training accuracy: 0.9984181413872804\n",
      "Validation loss per 100 evaluation steps: 0.0024469320196658373\n",
      "Validation Loss: 0.023708466494766375\n",
      "Validation Accuracy: 0.9960267183327527\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0124\n",
      "\t - Validation loss: 0.0237\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0035993196070194244\n",
      "Validation Loss: 0.012682968459557742\n",
      "Validation Accuracy: 0.9965257206519773\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 5/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.6410720348358154\n",
      "Training loss per 100 training steps: 0.8543326244643419\n",
      "Training loss per 100 training steps: 0.724005871077082\n",
      "Training loss: 0.6588967548949378\n",
      "Training accuracy: 0.8213723998841206\n",
      "Validation loss per 100 evaluation steps: 0.0910223051905632\n",
      "Validation Loss: 0.13996939472854136\n",
      "Validation Accuracy: 0.9735884616079616\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6589\n",
      "\t - Validation loss: 0.1400\n",
      "Validation loss decreased (0.004614 --> 0.139969).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.20809149742126465\n",
      "Training loss per 100 training steps: 0.09596482954808686\n",
      "Training loss per 100 training steps: 0.10042278644216446\n",
      "Training loss: 0.09173522558564148\n",
      "Training accuracy: 0.9800930643855453\n",
      "Validation loss per 100 evaluation steps: 0.014104143716394901\n",
      "Validation Loss: 0.023555472951071958\n",
      "Validation Accuracy: 0.9978233421168203\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0917\n",
      "\t - Validation loss: 0.0236\n",
      "Validation loss decreased (0.139969 --> 0.023555).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.017534947022795677\n",
      "Training loss per 100 training steps: 0.0235368143490488\n",
      "Training loss per 100 training steps: 0.033262763211772364\n",
      "Training loss: 0.031092582362461367\n",
      "Training accuracy: 0.9945284173655191\n",
      "Validation loss per 100 evaluation steps: 0.004415952134877443\n",
      "Validation Loss: 0.007845315694188079\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0311\n",
      "\t - Validation loss: 0.0078\n",
      "Validation loss decreased (0.023555 --> 0.007845).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009397774934768677\n",
      "Training loss per 100 training steps: 0.011164541395454862\n",
      "Training loss per 100 training steps: 0.01892973068726263\n",
      "Training loss: 0.0175555918156365\n",
      "Training accuracy: 0.9972822253664396\n",
      "Validation loss per 100 evaluation steps: 0.002321334322914481\n",
      "Validation Loss: 0.004445563035551459\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0176\n",
      "\t - Validation loss: 0.0044\n",
      "Validation loss decreased (0.007845 --> 0.004446).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006928912829607725\n",
      "Training loss per 100 training steps: 0.00689719382691944\n",
      "Training loss per 100 training steps: 0.013489477656114458\n",
      "Training loss: 0.012913562490471773\n",
      "Training accuracy: 0.9978081943102561\n",
      "Validation loss per 100 evaluation steps: 0.0016651848563924432\n",
      "Validation Loss: 0.006673847191268578\n",
      "Validation Accuracy: 0.9982030651340995\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0129\n",
      "\t - Validation loss: 0.0067\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0018074269173666835\n",
      "Validation Loss: 0.005484775486790264\n",
      "Validation Accuracy: 0.9994350282485875\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 6/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.711784601211548\n",
      "Training loss per 100 training steps: 0.9186089011554671\n",
      "Training loss per 100 training steps: 0.7439759078607038\n",
      "Training loss: 0.6736841584641894\n",
      "Training accuracy: 0.8124087433187126\n",
      "Validation loss per 100 evaluation steps: 0.09654489159584045\n",
      "Validation Loss: 0.12248709245274464\n",
      "Validation Accuracy: 0.978490694355518\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6737\n",
      "\t - Validation loss: 0.1225\n",
      "Validation loss decreased (0.004446 --> 0.122487).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.13097745180130005\n",
      "Training loss per 100 training steps: 0.08977446283702509\n",
      "Training loss per 100 training steps: 0.0946773695736308\n",
      "Training loss: 0.08661380063100647\n",
      "Training accuracy: 0.9826135952188528\n",
      "Validation loss per 100 evaluation steps: 0.013533656485378742\n",
      "Validation Loss: 0.017621773264060416\n",
      "Validation Accuracy: 0.9993055555555554\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0866\n",
      "\t - Validation loss: 0.0176\n",
      "Validation loss decreased (0.122487 --> 0.017622).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.017557138577103615\n",
      "Training loss per 100 training steps: 0.019353401215544137\n",
      "Training loss per 100 training steps: 0.029638813910496175\n",
      "Training loss: 0.028052324973078083\n",
      "Training accuracy: 0.995585534777107\n",
      "Validation loss per 100 evaluation steps: 0.0060171824879944324\n",
      "Validation Loss: 0.007012996566481888\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0281\n",
      "\t - Validation loss: 0.0070\n",
      "Validation loss decreased (0.017622 --> 0.007013).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009348200634121895\n",
      "Training loss per 100 training steps: 0.00995897029130028\n",
      "Training loss per 100 training steps: 0.017553411365083572\n",
      "Training loss: 0.0164034097668707\n",
      "Training accuracy: 0.9977082165792202\n",
      "Validation loss per 100 evaluation steps: 0.0028527574613690376\n",
      "Validation Loss: 0.004189013437523196\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0164\n",
      "\t - Validation loss: 0.0042\n",
      "Validation loss decreased (0.007013 --> 0.004189).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006807086523622274\n",
      "Training loss per 100 training steps: 0.009067844989073306\n",
      "Training loss per 100 training steps: 0.01454345410601676\n",
      "Training loss: 0.013256299181277825\n",
      "Training accuracy: 0.9979202973331872\n",
      "Validation loss per 100 evaluation steps: 0.0019067967077717185\n",
      "Validation Loss: 0.0031916767669220767\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0133\n",
      "\t - Validation loss: 0.0032\n",
      "Validation loss decreased (0.004189 --> 0.003192).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005858845077455044\n",
      "Training loss per 100 training steps: 0.004210461359839923\n",
      "Training loss per 100 training steps: 0.011866224488354664\n",
      "Training loss: 0.010793829673290754\n",
      "Training accuracy: 0.9983190783186043\n",
      "Validation loss per 100 evaluation steps: 0.0014340217458084226\n",
      "Validation Loss: 0.0032430029202563065\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0108\n",
      "\t - Validation loss: 0.0032\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0022701798006892204\n",
      "Validation Loss: 0.005254827678436413\n",
      "Validation Accuracy: 0.9990706774272439\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 7/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.620680809020996\n",
      "Training loss per 100 training steps: 0.9129772236441621\n",
      "Training loss per 100 training steps: 0.7639076308676259\n",
      "Training loss: 0.6883752761142594\n",
      "Training accuracy: 0.811555092964329\n",
      "Validation loss per 100 evaluation steps: 0.1218174397945404\n",
      "Validation Loss: 0.13753980174660682\n",
      "Validation Accuracy: 0.9795440866046208\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6884\n",
      "\t - Validation loss: 0.1375\n",
      "Validation loss decreased (0.003192 --> 0.137540).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.20822390913963318\n",
      "Training loss per 100 training steps: 0.10314855166701692\n",
      "Training loss per 100 training steps: 0.10151790190413965\n",
      "Training loss: 0.09211155547987387\n",
      "Training accuracy: 0.9816587951518605\n",
      "Validation loss per 100 evaluation steps: 0.022626908496022224\n",
      "Validation Loss: 0.027296427870169282\n",
      "Validation Accuracy: 0.9935827531276178\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0921\n",
      "\t - Validation loss: 0.0273\n",
      "Validation loss decreased (0.137540 --> 0.027296).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.021439267322421074\n",
      "Training loss per 100 training steps: 0.022473995108157396\n",
      "Training loss per 100 training steps: 0.028946861684952505\n",
      "Training loss: 0.027121960703956605\n",
      "Training accuracy: 0.9965337404629967\n",
      "Validation loss per 100 evaluation steps: 0.007340966258198023\n",
      "Validation Loss: 0.010754898380643379\n",
      "Validation Accuracy: 0.9988876529477196\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0271\n",
      "\t - Validation loss: 0.0108\n",
      "Validation loss decreased (0.027296 --> 0.010755).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009278560057282448\n",
      "Training loss per 100 training steps: 0.012689788947988412\n",
      "Training loss per 100 training steps: 0.016981752575444643\n",
      "Training loss: 0.01571123637532925\n",
      "Training accuracy: 0.9979089170235791\n",
      "Validation loss per 100 evaluation steps: 0.003511791815981269\n",
      "Validation Loss: 0.004375529409541438\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0157\n",
      "\t - Validation loss: 0.0044\n",
      "Validation loss decreased (0.010755 --> 0.004376).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.006564553361386061\n",
      "Training loss per 100 training steps: 0.0072658337873987636\n",
      "Training loss per 100 training steps: 0.013133430009040593\n",
      "Training loss: 0.01209117118817042\n",
      "Training accuracy: 0.9983695457177478\n",
      "Validation loss per 100 evaluation steps: 0.0022789526265114546\n",
      "Validation Loss: 0.003156291813744853\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0121\n",
      "\t - Validation loss: 0.0032\n",
      "Validation loss decreased (0.004376 --> 0.003156).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0048814741894602776\n",
      "Training loss per 100 training steps: 0.004619741376655379\n",
      "Training loss per 100 training steps: 0.010140179251019486\n",
      "Training loss: 0.009258067501442773\n",
      "Training accuracy: 0.998624802727322\n",
      "Validation loss per 100 evaluation steps: 0.0016360743902623653\n",
      "Validation Loss: 0.0021994070906657726\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0093\n",
      "\t - Validation loss: 0.0022\n",
      "Validation loss decreased (0.003156 --> 0.002199).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0036209269892424345\n",
      "Training loss per 100 training steps: 0.0034265361108475985\n",
      "Training loss per 100 training steps: 0.00833311834689971\n",
      "Training loss: 0.007827654591968925\n",
      "Training accuracy: 0.9985998261979461\n",
      "Validation loss per 100 evaluation steps: 0.0014188614441081882\n",
      "Validation Loss: 0.0023438978280561668\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0078\n",
      "\t - Validation loss: 0.0023\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0014723845524713397\n",
      "Validation Loss: 0.0060824881666727984\n",
      "Validation Accuracy: 0.9989271871539314\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 8/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.548401355743408\n",
      "Training loss per 100 training steps: 0.9141601222281409\n",
      "Training loss per 100 training steps: 0.7634474820091357\n",
      "Training loss: 0.690120298008458\n",
      "Training accuracy: 0.8095958838285581\n",
      "Validation loss per 100 evaluation steps: 0.1195816621184349\n",
      "Validation Loss: 0.17158317491412162\n",
      "Validation Accuracy: 0.9704062740512929\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6901\n",
      "\t - Validation loss: 0.1716\n",
      "Validation loss decreased (0.002199 --> 0.171583).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.17681828141212463\n",
      "Training loss per 100 training steps: 0.1029561783583595\n",
      "Training loss per 100 training steps: 0.10599165180911176\n",
      "Training loss: 0.09663896068554967\n",
      "Training accuracy: 0.9807987940087609\n",
      "Validation loss per 100 evaluation steps: 0.014438383281230927\n",
      "Validation Loss: 0.021185781465222438\n",
      "Validation Accuracy: 0.9985119047619048\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0966\n",
      "\t - Validation loss: 0.0212\n",
      "Validation loss decreased (0.171583 --> 0.021186).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.01527749840170145\n",
      "Training loss per 100 training steps: 0.02032340771638521\n",
      "Training loss per 100 training steps: 0.03018296543341964\n",
      "Training loss: 0.028266089952730833\n",
      "Training accuracy: 0.9963203411525111\n",
      "Validation loss per 100 evaluation steps: 0.004692344926297665\n",
      "Validation Loss: 0.006571889738552272\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0283\n",
      "\t - Validation loss: 0.0066\n",
      "Validation loss decreased (0.021186 --> 0.006572).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.008349192328751087\n",
      "Training loss per 100 training steps: 0.00894170765543707\n",
      "Training loss per 100 training steps: 0.016979575468764746\n",
      "Training loss: 0.01578658474159247\n",
      "Training accuracy: 0.9981263254951522\n",
      "Validation loss per 100 evaluation steps: 0.002410487039014697\n",
      "Validation Loss: 0.0039870738633908335\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0158\n",
      "\t - Validation loss: 0.0040\n",
      "Validation loss decreased (0.006572 --> 0.003987).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.007587976288050413\n",
      "Training loss per 100 training steps: 0.005567243170583307\n",
      "Training loss per 100 training steps: 0.012968915024661083\n",
      "Training loss: 0.012016441153573702\n",
      "Training accuracy: 0.9983987368385197\n",
      "Validation loss per 100 evaluation steps: 0.0017049722373485565\n",
      "Validation Loss: 0.003080506717863803\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0120\n",
      "\t - Validation loss: 0.0031\n",
      "Validation loss decreased (0.003987 --> 0.003081).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.007245584856718779\n",
      "Training loss per 100 training steps: 0.004130984319945668\n",
      "Training loss per 100 training steps: 0.009868900294517589\n",
      "Training loss: 0.009238689117027963\n",
      "Training accuracy: 0.9988405259722224\n",
      "Validation loss per 100 evaluation steps: 0.0013575004413723946\n",
      "Validation Loss: 0.0025612289163594445\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0092\n",
      "\t - Validation loss: 0.0026\n",
      "Validation loss decreased (0.003081 --> 0.002561).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.003426402108743787\n",
      "Training loss per 100 training steps: 0.007176560310573124\n",
      "Training loss per 100 training steps: 0.01091066029719749\n",
      "Training loss: 0.009830150283685252\n",
      "Training accuracy: 0.9982834229740319\n",
      "Validation loss per 100 evaluation steps: 0.0011997490655630827\n",
      "Validation Loss: 0.002419311588164419\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0098\n",
      "\t - Validation loss: 0.0024\n",
      "Validation loss decreased (0.002561 --> 0.002419).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0031235720962285995\n",
      "Training loss per 100 training steps: 0.0030885742882746136\n",
      "Training loss per 100 training steps: 0.007044145583745037\n",
      "Training loss: 0.006442163357738124\n",
      "Training accuracy: 0.9990374848174941\n",
      "Validation loss per 100 evaluation steps: 0.0009250870789401233\n",
      "Validation Loss: 0.0017111559718614444\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 8/100\n",
      "\t - Training loss: 0.0064\n",
      "\t - Validation loss: 0.0017\n",
      "Validation loss decreased (0.002419 --> 0.001711).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.002645566826686263\n",
      "Training loss per 100 training steps: 0.0030118759806811958\n",
      "Training loss per 100 training steps: 0.005733843835473839\n",
      "Training loss: 0.005256714975801805\n",
      "Training accuracy: 0.9991473245304705\n",
      "Validation loss per 100 evaluation steps: 0.0008239764720201492\n",
      "Validation Loss: 0.003883383088395931\n",
      "Validation Accuracy: 0.9989415322580645\n",
      "*****\n",
      "Epoch 9/100\n",
      "\t - Training loss: 0.0053\n",
      "\t - Validation loss: 0.0039\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0008263228228315711\n",
      "Validation Loss: 0.001316837060827917\n",
      "Validation Accuracy: 0.9997076023391813\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 9/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.660893201828003\n",
      "Training loss per 100 training steps: 0.888359938222583\n",
      "Training loss per 100 training steps: 0.7507915377097937\n",
      "Training loss: 0.6748183004620696\n",
      "Training accuracy: 0.8157483795734982\n",
      "Validation loss per 100 evaluation steps: 0.14398081600666046\n",
      "Validation Loss: 0.15617321773121753\n",
      "Validation Accuracy: 0.9683789291292816\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6748\n",
      "\t - Validation loss: 0.1562\n",
      "Validation loss decreased (0.001711 --> 0.156173).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.13406157493591309\n",
      "Training loss per 100 training steps: 0.10286540174764572\n",
      "Training loss per 100 training steps: 0.10546370802345265\n",
      "Training loss: 0.09604922397954374\n",
      "Training accuracy: 0.9804374772966432\n",
      "Validation loss per 100 evaluation steps: 0.01987615041434765\n",
      "Validation Loss: 0.030648614489473404\n",
      "Validation Accuracy: 0.9948812083973374\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0960\n",
      "\t - Validation loss: 0.0306\n",
      "Validation loss decreased (0.156173 --> 0.030649).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.017215153202414513\n",
      "Training loss per 100 training steps: 0.025342213165125634\n",
      "Training loss per 100 training steps: 0.033823477064921934\n",
      "Training loss: 0.031534879484033884\n",
      "Training accuracy: 0.9945671179315974\n",
      "Validation loss per 100 evaluation steps: 0.005884621292352676\n",
      "Validation Loss: 0.011544480128213764\n",
      "Validation Accuracy: 0.9972363031234\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0315\n",
      "\t - Validation loss: 0.0115\n",
      "Validation loss decreased (0.030649 --> 0.011544).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.009661803022027016\n",
      "Training loss per 100 training steps: 0.010355739400141162\n",
      "Training loss per 100 training steps: 0.019369584846481755\n",
      "Training loss: 0.018066269545150653\n",
      "Training accuracy: 0.9974310563458785\n",
      "Validation loss per 100 evaluation steps: 0.0031706523150205612\n",
      "Validation Loss: 0.009321449153746168\n",
      "Validation Accuracy: 0.9972363031234\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0181\n",
      "\t - Validation loss: 0.0093\n",
      "Validation loss decreased (0.011544 --> 0.009321).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.00810927152633667\n",
      "Training loss per 100 training steps: 0.007341569010629365\n",
      "Training loss per 100 training steps: 0.01408861069569355\n",
      "Training loss: 0.012997732569166153\n",
      "Training accuracy: 0.9977771753097706\n",
      "Validation loss per 100 evaluation steps: 0.0019886710215359926\n",
      "Validation Loss: 0.006208148649117599\n",
      "Validation Accuracy: 0.9977918586789555\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0130\n",
      "\t - Validation loss: 0.0062\n",
      "Validation loss decreased (0.009321 --> 0.006208).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005586931947618723\n",
      "Training loss per 100 training steps: 0.004824192921335966\n",
      "Training loss per 100 training steps: 0.01021429951203088\n",
      "Training loss: 0.009405635648990097\n",
      "Training accuracy: 0.9986772556084035\n",
      "Validation loss per 100 evaluation steps: 0.001583041506819427\n",
      "Validation Loss: 0.0027332616756514955\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0094\n",
      "\t - Validation loss: 0.0027\n",
      "Validation loss decreased (0.006208 --> 0.002733).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.004042362328618765\n",
      "Training loss per 100 training steps: 0.003624203172281827\n",
      "Training loss per 100 training steps: 0.0072209054033100534\n",
      "Training loss: 0.006688151360360295\n",
      "Training accuracy: 0.9989087982505145\n",
      "Validation loss per 100 evaluation steps: 0.0012091288808733225\n",
      "Validation Loss: 0.004376491419194887\n",
      "Validation Accuracy: 0.9994444444444445\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0067\n",
      "\t - Validation loss: 0.0044\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.0017142262076959014\n",
      "Validation Loss: 0.0024507679724289724\n",
      "Validation Accuracy: 0.999344739716054\n",
      "\n",
      "********** \tCROSS-VAL iteration with fold 10/10\t **********\n",
      "Train size: 1904\n",
      "Validation size: 238\n",
      "Test size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training started with max_epochs= 100...\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 2.7715253829956055\n",
      "Training loss per 100 training steps: 0.9283967268939065\n",
      "Training loss per 100 training steps: 0.7359226822334143\n",
      "Training loss: 0.6648078494462646\n",
      "Training accuracy: 0.8221335826395535\n",
      "Validation loss per 100 evaluation steps: 0.1689964085817337\n",
      "Validation Loss: 0.13543000780045986\n",
      "Validation Accuracy: 0.976124599232547\n",
      "*****\n",
      "Epoch 1/100\n",
      "\t - Training loss: 0.6648\n",
      "\t - Validation loss: 0.1354\n",
      "Validation loss decreased (0.002733 --> 0.135430).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.10209963470697403\n",
      "Training loss per 100 training steps: 0.1008529950228363\n",
      "Training loss per 100 training steps: 0.10165592231115891\n",
      "Training loss: 0.09272944945215929\n",
      "Training accuracy: 0.9794953068707053\n",
      "Validation loss per 100 evaluation steps: 0.017541248351335526\n",
      "Validation Loss: 0.021879342718360326\n",
      "Validation Accuracy: 0.9978562801932368\n",
      "*****\n",
      "Epoch 2/100\n",
      "\t - Training loss: 0.0927\n",
      "\t - Validation loss: 0.0219\n",
      "Validation loss decreased (0.135430 --> 0.021879).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.09590568393468857\n",
      "Training loss per 100 training steps: 0.022431933145859454\n",
      "Training loss per 100 training steps: 0.03211742988440083\n",
      "Training loss: 0.029868595415585432\n",
      "Training accuracy: 0.9955513361818209\n",
      "Validation loss per 100 evaluation steps: 0.006211357656866312\n",
      "Validation Loss: 0.007180386226779471\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 3/100\n",
      "\t - Training loss: 0.0299\n",
      "\t - Validation loss: 0.0072\n",
      "Validation loss decreased (0.021879 --> 0.007180).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.008807847276329994\n",
      "Training loss per 100 training steps: 0.009354360913396767\n",
      "Training loss per 100 training steps: 0.017092202146032555\n",
      "Training loss: 0.015849682150267753\n",
      "Training accuracy: 0.9982050065377398\n",
      "Validation loss per 100 evaluation steps: 0.003505811095237732\n",
      "Validation Loss: 0.004104202764574438\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 4/100\n",
      "\t - Training loss: 0.0158\n",
      "\t - Validation loss: 0.0041\n",
      "Validation loss decreased (0.007180 --> 0.004104).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.007019398733973503\n",
      "Training loss per 100 training steps: 0.006080479640052608\n",
      "Training loss per 100 training steps: 0.013021308123666923\n",
      "Training loss: 0.012016115654377314\n",
      "Training accuracy: 0.9983922106826663\n",
      "Validation loss per 100 evaluation steps: 0.0024884392041713\n",
      "Validation Loss: 0.0032276105543132872\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 5/100\n",
      "\t - Training loss: 0.0120\n",
      "\t - Validation loss: 0.0032\n",
      "Validation loss decreased (0.004104 --> 0.003228).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.005317653063684702\n",
      "Training loss per 100 training steps: 0.005125176864630073\n",
      "Training loss per 100 training steps: 0.010051793394499083\n",
      "Training loss: 0.009372625697576324\n",
      "Training accuracy: 0.9986228061186793\n",
      "Validation loss per 100 evaluation steps: 0.0018526710337027907\n",
      "Validation Loss: 0.002545850941290458\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 6/100\n",
      "\t - Training loss: 0.0094\n",
      "\t - Validation loss: 0.0025\n",
      "Validation loss decreased (0.003228 --> 0.002546).  Saving model ...\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Training loss per 100 training steps: 0.0038876303005963564\n",
      "Training loss per 100 training steps: 0.003632182125140461\n",
      "Training loss per 100 training steps: 0.00893033054293555\n",
      "Training loss: 0.008161558104902036\n",
      "Training accuracy: 0.9988007483979945\n",
      "Validation loss per 100 evaluation steps: 0.0014705476351082325\n",
      "Validation Loss: 0.002777068536185349\n",
      "Validation Accuracy: 1.0\n",
      "*****\n",
      "Epoch 7/100\n",
      "\t - Training loss: 0.0082\n",
      "\t - Validation loss: 0.0028\n",
      "EarlyStopping counter: 1 out of 0\n",
      "\n",
      "\n",
      "Early stopping\n",
      "Validation loss per 100 evaluation steps: 0.001289637410081923\n",
      "Validation Loss: 0.007209059520391747\n",
      "Validation Accuracy: 0.9989550679205852\n",
      "CPU times: user 2h 7min 6s, sys: 47 s, total: 2h 7min 53s\n",
      "Wall time: 2h 12min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mep_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_built_obj seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ordinal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_loc_space seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/mehrzad/anaconda3/envs/transformers-book/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, model_name=str):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\\n\\n')\n",
    "        torch.save(model.state_dict(), f'checkpoints/{self.model_name}.pt')\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "\n",
    "        \n",
    "          \n",
    "MAX_LEN = 150\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "PATIENCE = 0\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0}\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Device:  {device}\\n\\n\")\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "early_stopping = EarlyStopping(patience=PATIENCE, verbose=True, model_name='bert_base')\n",
    "\n",
    "\n",
    "\n",
    "train_losses, val_losses, test_report_bert = [], [], []\n",
    "\n",
    "history_bert = {}\n",
    "\n",
    "\n",
    "seeds = [0, 42, 123]\n",
    "n_splits = 10\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "for seed in seeds:\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    print(\"\\n\"*3+\"#\"*30,f\"\\t  Running KFold with seed {seed}\\t\", \"#\"*30+\"\\n\")\n",
    "    \n",
    "    \n",
    "    # set random seed \n",
    "    np.random.seed(seed)  \n",
    "    torch.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for i, (not_test_idx, test_idx) in enumerate(kf.split(data)):\n",
    "        test_data = data.iloc[test_idx]\n",
    "        \n",
    "        # Keep remaining data for training + validation\n",
    "        not_test_data = data.iloc[not_test_idx]\n",
    "        \n",
    "        val_size = len(test_data)\n",
    "        val_data = not_test_data.iloc[:val_size]\n",
    "        train_data = not_test_data.iloc[val_size:]\n",
    "        \n",
    "        print(\"\\n\"+\"*\"*10, f'\\tCROSS-VAL iteration with fold {i+1}/{n_splits}\\t', \"*\"*10)\n",
    "        print(\"Train size:\", len(train_data))\n",
    "        print(\"Validation size:\", len(val_data))\n",
    "        print(\"Test size:\", len(test_data))\n",
    "        \n",
    "           \n",
    "        training_set = dataset(train_data.reset_index(drop=True), tokenizer, MAX_LEN)\n",
    "        validation_set = dataset(val_data.reset_index(drop=True), tokenizer, MAX_LEN)\n",
    "        test_set = dataset(test_data.reset_index(drop=True), tokenizer, MAX_LEN)\n",
    "\n",
    "\n",
    "        training_loader = DataLoader(training_set, **train_params)\n",
    "        validation_loader = DataLoader(validation_set, **test_params)\n",
    "        test_loader = DataLoader(test_set, **test_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # load fresh base model for new fold validation\n",
    "        model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        early_stopping.reset()\n",
    "\n",
    "        \n",
    "        \n",
    "        # train/eval loop\n",
    "        print(f\"\\n\\nTraining started with max_epochs= {EPOCHS}...\\n \\n\")\n",
    "        \n",
    "        for epoch in range(1, EPOCHS + 1):\n",
    "\n",
    "            print(\"-\"*40)\n",
    "            train_loss = train(epoch, training_loader)\n",
    "            val_loss = valid(model, validation_loader)[2] \n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            print(\n",
    "                f'*****\\nEpoch {epoch}/{EPOCHS}\\n\\t - Training loss: {train_loss:.4f}\\n\\t - Validation loss: {val_loss:.4f}'\n",
    "            )\n",
    "\n",
    "\n",
    "            # Check early stopping\n",
    "            early_stopping(val_loss, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"\\n\\nEarly stopping\")\n",
    "\n",
    "                # Compute metrics for the final test set\n",
    "                labels, predictions, test_loss = valid(model, test_loader)  \n",
    "                test_report_bert.append(classification_report([labels], [predictions], digits=4))\n",
    "#                 history_bert[f'Fold {i+1}']={'train_loss':[train_losses], 'val_loss':[val_losses]}\n",
    "                history_bert[f'seed{seed}/fold{i+1}']={'train_loss':[train_losses], 'val_loss':[val_losses]}\n",
    "\n",
    "                break\n",
    "\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c3ff710",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000       100\n",
      "  _loc_level     1.0000    1.0000    1.0000        60\n",
      "  _loc_space     1.0000    1.0000    1.0000        86\n",
      "    _mep_obj     0.9955    0.9778    0.9865       225\n",
      "       _name     1.0000    1.0000    1.0000       198\n",
      "     _number     1.0000    1.0000    1.0000        28\n",
      "    _ordinal     1.0000    1.0000    1.0000        43\n",
      "   _quantity     1.0000    1.0000    1.0000       159\n",
      "\n",
      "   micro avg     0.9989    0.9944    0.9967       899\n",
      "   macro avg     0.9994    0.9972    0.9983       899\n",
      "weighted avg     0.9989    0.9944    0.9966       899\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        91\n",
      "  _loc_level     1.0000    1.0000    1.0000        69\n",
      "  _loc_space     1.0000    1.0000    1.0000        86\n",
      "    _mep_obj     0.9910    0.9955    0.9932       221\n",
      "       _name     1.0000    1.0000    1.0000       209\n",
      "     _number     0.9600    1.0000    0.9796        24\n",
      "    _ordinal     1.0000    1.0000    1.0000        61\n",
      "   _quantity     1.0000    0.9934    0.9967       152\n",
      "\n",
      "   micro avg     0.9967    0.9978    0.9973       913\n",
      "   macro avg     0.9939    0.9986    0.9962       913\n",
      "weighted avg     0.9968    0.9978    0.9973       913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        97\n",
      "  _loc_level     1.0000    1.0000    1.0000        59\n",
      "  _loc_space     1.0000    1.0000    1.0000       102\n",
      "    _mep_obj     0.9957    0.9915    0.9936       235\n",
      "       _name     1.0000    1.0000    1.0000       214\n",
      "     _number     1.0000    1.0000    1.0000        29\n",
      "    _ordinal     1.0000    1.0000    1.0000        38\n",
      "   _quantity     1.0000    1.0000    1.0000       146\n",
      "\n",
      "   micro avg     0.9989    0.9978    0.9984       920\n",
      "   macro avg     0.9995    0.9989    0.9992       920\n",
      "weighted avg     0.9989    0.9978    0.9984       920\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000       107\n",
      "  _loc_level     1.0000    1.0000    1.0000        55\n",
      "  _loc_space     1.0000    1.0000    1.0000        97\n",
      "    _mep_obj     0.9848    0.9700    0.9773       200\n",
      "       _name     1.0000    1.0000    1.0000       213\n",
      "     _number     1.0000    1.0000    1.0000        26\n",
      "    _ordinal     1.0000    1.0000    1.0000        44\n",
      "   _quantity     1.0000    1.0000    1.0000       142\n",
      "\n",
      "   micro avg     0.9966    0.9932    0.9949       884\n",
      "   macro avg     0.9981    0.9962    0.9972       884\n",
      "weighted avg     0.9966    0.9932    0.9949       884\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        86\n",
      "  _loc_level     1.0000    1.0000    1.0000        59\n",
      "  _loc_space     1.0000    1.0000    1.0000        89\n",
      "    _mep_obj     0.9869    0.9741    0.9805       232\n",
      "       _name     1.0000    1.0000    1.0000       194\n",
      "     _number     1.0000    1.0000    1.0000        21\n",
      "    _ordinal     1.0000    1.0000    1.0000        51\n",
      "   _quantity     1.0000    1.0000    1.0000       150\n",
      "\n",
      "   micro avg     0.9966    0.9932    0.9949       882\n",
      "   macro avg     0.9984    0.9968    0.9976       882\n",
      "weighted avg     0.9966    0.9932    0.9949       882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        95\n",
      "  _loc_level     1.0000    1.0000    1.0000        59\n",
      "  _loc_space     1.0000    1.0000    1.0000        90\n",
      "    _mep_obj     0.9860    0.9769    0.9814       216\n",
      "       _name     1.0000    1.0000    1.0000       222\n",
      "     _number     1.0000    1.0000    1.0000        28\n",
      "    _ordinal     1.0000    1.0000    1.0000        38\n",
      "   _quantity     1.0000    1.0000    1.0000       151\n",
      "\n",
      "   micro avg     0.9967    0.9944    0.9955       899\n",
      "   macro avg     0.9982    0.9971    0.9977       899\n",
      "weighted avg     0.9966    0.9944    0.9955       899\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        87\n",
      "  _loc_level     1.0000    1.0000    1.0000        63\n",
      "  _loc_space     1.0000    1.0000    1.0000        86\n",
      "    _mep_obj     0.9959    0.9918    0.9938       244\n",
      "       _name     1.0000    1.0000    1.0000       212\n",
      "     _number     1.0000    1.0000    1.0000        23\n",
      "    _ordinal     1.0000    1.0000    1.0000        65\n",
      "   _quantity     1.0000    1.0000    1.0000       160\n",
      "\n",
      "   micro avg     0.9989    0.9979    0.9984       940\n",
      "   macro avg     0.9995    0.9990    0.9992       940\n",
      "weighted avg     0.9989    0.9979    0.9984       940\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        81\n",
      "  _loc_level     1.0000    1.0000    1.0000        69\n",
      "  _loc_space     1.0000    1.0000    1.0000        97\n",
      "    _mep_obj     0.9959    0.9918    0.9939       245\n",
      "       _name     1.0000    1.0000    1.0000       172\n",
      "     _number     1.0000    1.0000    1.0000        25\n",
      "    _ordinal     1.0000    1.0000    1.0000        64\n",
      "   _quantity     1.0000    1.0000    1.0000       147\n",
      "\n",
      "   micro avg     0.9989    0.9978    0.9983       900\n",
      "   macro avg     0.9995    0.9990    0.9992       900\n",
      "weighted avg     0.9989    0.9978    0.9983       900\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        97\n",
      "  _loc_level     1.0000    1.0000    1.0000        66\n",
      "  _loc_space     1.0000    1.0000    1.0000        90\n",
      "    _mep_obj     0.9784    0.9784    0.9784       232\n",
      "       _name     1.0000    1.0000    1.0000       225\n",
      "     _number     1.0000    1.0000    1.0000        24\n",
      "    _ordinal     1.0000    1.0000    1.0000        64\n",
      "   _quantity     1.0000    1.0000    1.0000       152\n",
      "\n",
      "   micro avg     0.9947    0.9947    0.9947       950\n",
      "   macro avg     0.9973    0.9973    0.9973       950\n",
      "weighted avg     0.9947    0.9947    0.9947       950\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        85\n",
      "  _loc_level     1.0000    1.0000    1.0000        66\n",
      "  _loc_space     1.0000    1.0000    1.0000       111\n",
      "    _mep_obj     0.9625    0.9545    0.9585       242\n",
      "       _name     1.0000    1.0000    1.0000       253\n",
      "     _number     1.0000    1.0000    1.0000        22\n",
      "    _ordinal     1.0000    1.0000    1.0000        60\n",
      "   _quantity     1.0000    1.0000    1.0000       152\n",
      "\n",
      "   micro avg     0.9909    0.9889    0.9899       991\n",
      "   macro avg     0.9953    0.9943    0.9948       991\n",
      "weighted avg     0.9908    0.9889    0.9899       991\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        95\n",
      "  _loc_level     1.0000    1.0000    1.0000        63\n",
      "  _loc_space     1.0000    1.0000    1.0000        88\n",
      "    _mep_obj     0.9871    0.9703    0.9786       236\n",
      "       _name     1.0000    1.0000    1.0000       206\n",
      "     _number     1.0000    1.0000    1.0000        24\n",
      "    _ordinal     1.0000    1.0000    1.0000        47\n",
      "   _quantity     1.0000    1.0000    1.0000       153\n",
      "\n",
      "   micro avg     0.9967    0.9923    0.9945       912\n",
      "   macro avg     0.9984    0.9963    0.9973       912\n",
      "weighted avg     0.9967    0.9923    0.9945       912\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        88\n",
      "  _loc_level     1.0000    1.0000    1.0000        62\n",
      "  _loc_space     1.0000    1.0000    1.0000        99\n",
      "    _mep_obj     1.0000    1.0000    1.0000       218\n",
      "       _name     1.0000    1.0000    1.0000       188\n",
      "     _number     1.0000    1.0000    1.0000        21\n",
      "    _ordinal     1.0000    1.0000    1.0000        59\n",
      "   _quantity     1.0000    1.0000    1.0000       157\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000       892\n",
      "   macro avg     1.0000    1.0000    1.0000       892\n",
      "weighted avg     1.0000    1.0000    1.0000       892\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        95\n",
      "  _loc_level     1.0000    1.0000    1.0000        57\n",
      "  _loc_space     1.0000    1.0000    1.0000        78\n",
      "    _mep_obj     0.9689    0.9646    0.9667       226\n",
      "       _name     1.0000    1.0000    1.0000       186\n",
      "     _number     1.0000    1.0000    1.0000        19\n",
      "    _ordinal     1.0000    1.0000    1.0000        57\n",
      "   _quantity     1.0000    1.0000    1.0000       150\n",
      "\n",
      "   micro avg     0.9919    0.9908    0.9914       868\n",
      "   macro avg     0.9961    0.9956    0.9958       868\n",
      "weighted avg     0.9919    0.9908    0.9913       868\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        88\n",
      "  _loc_level     1.0000    1.0000    1.0000        71\n",
      "  _loc_space     1.0000    1.0000    1.0000       100\n",
      "    _mep_obj     0.9921    0.9843    0.9882       255\n",
      "       _name     1.0000    1.0000    1.0000       234\n",
      "     _number     1.0000    1.0000    1.0000        27\n",
      "    _ordinal     1.0000    1.0000    1.0000        62\n",
      "   _quantity     1.0000    1.0000    1.0000       146\n",
      "\n",
      "   micro avg     0.9980    0.9959    0.9969       983\n",
      "   macro avg     0.9990    0.9980    0.9985       983\n",
      "weighted avg     0.9979    0.9959    0.9969       983\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     0.9785    0.9785    0.9785        93\n",
      "  _loc_level     1.0000    1.0000    1.0000        70\n",
      "  _loc_space     1.0000    1.0000    1.0000        91\n",
      "    _mep_obj     0.9906    0.9813    0.9859       214\n",
      "       _name     1.0000    1.0000    1.0000       217\n",
      "     _number     1.0000    1.0000    1.0000        31\n",
      "    _ordinal     1.0000    1.0000    1.0000        59\n",
      "   _quantity     1.0000    1.0000    1.0000       142\n",
      "\n",
      "   micro avg     0.9956    0.9935    0.9945       917\n",
      "   macro avg     0.9961    0.9950    0.9956       917\n",
      "weighted avg     0.9956    0.9935    0.9945       917\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        95\n",
      "  _loc_level     1.0000    1.0000    1.0000        57\n",
      "  _loc_space     1.0000    1.0000    1.0000        96\n",
      "    _mep_obj     0.9862    0.9598    0.9729       224\n",
      "       _name     1.0000    1.0000    1.0000       198\n",
      "     _number     1.0000    1.0000    1.0000        23\n",
      "    _ordinal     1.0000    1.0000    1.0000        48\n",
      "   _quantity     1.0000    1.0000    1.0000       157\n",
      "\n",
      "   micro avg     0.9966    0.9900    0.9933       898\n",
      "   macro avg     0.9983    0.9950    0.9966       898\n",
      "weighted avg     0.9966    0.9900    0.9932       898\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        91\n",
      "  _loc_level     1.0000    1.0000    1.0000        55\n",
      "  _loc_space     1.0000    1.0000    1.0000        97\n",
      "    _mep_obj     0.9820    0.9776    0.9798       223\n",
      "       _name     1.0000    1.0000    1.0000       222\n",
      "     _number     1.0000    1.0000    1.0000        23\n",
      "    _ordinal     1.0000    1.0000    1.0000        37\n",
      "   _quantity     1.0000    1.0000    1.0000       178\n",
      "\n",
      "   micro avg     0.9957    0.9946    0.9951       926\n",
      "   macro avg     0.9977    0.9972    0.9975       926\n",
      "weighted avg     0.9957    0.9946    0.9951       926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        97\n",
      "  _loc_level     1.0000    1.0000    1.0000        59\n",
      "  _loc_space     1.0000    1.0000    1.0000        93\n",
      "    _mep_obj     0.9913    0.9828    0.9871       233\n",
      "       _name     1.0000    1.0000    1.0000       209\n",
      "     _number     1.0000    1.0000    1.0000        27\n",
      "    _ordinal     1.0000    1.0000    1.0000        41\n",
      "   _quantity     1.0000    1.0000    1.0000       138\n",
      "\n",
      "   micro avg     0.9978    0.9955    0.9967       897\n",
      "   macro avg     0.9989    0.9979    0.9984       897\n",
      "weighted avg     0.9978    0.9955    0.9966       897\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        91\n",
      "  _loc_level     1.0000    1.0000    1.0000        59\n",
      "  _loc_space     1.0000    1.0000    1.0000        88\n",
      "    _mep_obj     0.9913    0.9828    0.9870       232\n",
      "       _name     1.0000    1.0000    1.0000       217\n",
      "     _number     1.0000    1.0000    1.0000        26\n",
      "    _ordinal     1.0000    1.0000    1.0000        55\n",
      "   _quantity     1.0000    1.0000    1.0000       145\n",
      "\n",
      "   micro avg     0.9978    0.9956    0.9967       913\n",
      "   macro avg     0.9989    0.9978    0.9984       913\n",
      "weighted avg     0.9978    0.9956    0.9967       913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        93\n",
      "  _loc_level     1.0000    1.0000    1.0000        72\n",
      "  _loc_space     1.0000    1.0000    1.0000       104\n",
      "    _mep_obj     0.9957    0.9913    0.9935       231\n",
      "       _name     1.0000    1.0000    1.0000       235\n",
      "     _number     1.0000    1.0000    1.0000        29\n",
      "    _ordinal     1.0000    1.0000    1.0000        63\n",
      "   _quantity     1.0000    1.0000    1.0000       145\n",
      "\n",
      "   micro avg     0.9990    0.9979    0.9985       972\n",
      "   macro avg     0.9995    0.9989    0.9992       972\n",
      "weighted avg     0.9990    0.9979    0.9985       972\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        89\n",
      "  _loc_level     1.0000    1.0000    1.0000        64\n",
      "  _loc_space     1.0000    1.0000    1.0000        91\n",
      "    _mep_obj     0.9876    0.9675    0.9774       246\n",
      "       _name     1.0000    1.0000    1.0000       220\n",
      "     _number     1.0000    1.0000    1.0000        21\n",
      "    _ordinal     1.0000    1.0000    1.0000        51\n",
      "   _quantity     1.0000    1.0000    1.0000       151\n",
      "\n",
      "   micro avg     0.9968    0.9914    0.9941       933\n",
      "   macro avg     0.9984    0.9959    0.9972       933\n",
      "weighted avg     0.9967    0.9914    0.9940       933\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        88\n",
      "  _loc_level     1.0000    1.0000    1.0000        59\n",
      "  _loc_space     1.0000    1.0000    1.0000        85\n",
      "    _mep_obj     0.9916    0.9834    0.9875       241\n",
      "       _name     1.0000    1.0000    1.0000       192\n",
      "     _number     1.0000    1.0000    1.0000        26\n",
      "    _ordinal     1.0000    1.0000    1.0000        53\n",
      "   _quantity     1.0000    1.0000    1.0000       154\n",
      "\n",
      "   micro avg     0.9978    0.9955    0.9967       898\n",
      "   macro avg     0.9990    0.9979    0.9984       898\n",
      "weighted avg     0.9978    0.9955    0.9966       898\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        97\n",
      "  _loc_level     1.0000    1.0000    1.0000        62\n",
      "  _loc_space     1.0000    1.0000    1.0000       116\n",
      "    _mep_obj     0.9957    0.9915    0.9936       234\n",
      "       _name     1.0000    1.0000    1.0000       246\n",
      "     _number     1.0000    1.0000    1.0000        27\n",
      "    _ordinal     1.0000    1.0000    1.0000        45\n",
      "   _quantity     1.0000    1.0000    1.0000       142\n",
      "\n",
      "   micro avg     0.9990    0.9979    0.9985       969\n",
      "   macro avg     0.9995    0.9989    0.9992       969\n",
      "weighted avg     0.9990    0.9979    0.9984       969\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     0.9867    1.0000    0.9933        74\n",
      "  _loc_level     1.0000    1.0000    1.0000        59\n",
      "  _loc_space     1.0000    1.0000    1.0000        83\n",
      "    _mep_obj     0.9794    0.9444    0.9616       252\n",
      "       _name     1.0000    1.0000    1.0000       190\n",
      "     _number     1.0000    1.0000    1.0000        21\n",
      "    _ordinal     1.0000    1.0000    1.0000        45\n",
      "   _quantity     1.0000    1.0000    1.0000       151\n",
      "\n",
      "   micro avg     0.9931    0.9840    0.9885       875\n",
      "   macro avg     0.9958    0.9931    0.9944       875\n",
      "weighted avg     0.9929    0.9840    0.9884       875\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        88\n",
      "  _loc_level     1.0000    1.0000    1.0000        63\n",
      "  _loc_space     1.0000    1.0000    1.0000        91\n",
      "    _mep_obj     0.9910    0.9822    0.9866       225\n",
      "       _name     1.0000    1.0000    1.0000       187\n",
      "     _number     1.0000    1.0000    1.0000        19\n",
      "    _ordinal     1.0000    1.0000    1.0000        58\n",
      "   _quantity     1.0000    1.0000    1.0000       141\n",
      "\n",
      "   micro avg     0.9977    0.9954    0.9966       872\n",
      "   macro avg     0.9989    0.9978    0.9983       872\n",
      "weighted avg     0.9977    0.9954    0.9965       872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        90\n",
      "  _loc_level     1.0000    1.0000    1.0000        60\n",
      "  _loc_space     1.0000    1.0000    1.0000        99\n",
      "    _mep_obj     0.9871    0.9871    0.9871       233\n",
      "       _name     1.0000    1.0000    1.0000       221\n",
      "     _number     1.0000    1.0000    1.0000        26\n",
      "    _ordinal     1.0000    1.0000    1.0000        49\n",
      "   _quantity     1.0000    1.0000    1.0000       165\n",
      "\n",
      "   micro avg     0.9968    0.9968    0.9968       943\n",
      "   macro avg     0.9984    0.9984    0.9984       943\n",
      "weighted avg     0.9968    0.9968    0.9968       943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        95\n",
      "  _loc_level     1.0000    1.0000    1.0000        66\n",
      "  _loc_space     1.0000    1.0000    1.0000        91\n",
      "    _mep_obj     0.9858    0.9720    0.9788       214\n",
      "       _name     1.0000    1.0000    1.0000       235\n",
      "     _number     1.0000    1.0000    1.0000        27\n",
      "    _ordinal     1.0000    1.0000    1.0000        60\n",
      "   _quantity     1.0000    1.0000    1.0000       158\n",
      "\n",
      "   micro avg     0.9968    0.9937    0.9952       946\n",
      "   macro avg     0.9982    0.9965    0.9974       946\n",
      "weighted avg     0.9968    0.9937    0.9952       946\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000        91\n",
      "  _loc_level     1.0000    1.0000    1.0000        66\n",
      "  _loc_space     1.0000    1.0000    1.0000        97\n",
      "    _mep_obj     0.9907    0.9953    0.9930       214\n",
      "       _name     1.0000    1.0000    1.0000       216\n",
      "     _number     1.0000    1.0000    1.0000        31\n",
      "    _ordinal     1.0000    1.0000    1.0000        55\n",
      "   _quantity     1.0000    1.0000    1.0000       150\n",
      "\n",
      "   micro avg     0.9978    0.9989    0.9984       920\n",
      "   macro avg     0.9988    0.9994    0.9991       920\n",
      "weighted avg     0.9978    0.9989    0.9984       920\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000       101\n",
      "  _loc_level     1.0000    1.0000    1.0000        64\n",
      "  _loc_space     0.9886    1.0000    0.9943        87\n",
      "    _mep_obj     0.9913    0.9913    0.9913       230\n",
      "       _name     1.0000    1.0000    1.0000       209\n",
      "     _number     1.0000    1.0000    1.0000        24\n",
      "    _ordinal     1.0000    1.0000    1.0000        67\n",
      "   _quantity     1.0000    1.0000    1.0000       152\n",
      "\n",
      "   micro avg     0.9968    0.9979    0.9973       934\n",
      "   macro avg     0.9975    0.9989    0.9982       934\n",
      "weighted avg     0.9968    0.9979    0.9973       934\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _built_obj     1.0000    1.0000    1.0000       113\n",
      "  _loc_level     1.0000    1.0000    1.0000        62\n",
      "  _loc_space     1.0000    1.0000    1.0000        94\n",
      "    _mep_obj     0.9850    0.9704    0.9777       203\n",
      "       _name     1.0000    1.0000    1.0000       196\n",
      "     _number     1.0000    1.0000    1.0000        28\n",
      "    _ordinal     1.0000    1.0000    1.0000        45\n",
      "   _quantity     1.0000    1.0000    1.0000       147\n",
      "\n",
      "   micro avg     0.9966    0.9932    0.9949       888\n",
      "   macro avg     0.9981    0.9963    0.9972       888\n",
      "weighted avg     0.9966    0.9932    0.9949       888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for report in test_report_bert: \n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a410109d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique true labels: {'I_ordinal', 'I_loc_space', 'B_mep_obj', 'I_built_obj', 'B_loc_space', 'B_ordinal', 'B_loc_level', 'B_name', 'B_quantity', 'I_mep_obj', 'B_built_obj', 'B_number', 'O'}\n",
      "\n",
      "unique predicted labels: {'I_ordinal', 'I_loc_space', 'B_mep_obj', 'I_built_obj', 'B_loc_space', 'B_ordinal', 'B_loc_level', 'B_name', 'B_quantity', 'I_mep_obj', 'B_built_obj', 'B_number', 'O'}\n",
      "\n",
      "\n",
      "Precision: 0.9969 ± 0.0020\n",
      "Recall: 0.9947 ± 0.0033\n",
      "F1 Score: 0.9958 ± 0.0026\n"
     ]
    }
   ],
   "source": [
    "print(f\"unique true labels: {set(labels)}\\n\")\n",
    "print(f\"unique predicted labels: {set(predictions)}\\n\\n\")\n",
    "\n",
    "\n",
    "def extract_weighted_avg(eval_reports=[]):\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    \n",
    "    pattern = r'weighted avg\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)'\n",
    "    \n",
    "    \n",
    "    for report in eval_reports:\n",
    "        match = re.search(pattern, report)\n",
    "        \n",
    "        if match:           \n",
    "            precision_scores.append(float(match.group(1)))\n",
    "            recall_scores.append(float(match.group(2)))\n",
    "            f1_scores.append(float(match.group(3)))\n",
    "        else:\n",
    "            print('Erro encountered when parsing evaluation report str')\n",
    "            \n",
    "        scores= {'precision':precision_scores, 'recall':recall_scores, 'f1':f1_scores}\n",
    " \n",
    "        \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "scores = extract_weighted_avg(test_report_bert)\n",
    "\n",
    "precision_avg = np.mean(scores['precision'])\n",
    "precision_std = np.std(scores['precision'])\n",
    "\n",
    "recall_avg = np.mean(scores['recall'])\n",
    "recall_std = np.std(scores['recall'])\n",
    "\n",
    "f1_avg = np.mean(scores['f1'])\n",
    "f1_std = np.std(scores['f1'])\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision_avg:.4f} ± {precision_std:.4f}\")\n",
    "print(f\"Recall: {recall_avg:.4f} ± {recall_std:.4f}\")\n",
    "print(f\"F1 Score: {f1_avg:.4f} ± {f1_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2acb2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAJaCAYAAABTFAYQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOy9edwlVXUu/JxzeqIZGhToRuxIVJBBBC8EgkbFaxscojhFrjEyRPCLoR1CuDF8KjjFdkTicCWiSJwC0YvGLyKoRJwgwUCCqIhDhG6E7gaZG3o6p74/6lTV3rv2rjpVtdbau07v5/eDOm+9b9fap4Zde631rGcNkiRJEBERERERERERERERERER4R1D3wOIiIiIiIiIiIiIiIiIiIhIEZ30iIiIiIiIiIiIiIiIiIhAEJ30iIiIiIiIiIiIiIiIiIhAEJ30iIiIiIiIiIiIiIiIiIhAEJ30iIiIiIiIiIiIiIiIiIhAEJ30iIiIiIiIiIiIiIiIiIhAEJ30iIiIiIiIiIiIiIiIiIhAEJ30iIiIiIiIiIiIiIiIiIhAsMD3AKQxmUxw++23Y9ddd8VgMPA9nIiIiIiIiIiIiIiIiIg5R5IkeOCBB/CoRz0Kw2F1rnyHc9Jvv/12rFy50vcwIiIiIiIiIiIiIiIiInYwrFu3Do9+9KMr/2aHc9J33XVXAOnJ2W233TyPJiIiIiIiIiIiIiIiImLecf/992PlypW5P1qFHc5Jzyjuu+22W3TSIyIiIiIiIiIiIiIiIsQwS8l1FI6LiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIiIiIiIiIiIiIiIiAgE0UmPiIhw4l3/8lP87dd+6nsYERERERERERERETsMopMeERFhxUNbt+OT3/81Lvjer7F529j3cCIiIiIiIiIiIiJ2CEQnPSIiwopt4yT/PJ4kFX8ZEREREREREREREUGF6KRHRERYkSSKk55EJz0iIiIiIiIiIiJCAtFJj4iIsEJNnicTf+OIiIiIiIiIiIiI2JEQnfSIiAgrJjGTHhERERER0RhX3rQB/3jtWt/DiIiI6DGikx7BjiRJ8Ks7H8Qk1jX3CpqTHq9dRETEDozzv/MrXPGT9b6HEdET/NUXb8BZl96IOx/Y4nsoERERPUV00iPY8cXrbsOzPvgdXPiDX/seSkQDTBSKexIz6RERETso1v72Ibzn6z/DOf/8E99DiegJHtqSdkR5aOt2zyOJiIjoK6KTHsGOtb99CABw63Qb0Q9EuntEREQE8PC26HBFNEP2/owktIiIiLaITnoEO8b5yyq+rfoE9XrFhUZEhB+c/51f4cQLr8WW7WPfQ9lhkc2F8RUWMSuydU8sFYuIiGiL6KRHsGMSnfReQr1cUU8gIsIPPnvNrfjuz+/Ez+54wPdQdlhkjlZkFEXMgiRJ8vdnLBWLiIhoi+ikR7Aje0dNYhuvXkHNAMQAS0SEH0QH0T/yd1i8BhEzQL1N4nMbERHRFkE46R/72Mew3377YcmSJTj66KNx7bXXOv/22GOPxWAwKP33/Oc/X3DEEU0wiYvMXkJK3f2Bzdvw1Rtux6Ytsd4zIsJEzkSKbBZvKK6B54FE9AKxM0pERAQFvDvpl1xyCc444wycc845uP7663HYYYfhuOOOw8aNG61/f+mll+KOO+7I//vxj3+M0WiEP/7jPxYeecSsGMdFZi+hXi7ODNKnf3ALXv+P/4nP/dutbDYiIvqK7DmMi31/yOa/GGiOmAXqfRJvmYiIiLbw7qSfe+65OO2003DKKafg4IMPxvnnn4+lS5fiwgsvtP79Ix7xCKxYsSL/75vf/CaWLl0anfSAEamC/UQiJBx396at6fahrXxGIiJ6iqgS7R9RVyWiCTS6e3xwIyIiWsKrk75161Zcd911WLVqVb5vOBxi1apVuOaaa2Y6xqc+9Sn8r//1v7Dzzjtbf79lyxbcf//92n8RsiiyEJ4HEtEIYyHKXhKZFhERTkQH0T+yqSlJohBYRD30ziiy98svNjyA+x7aJmozIiKCB16d9Lvuugvj8RjLly/X9i9fvhzr16+v/ffXXnstfvzjH+PUU091/s2aNWuwbNmy/L+VK1d2HndEM8RFZj+h1l9yXruCzstmIiKit8g1PWIQyxsmExlWUcR8QKpUzMRt9zyEPzzvuzjts/8hZjMiIoIP3unuXfCpT30Khx56KI466ijn35x11lm477778v/WrVsnOMIIoHC+Yqa0X9CyAYwO9DgGcSIinIjlQv4hxSqKmA+o94hk8HnD/ZuRJMDt9z4sZzQiIoINXp30PffcE6PRCBs2bND2b9iwAStWrKj8t5s2bcLFF1+MV7/61ZV/t3jxYuy2227afxGyyOiBcXHTL0i1kUnmyEnfvG2M7//iLmzdHmkBETSIQSz/SDxlRiP6icQT3T0mRCIi5gtenfRFixbhiCOOwJVXXpnvm0wmuPLKK3HMMcdU/tsvfvGL2LJlC/70T/+Ue5hecO9DW/Hruzbhzge2+B5KZ0Tho35iLLTQyLL08xDEueC7/40//dS/4+IfrvU9lIg5Qa7pEeM+3uCzxjiif9Do7oLvtbjWioiYL3inu59xxhm44IIL8A//8A+46aab8NrXvhabNm3CKaecAgA48cQTcdZZZ5X+3ac+9Sm86EUvwiMf+UjpIYvgoqtvwTM/cBXO+9bPfQ+lMyaRrtlL6HR3vms3nqOFxYYHNgMANt7f/+BaHZIkwV/90w1Yc9lNvocy14jzp3+oc9M8BBMjeDH2pGEQWwVGRMwXFvgewAknnIA777wTZ599NtavX4/DDz8cl19+eS4mt3btWgyHeizh5ptvxve//3184xvf8DFkEQwHAwDz4bhkDl5cZPYLUi3Y8uj/HNzsuQjeDnCv3/ngFvzf62/DcACc9byDfA9nbpHPn3PwfPQVUTguognUd6fku2AS6e5B4J5NW/Gl627D8Yc/CnvvtsT3cCJ6DO9OOgCsXr0aq1evtv7uqquuKu17whOeMPdtUEbDqZM+B5PtJNak9xJS2aNkjhzbHamd3DgPvqXfezANLEbQImbH/EOKVRQxH/BPd4/3aIbrbr0HKx+xE/beVc5ZvuQ/1uE9X/8ZfrtpK/7muQeK2Y2YP3inu0fYUWTS+z/ZRrpmP6FT9hjp7nPEtJin71IHvc2Qv3HMO4r50+84dmRoAcsd4NmO6AZfGgYxIaLjV3c+iJd+/Gq8/h//U9Tug5u3AwAe2Bz71Ud0Q3TSA8U0kT4XC4KCzux5IBGNILXQmEu6+w5wr6vXKy4KeaDRrOM59oYoHBfRBGNPc2MUjtOx4X4/GjHxOkRQITrpgWIu6e5xcdMraC3YROjubCbEsCPRDaPjwg/1vMZAiD/owRKPA4noBfSWfXJ285r0OB8D8FdKN56jxEOEX0QnPVDMl3Bcup13HYF5g/qi57x080QRz17KO4JDpdPd5//7+kA8x2EgXoeIJoh09zDgK2g+Tzo7EX4RnfRAMY909/ji6BekKHvzSHeXXxQk2LpdNsUXs7z8iGyFMBDv9fnBjbfdh6e+51/x1RtuZ7Ph637ZkZhcsyBPAAizX2JHowgqRCc9UMwX3T3dzgOdeUeCRndnrUmf2piLe93Py/msS2/E7/3tt3DnA3K1d5ECzA99se9xIDs4pIIl40mCW3+7ie34EcDVv7oLv7n3YXz7ZxvZbPjLpKfbeXiXUiDxdD4i3T2CCtFJDxTD4Typu6ffIdLd+wWd7s5Zkz4/Iiu+WCPX3nI37nt4G36x8QExm5ECzI94jsOA7nTx2Xnf5T/DM95/Fb59M58DuaNDwpH19dxGwTId/unuomYj5hDRSQ8UWU36PGRPIt29n9D7pPPZGc8RRa8Q7pG1m506yYy2luWdg2sXIiLdPQyozxXne+zW3z4EAFg73UbQQ8Jx055bwTlZa5sa11ve9G5i2UEEFaKTHihGc9kn3e84IppBqk+6FEXvtnsewh33Pcxqw1d9fXbuJJ3luCDkR2xzFwakWEXjGNBmh0S9sKbnIjgnS5Wo9QW+6P9FLXx41+DBLdsjq7VHiE56oJgnunviyXGJ6IZEKIuXCESdt2wf43l/9z288KM/YL0PfbUb9BEc8NVmaEfCJJ7jICDFGpGYC7nw2Wtuwdu++pPgHQAJx02bGz0Ix5mfQ8S9D23FD355l8z7WHjyDFUb4Df3Powj3vlN/NUXb/A9lIgZEZ30QJGruwf2kLeBjyzfrLjlrk14eOvY9zCChFRdnQQlbdOWMe7fvB13PrAF2xj5h75ezj7UZMdCjsuODJ02G88xAHzye/+N1V+4Xlg1u/jMabfP7Sg/+M2f46Krb8Hau8Om6hdsBT4bUhoGJnR2k5zdNjjnqz/BKz/57/i3//4tm41CD4nNhN1uoM/xrzY+iC3bJ/jJb+73PZSIGRGd9EAxmqNMeqj1Ob/c+CCO/cBVeP3F/+l7KEFCSlm6yALz25CyI74o8BAciA4kPzS6e2Dzpy9c8L3/xr/86A78fIOkSKJKd+e0k277qEWTtYDcFvjgk3yO5i/hAiLd3YUN928GAGxk7EhSdBbyVZMuarYW86T/s6MgOumBYpDVpIf9vpsJeU16YDPWbfekEf91gUf+fUHKCZN4kUrRVXPWiDi9Tv7lK1UOsSMjqruXsX0s/4xJZdJDDWjPgoJa7HkgNZBg9qn3iCT9v090dxGVfW/vY3ixW4fsXgw9gBNRIDrpgSITjpuHh6mg/ngeiIGoOl8NqRd+fn+wvqyVz6w1penWV+RecoE8FlK83pER2Qpl+Ji31XMvoQrex2sdqmNiQqYmXWWh+QkmhX4PTQSCJf6YbWEG2/LuM4HfGxEFopMeKEbTKxO6CMssCNUZziaseQiEcEBrOySxMBVriTN/i+yig0LM2swTpEpO+gQfGidyAct028d3Uqh1uCYSAcdNinlhYuwpONAGhQPdb5ae3W6Yz0KuxxDYuCLciE56oBjkfdL7/zBlXyG0gMPYU5S1L5ASvylepHw2tJY4cyj85GNREB1IfkgxQPqE7DTIqmYXnznv9bGnIB8FQg3Gm5AoSZLSMDCRCL2zKSChvxDp7jqKTkuydreNJ/jhLXfnuhURsyM66YGioLt7HggBQq2DSXqyqPCFeco+SwnqFHR3NhNW+KiFjw4kPyJboQwfokzS7ShDe1fWIUkSL2yeNhDRQPEk+ChVlkEBiXalerBE/jqEpinl6xn93L/dij8+/xpcdPWvRe3OA6KTHigydffQss9tINHypA1CjXaGgnkSS5JTZ/aTCUs83Mt6Jj0+QwD9fB3PcRnF+0SQRqy1tuKn5/btUqu3fV+cQyl1d9m2mMrnwG8iiXelr7KDYOnunpgF6+9LlfzvmG4jZkd00gPFYI76pGfRxNACDn3uSSsB8TpMThq6kLPjw4FQ7cWadH/YNp7guX/3PbzmM/9Bdkxf/ZZDhh/9BftnauTPcc8utj6/ehzIDJCg5fsSfPQlWNcG2X3C+Rxr96WHd2NojBhfwYM+C2L6xgLfA4iwI8ukhz7RzoLQJ6x5OMcckMoGSLw4pBYvvuhkPijA0YHUsf6+zfjZ+gfw33dtIjtmbMFWho86U6kWjn0tweoT46NYj/DZGHuaG7kYY+vv24yHt43xu3vuTHZMiXs9YTofdRgHqqLuq3/7uMeCmL4RM+mBIqtJn4d72ofQzyzwNWH1BXp9G6MdgeswFmvB5idS7YXuHluwaeCY5/rk/EjBi0iiWAu2dNu3xaw63NAYcyYkHChfGe0xU0eWl51/NZ73d9/Dpi3byY4pwf7StAE8MBpCe44lWItWu4GWvPYB0UkPFIM56pM+DtQZngjQrfoMKQdhwuDclG3IBBx81XyNfTguRHT3W+7alNes9Rkc7W2iOJ8OXwJlUv2nJejuW7aP8bKPX401l91Edkyte0bg96lEINXXc8v1zr793ofx8LYx7nt4G9kxRYLzifpZ/jqEJxznh3ZetD0Me24IEdFJDxQZ3T207HMbhEorD3VcoUBqYSqt8ipDd2cz4bDrlwLc9v54aOt2PO/D38NLP3411bC8oRCkoluM+KptDRXqaZXMysjNH/yOy682bsJ/3HoP/u/1t5Eds0+MD+kWbJJOuk7vpmT0pFvKcybB/tLOh+B8Mc7XAWE9C75KT31p9cwDopMeKEbTKxPaQ94GSeATVlz82iHVczVvVzIHmQ0fdPckSZRnTMysrpzb8vve+9A2PLR1jDvue5hoVCm+8/M78Xff+oVsL22G8hCpWui+IATnR6L0RyJgSblg7hPjQ4KJoQct2MyUwEF35yr1GAusv3wxPELVlvCnmZNu4zusOaJwXKCYJ7p7qO0o4sRRDakXXEF3ZzMhlunx0q9ciPFQtqtmebsdYzLNPmfzXle8619+il9sfBDPOmhvPHHfZSTHrIPZ7idjQ1EdM7D1nhdoglyStb5CwQGJ0h+OOcqXU9oGEmwF9dii/bkZ3nNc706ZgFTxObZgU8tpZO0WfePDOh99QMykB4pMOC60mpY2KARCPA/EgK/64b5AaqEhQdWWasHmm3YuGXDSeke3tKtn4LqOqMBDW8faVgIU56PymHGe0unuvmrSez4XcjipfWrHKNOfW+Z9Y4JDzZxLqb7QBKI7ZskGE/2/DqGueX0J2kl0VJhXRCc9UAwzJz3wF94skKg9aoNCzMLzQAKFWB2mAN1dqhVLdmzJe0pjPIguCJUxtHXSme4xH3RDju/Sp77HEvB1r8vPhWwmWLJ8vhgObSDBoKMoBWoDjmC0OnzKe0YkWOKJ7s5Rw08BX+MaR5Hm1ohOeqAYTq9MaA95G4QqfhTp7tXQHAQJiuccLJo4FL7roJryRa1s+1xz0Yj9KIDTPy+R7q6Dqw90HbgcFROScyGHCBgQ/vtURgPFz33K8Z7jCozNM93dVyvWOvhiZuXnI77EGiM66YEiV3efg3s6VCpcpLtXQ6e7c9rhvw5SGTgfYoT+RIq6n9OEaW7woSarPS9E14GDQt9n+Fp064tbfjsScyHp8+aJ4dAGEu2xfNHdOejdXN9FIrvqK6gn0UqxDXytxWMnpfaITnqgmCe6O4fiKAVCzfCHAnHHViAQYH4mtzO9171RHD1l8NteO21u4KC79zyTHunuOvzRV2XsSty3LOrugQbibZBpwaZ+FrxPtXc20TGZvotEdtVfsGRqM7BnwZt+jQBDaF4RnfRAkTnp87Awk6oHborY3qgaXFlOExKKxppAmUjAQdBZFvpuJigW5hQK8TZk86Yo/Z8hqOVrsT8rJM8v4C+wKlVSkn0lVhuKYBdZtnVi/xwiRGrSPTFgOJgmHPMaoLKdyA5Zgq81XkF3FzM5E7T3ieBzGjPp7RGd9EBR0N37f1P7imbWIfQFsG/oE7pAZkeI9iZhR/IFKNUeqspu2+eaq81fUXdLdsiZbaaf6ammoc1R//e62/B7f3slblh3r5hNLqXpWrsMGUqrHYHF7IThHPYp4F0Ixs5jBpd+vuC4XwAhbQChNYwJiR7wbeDrOZUQxJxXRCc9UGQtdkN7yNvAl9JpHbiyePMCrpezCY4aSRNS19qHeqq3Fy+BU6oJTlHSbz3oTXCUh0i1DmyD7/z8Ttz14BZc++u7xWwmnt4l4nR3oewiiyMX2H1qQiYQYv/MDY4Mfp/FPfXzwWbGYjfdhrTeBXwyPPjXePOK6KQHipzuPgc3taZ0GpAz7Ku+sS+QqnXODi0m5COwKPDlQPhQbDXH0ATqeaLMbHkpO2BYzOrHJDkkGSQYMC6bgHRpR/GZMwMrHbCkK8uQe5du6xjBkAikhnCfcrRgY1F3n8uadPkg8SzwxizIghaBnY8+IDrpgWJe1d1DcoZ9KQX3BYnQhC5Cd1drJgUWwLK10MVnf+ru7Y7BNTf4UHfXe0XTHFNKS6ENfCxEfandSwn4yWQXVXtUTrp6fL6x//t//xaHvu0KfPbfbm19jGx8nLePbxVtSrtcbbskAqljofe+iWIdIGZyJvjqwpAEGrToA6KTHihydfc5uKlDrf321TOyL5CiRom8rIUyG77p7r5EiloLxzEtGiScHZdNgC7g4Eu5fxb4aDPEldWrgx4c4LMj0o6SIeAgdX5uuO1ebN42wQ87lFjIBIXV55bNTNmuFiyhOibPHDQRyK76fjeG5pQmnt4nke7eHtFJDxTD6ZUJbWHWBqHWq0mpl/cVOtOA0c702EnCl4EWy4R5qIX2tRBJCJ5rLrVZCVEil02Akmoq4/y0Qb4QFTzHvjLpYiKaAvet/tzSHFOKVkzRW1uGZq18lnwXMJTw6cwLkkNOj5Xd63THNOGrhaWPUqBZoJftyNktWrDJ2ZwXRCc9UIymmXROx0UKvaC7BzSuUKBet74r4UqxOXzQ3HS6ux+Hqe3zw6funi3EyQ45s03zc7djKp8DW+HkDqUvkUTBayuVgZLIwKnnjeq7JMLzaycnXQkKcyEIujuD3gDlsy6hgO6r80lRUhHWnO1LiDTS3dsjOumBIqO7A/2PPvlSOq0DRw3pPEG6bVn6mceGVAslH9lF35Q+83MTcGQ6kiQp6O49r5cOtX0l4CdbFITzI+KEsplgr1sOnakk3vLTk3AclVkOxy5JkjxIIhH0Mj9zI1S6u6/7UkIQc14RnfRAMRyqTnq/b+xQ6e6hZvgB4JcbH8AvNjzgdQwSE7rqUJk2KSG1yJ4XwbJZQPFcc6i7a3XLvmrSWWp9w5qjfFAYfTELxkJ2cyddqk6XIdsqwzRof4y5bsHGcB04WCRS58cX3b1wSsPKpksxXkyEqnbfB0QnPVAoPnqvb2w1YgqEtdDUhNECOsfbxxO85P9cjZd8/OrO7Wa6QKJ+yTwuH91dxtnJXsjelKd7VoPNLrbmgdIH0AVLQp07AeVe90V395ZJ57STbsWyvAyMD87LMiaYXyUCPUEwPsgChcrxA6fQm/AlDpwIPQ9NISXwaGKSa0nI2ZwXLPA9gAg7RnOSSTcfypACDlJ1yk2xZfsE92/eDgDYvG2MhSM/sTQu5W3NhnHe2TLpQnXbOc16B8guUjw/HPeYrwUyhxJ7yHT3bDzeVNY9Lbp568X5Ax9jhrmQg0ViA0VtqykYO8Sg4q/bQeLdabXLsKbhDurMJ6Oh+DxmusfawHff+JCSYX1BzKQHinmpSS87YZ4GYkGoC2A9yhzIOJicHfOlz/V95dSH/ToufasP5rjXfQnp8dPdSQ5JBh816YmvRbdAv2UpJX+OZ06qJp2itlVivvSVAOAIDnDMQRMG8UKrHU/MG19srjpItdUt2fXwrpgXRCc9UKhOekgPeVNIZUrbwNeEVQepF1jtOAQWGiW6u0BNOh913ww4yFw7KSpuld22VRkcC2Zv52Oi3mM0hkOmu+cUxh0gICWhEi2VjeZ47/VJ80NnHnUdkcuGX2eI0q42BzGwnVg7xwTAvAlp3paaY0zk+iU99mV8ITrpgUKju/f4xjZfgiEFHPQJy984TIQShZVpjSYTxOGofa6ywWnHBMciahbQZNKLz2SZH6F6RxMcz0uobB/AT3bElwipTnfnsSElEsgxFyYMz3GVnU5OusB5lggE2O3S36cc6xGpNY43RkNi/+wbvoJHiYd3xbwgOumBQhWOCykS1xQhZ9JDcYZN+JpIS+MQoNqa551r4S1Bxyx9F6FrJ0U1NUFRC8+RUUk8MVE4srx6BpfkkGQosppyNkNYdHNl/sRKchgCHVJlGZmdLpdAggI9YZgLZsGYoSyDRTFem6NJDmmF75Zj0nbr4KuUMrZga4/opAeKwWCAjPHe5+hTyUkPKGMdLCUpkAleYkEslX2WuNa+7nVvitcEC1GORZQ/dffiM1l9vSeWxCzIhuOPrSBmVmTRLfUc87TUkmIBdM/ISbAxQmB8kDnpDJRxqfMTRNlBQPO2r1LK4l0hZnJuEJ30gDGaeul9vrHN+SksZ1j5HNK4lKGEQneXEEtK7bCYEXF2pOrrTfhaEJD0SeeuSRetu2PIOHkKwMyC7Nz6Cgz5WnRLlMtwfjWOgIOYWnd2z1HVpEu8b3zdp2TX1v65CyQ0HgBzjcdmpoTE0/Wvg68ANsVzu6MiOukBYzjlvIf0kDeFuUgOaaEZKt1d6gVWB4k6Qy90d6ZTWlKqF3PS5W2W7bY7Bkv22RPVlCOoFaq4JVCMx1ubO08sCa6v66UtVc86KuQZOaJMOtdY9eAaiwkrxgRzsok+t2DzNV/4Erisg29mQUjnoi+ITnrAyOrSQ3Igm6JMAQ7nu4RS+20iFLq73pOYx0aJ7t5j+qGve30iEICwgWIhwpNJVz57yBZQ2h17+i6zQKKntwlfGSoREU2heX9HV3eXEOhTbXCql5tIGN5zLHR3IRajr5LGUNromkh8vRsT+XfFvCA66QEjp7sH5EA2RZnu7mccNuiLIo8DMRBK8MAP3Z3fgWare/fUycCXmjnFgpAjeOJLbI2jTCVkuns2HMnAkK+5UcKxk2LEcGdGJZyuLs+XBEPMV8kaz7UtPnOUR3CeHl8ss2Dp7t5YZtk2nHPRF0QnPWAMcyfd80A6wHTCQmIFhFL7bWIcSPBAOz8CC9P05/4umsxz5KMFmzd195bflZsi3nu6e6AZGaA4t976pM9ZBt9HCzY6IbDiM+c7i0IlWiKgEIKqONV34yi/k3qOfa2lQi2l9PU+yenuAZ2LviA66QEjq0nv841tLpIlqV914Gj/RIFQggc6VYzHRsmxFehBLNFCKbXDYqbSrr/64HbHYM/SeFsgUx2z+BxaFsLHwksPSImZla9jZvxuLB0VGCjRNmSHJqO7s5Vxqe8bHht2u8pnhvmUjiFkPz41ghBVDWje9tUJpgiuiZmcG0QnPWCMpk56SA5kU5RqjgP6Lr4mrDqEMsFL0KjN40rQ6rkWwObYxejunsTFKOr9OMbuK8jFwWjwlZGbBT7U3X3V+krQc8Xo7iw6EDLv0gnBYl+GIeZnbcHxntM1DIiOKTSv+aCdJ0li2BUxOxN8dTTKS6NCOhk9QXTSA8ZwHvqkGw9lSA+plCJtU4SyMJdwdsxbW6RGkGth5qkm3RvdneD54VhU+qq746CFSrBZ2iKvM+x5ze0skBDwk6LI6sFXmmNKZSzzEovg6e52e9zgsMtxTCndEB/vglJiKqCJ2zfLrM++jC9EJz1gZDXpIT3kTWE+kyE9o6G0OjMRSvsOCWVUqbZlEnTMkrq70LWTaC9ntUucSefoLe7NgSSjEduPHwJ8LLx8BTAl5kKpdnssjpzQfUpBd5dwVHzNQSw16Qz141Lnx4dT6msdMAt8zZ+Z3T6zgn0hOukBo6C7ex5IB5RrjsP5MlI1gE2hUaW8ZtIlMg7mC43FjMwiW+i7VNn1RwFuZ5ejhtKbujvDYjYUVo0N2b0meo69ZSj5A2FSDgU/3Z3kkHY7Gd29i5MuEAT3FWhPGOYLjmOq6y3O8+ODZear7G0W+GZ4hHQu+gLvTvrHPvYx7LfffliyZAmOPvpoXHvttZV/f++99+L000/HPvvsg8WLF+OAAw7AZZddJjRaWcxDJj3sqKL6OZxxcQhQhToOKfV/jUo6Z3T3Ptdg86i7F599tJkB6AKrvvr8zgIf6u7e1IkFMsUSJTmpHfpggFiAIenO3tADg11H5M9GnV2qe4iDcShdHpHaZDOjwbzeIc3bUq3vXHYnScymN8UCn8YvueQSnHHGGTj//PNx9NFH47zzzsNxxx2Hm2++GXvvvXfp77du3YpnP/vZ2HvvvfGlL30J++67L2699Vbsvvvu8oMXwHAaQulzHYdUH+w2kFKkbYpQ2ndwZDlNmAwGkRrBOaO7h9Hup90xOMbuu+4OoMxQKp8DmqMAP9kRf31++e8pqQAEx/tFKlCYl1h0OD/SDDHRjhvKuacyy3Ft5doNyl+H0jogIJamrxaWZnBgNBAz3Xt4ddLPPfdcnHbaaTjllFMAAOeffz6+9rWv4cILL8Tf/M3flP7+wgsvxN13342rr74aCxcuBADst99+kkMWxWgwh+ruAU1Yoaq7h5I980IRF1gAz5u6u68FIYXjwlFzHULdMtliNtA5CiiuuSydt2xfAhL3lFRNunYOGeqWJWrSu9iQcFQ4zvEsYAl6MjDqNBYW5/3iwSktrQMCmrd93ZfmM5eV8kbUwxvdfevWrbjuuuuwatWqYjDDIVatWoVrrrnG+m+++tWv4phjjsHpp5+O5cuX44lPfCLe/e53YzweO+1s2bIF999/v/ZfX1DQ3T0PpAPMiTGkTHqo9Z7jQFTnJeiXUi80iQVwCMJxPihsQPvrxhE88ZdtVT8zsALCmaIAKBTGngtjzQL92vLb4Lxv9QUzzTGlAss53b3DRZBwEDnO8SzgqMFmKUkSYo1IPLclmwHT3X1l0n0FB+YB3pz0u+66C+PxGMuXL9f2L1++HOvXr7f+m//+7//Gl770JYzHY1x22WV461vfig9+8IN417ve5bSzZs0aLFu2LP9v5cqVpN+DE8NhrEnnhK+ekXUIJcOvlwPw2Ci90CRqBAUo9YAczc1bdlF7ftoeg/5e90UR56AR+7q2s8C7urtkQEo4yJckfAw6Hqer+My5XqEIDI2189yfczwLOL4bh2Mn1VknDLp7OPO2r6Cvr+DqPMC7cFwTTCYT7L333vjEJz6BI444AieccALe/OY34/zzz3f+m7POOgv33Xdf/t+6desER9wN80B3N4ce0gMqQYFuA21B6HGC96OILpHZ6DcroMpu3+p0ORxqb44cwwIolHaMNmTDkZyjQqC7S8xRtp+pwBFwkGoDmdnpMm6J934QdHciuxzZeY7SIBt8ZI5DVncPYf4M6Xz0Ad5q0vfcc0+MRiNs2LBB279hwwasWLHC+m/22WcfLFy4EKPRKN930EEHYf369di6dSsWLVpU+jeLFy/G4sWLaQcvhKmPHtzirAnKE5angVjgK9pdB6msRAjjkHJsRXq+eyrtCEEMpq1dFuVgX5RohuCaLbs6GIRRz5ddO8n3ky9RTYm5sBzQZjHD8l2kxBozM23vuSRJRNpyhUArJisfYpijObRIbPARLDHvzZB8Ul8aJ3pwQMzsXMBbJn3RokU44ogjcOWVV+b7JpMJrrzyShxzzDHWf/PUpz4Vv/zlLzFRrvLPf/5z7LPPPlYHve8YzQHdveS4BPRdfNFi6yBFBauDBDVKTjiu+Cy2yBa6p1S7krcLRQkBt9iabLbAPoYukHLc2qCoD5a3aX6eB7vlxT2/nZDrlm3IM+kt7znz60rQ3SXnZF3dPdxrK5VZ9dHpoz/sUU/B1YDORx/gle5+xhln4IILLsA//MM/4KabbsJrX/tabNq0KVd7P/HEE3HWWWflf//a174Wd999N97whjfg5z//Ob72ta/h3e9+N04//XRfX4EVw5zu7nkgHVCq0w3oy4RKJdUVSf2NQ6KOqHx/sJgR6Zcagrq7v7YqLTPpDPeYRKbMBo7sWcjUycxRkizHCoMlwWRD6FpzsIqk2F9d2RtiQqWe5iBudXeq9YhUbbQP5zDsOZs+iDOT3UAST32E1xZsJ5xwAu68806cffbZWL9+PQ4//HBcfvnluZjc2rVrMRwWcYSVK1fiiiuuwF/+5V/iSU96Evbdd1+84Q1vwJve9CZfX4EV8yAcZ04EITnD2mIloHMcinCchLNjnneRhakAxRGQu3a+otQUTqm+mO06ovJYJBcEHPdYH7pjzBvtvNauQEkOpx0O5XGpZy7peM9J1f0nnubkhOE+ZdENUenuAuURgBwLydc6YBb4mD/NEpOQ1tp9gFcnHQBWr16N1atXW3931VVXlfYdc8wx+Ld/+zfmUYWB0bT0MKSFWVOUF5meBmJBKLXfJnRVdX/jkoh+SjEtJFgTZSoli5lKu75EvNqKRfWZSmmCg60RNBPJQ016CKKAXBko02FOetTpwocQ2GSS5ImMWSFFRZZQkLfa1TKl9Mekc/xlghgh0N1DEn72MX+apz2koEUf0Ct19x0NGd09pIVZU5QWmaE6w+EMK5jggcQLTkrdXaYmXSZLY8IbBZhgIapTKTkWgCSHnNFu8ZmuJt3PPVUHNTviq0+6LF3TPgZaGzIZOPYWbIyXpeszVtZA6Toil53ic+/p7hwMIQ9BHanrUGZriJidCT4SQFLslXlFdNIDRkF39zyQDjAXUiEFHEKtkwmF7q5nXLhsyEzgEkI+vmhu3jLHBAsgHnV39bPgAplhARQqE0mC/m2DL70BicCPVOkPR2BMKnjSda4z71WZbiIsJqzgCRRyHJP/fWweW+o6hFyTznEt6yAVGJtXRCc9YIzmMJMe0oQVau9GHxStunFIUcTZMukCEXVfrBGJYIoNFA4TR62ar+4IHM9LqEwkfY6Ss+uvBRu/Eyo2FzIEOqTo7l0D62YJgRhDTOxdwJv1pvoaauKJ01n0oU9SLnsLY84G/LwbpUpM5hXRSQ8YmWZen29qqbYybeArG1SHUFTnRejuZqZQgn4okD0xbXJCIgBhtUuQDeG416UcBhMc2gChCm/66gPtq7WVTJBPJgPH0vdajL5cfG5jRqqHdQisKg6NDzLhOA9BHR/dVoBw5mzATwJIir0yr4hOesDIatJDyvI2Rbnm2NNALAglY20ilHFptGGB+kiAUdFY4JyWXkY+sieCL0AKVXl9EdV5SKXjeGvTxeD8UB63K3zQJgHDWfZUk87m2Ald64ThmeMQo7OhawDORws2m10usLRLYwhQmcFHCXaKXCbdzzpgFujsNxmbvlgl84LopAeM0TCju3seSAeEKnwEmItqjwMxoDrHPs+XWVfH8SKVooZx9AY24W1h5mEhYtpt34KNN/PjT7SJ6pjGz4HU8/lSr+ZgK8xmlz/IV2LiMF1rDgqw1DPXVfhKymGQupYmON4FHCw0c36UYKfIBUr0nwOJqwLww9IsaW2EdEJ6gOikB4xc3T0kD7IhyhNWON+FozaPAhw1YF3HAfC8bKSUULXAB9M59RVB9+WUJgSOGofImy919zHLAjnMBU4IdHd/rd+YmDim4yKRXaR65jThOJJD2u10vA7memT+ArYMbB4GQUwfnQy80d0DWltKaGuUbeo/h3Q++oDopAeMnO4eyMKsDcoUYE8DscCHqMgskMj6zoLS5MowFqmaWwm6e6m+3kOkmovxYANFVJ6CMm/CV7kIx4KwnJELY57yVvfvac6WYKuIdbpgyKZJ6bt0DTCI1f0HUJPOMQdxBR/ZtGg8sCVDDawCfrpjmHYCOh29QHTSA8ZoDoTjQhU+AvwtNOswDpDuDvCMxQfdXUzdXcpZLtWyipg1mChtj0HvUPt6fjicn3ILtjDmqbGHxa9pS5L6z9Fez4RcnS7HMyfzLu0aGJR6nnwF1ziCSXogleSQFq2i/rBGmtiUtDsLfNDdQy557QOikx4w5oLuLuSEtYFU9L8pQuyTDjDR3T1kNiSodalNFjMWu9Xj4AIN3Z05k+6JEk01z5WvLclhO8NXqVAILdjYhOOE6O5jhvdewuD429A1U2x+XbbyKk/PrR5MIjomg6MrV9ohv5YqB4JEzM6EqO7eP0QnPWAMh/On7h7Sd9HFjzwOxEAo6u4SlD2pKKt6WLYMlaesp69INUX2jCIbXzqmJ0o0RwY/1CzEPNeG2+0Wn/vego1b3Z2V7t7RCZXK4Ja1VqSyuAxBTwaWhJSAn4+a9JDZoxLBxrJN4+dA3mF9QXTSA0aeSe/xPR1yVDFcujv9IqoNJBY05jG53mcSL2tfLyNflGiKBSGHVoCvLC+H8xMq3d1XIFH9+lKsrBJ1WYiJI6HuTnUOpcROuwYDpNrcld9rUnOy8pnBoeZgXgCc+guqTRYTZZsBO6U+3o0ldfeAzkcfEJ30gDFKffRgFmZtYA49pO/iS6G4DqHQ8EvXjqMm3QvtjcWEN8EY87LIZQyUMbTNpDNkvX11R9Dt0gccKI/bFT5qG0t25ywIJlenS38OpejuXZ8xKeewRKsXeEa4mFxjhg4cZhCT65bxkUkPNbAK+CkFK89rImbnBtFJDxjDvE96f+/qkOnuHCIrFJAQKZppHAKTq1RNOkerr5INIQqfiXKmT8QsiTPMnaWRrVtWP9NnsYBw5k89oy2ZKZS/tuUgGJMdqYCl1o6SyumSCdp0DQb4cA5TuwJOeilITH9cNnX3OapJD7VECfAT5Aw10NwXRCc9YOQt2AJqW9YUIT+gvvpL1yEU4TiJujopRWOOLKcJXxHjUuTeR/1jS5s8WRo/zzVHcKDMZiE5bGf4KmOS6set2fQwRwEywcS+lZh0DQZIBVLNsUncq1w0aw4WmkQQI0kSES0aEyGveTX2m6f1SUhr7T4gOukBYzSYg0y6JwdiFvgSmKqDRE/vWSBRqiCVpRJpwWZmwnxl+qQWI6qD3dJmwrIAtB+fG2OG+SRU6qSvDL+PUiAp6rJUBk5vqUXkyAmxv7oGA6RKkkr3jI9MOoOTTub4C8xrPq4BYNM9EDE7E8ZCz6mKkIX0+oDopAeMnO4e0lPeECHXo+giK/7GYSLpuBChggQlTUJBHpApbZASJTLhi2ZPQYNkEY7zVC/NwczxpXNQBym6apVdX4tuMeFJpq+nz4VUx1TnAppjWu1oTkabf2/83HN9AQmbHF0rzIAsx/qr3PqL3oYNoZYoAX5YmlIMoXlFdNIDxtRHD2Zh1ga+snyzIBRauQlfokwmpChpVT9TQYIC7asWzVcgTHeY2h6j+Mzh2EqWCmm1vkR2y3T3MOYpX2KFIQgfcZkVE6hjyKZJMRy6vrN9tP6y/cxjs3oMbZEwPHMS2VVfCvsljZhA5myARuy1KcqBMRGzc4PopAeM0Txm0gP6LqH0IzcRwrjMeq50H70dqcW++uLkeldLZcLKdv1kWynYCfzq7n4y6RytrVIbJIftDCkGjAm9xELEJBKhMhaxtlQMbASpEq1xx7GXWRGdh2RFufSJx45ug+f+4QhwyyQA9J/l1N31n0OZswE/78aQmQV9QHTSA8Y89En3RYucBT7qG2eBL7quCptZjslVarHPUYdZsuGpfri0KBCLkHd/4XNkRn2Vi7DU+ga6wPEVfO3qpHW1CTCWy3go/WHpqMCZSe+ogyFVH+tj3VNmpdEcl6NUzHxncWS5fQmWhVqiBJhMFHmbtp8jqhGd9ICRq7v3+KY2F28hKdWH2iddX4j6GYNtIpWhpJGbSO0w1NWZ8EV3D4Fm317dnSGr50EcB+Ci7ps/hzFP+RNJlA8OyLWL0n/moudy0N3V658kjGPvOOeInWMPczJXaaFOdyc5pIgjK7W2MBEq3T1JEj90d0+MhnlBdNIDxmh6dUJ5yNtA6qXYFFxRZwpMPEykVWPIyi44rp0UJU2ihMDXy8hXBp/iPtWy3gwLQFHhOAbqvoQKcht4K7HwQLOX0nwoO3b8djg6Kth+pkJXuq5UdrWcKWYxY9jk+W4c7JVy8obDSdd/FhNKMwOYwczZ+s/zvj6ZF0QnPWAM56EFW6DUn5CjeyG0hlPtLpg66RyLRjnlZH7HzRz7vPdl1e/TdsfgVnf3VZPep9rNNvDRBxrwc6/7CCRy2uGoS5Vg85Qzgc2PIdeCTX7dI0F352IIcZweiUCA1W6g9G5fa/ESsyCQ89EXRCc9YAwZnSMpBLvI9CR8NAtCUJ1Xx7BwSung6ZMu49jqdXUsJoJ5CUrNFxT3KY9jq3yWVHdnuMdCpbuHUGIByFxf23fjYONIXWsOyqtEtowiM2reL2zlVSHQ3QMOekqcH1/q7qGKJftKIpQZHiJm5wbRSQ8Yo7nIpOs/h/JVQp1IAX0SC4nuLqLA2qM6TBPljBuLmRKk2AgmKOju3Oru3ujuRNegXN9IctjOKFE651iUyXZfcryTpWihPGrdbhtUoHhnSznPPsr8yn3B6R1qNic90KBOO7thOqVSjCATpeBjQGvtPiA66QEj65Pebyc9zEx6qDR8gKdmsMsYODPpUlFWEbq7t8i9+bNQhJwkk65+pl8ASs43HPdYqIwfX5ROH4J1tq/GcR18tGDrk9NFUXMtVl41PW62hhPJpDNlSvWgDskhRZIkvpzlcl/wMOdsqbWlj9KPeUJ00gPGkDGDKQXzeQxnwqr+2SdC6JOu2l044msF6IPu3vea0jq7Us+Y2Xu+zbVjyeqZGUkpgRyG5zZUxo+vek8fgTDb88RSQyv0rpxwPHPmdWFwiChYV+W6bd53wYJhFuBmMaOBK1PKEUiV6CUeDN09kDVvqZWkpzm7z/6MD0QnPWCM5qBP+tiIKIcyYYW6+AV4HJemkKK7Swn4mS2COCBF3TfhTyCn+ufZjkHPGvFFc1TN0LU/SrfF/Ely2M7wxd7wUQuf2ciClVx25VhFig2iryHB+KBwMkpMDOagcBHglg8mcQRgqI4p8RwH0yc9kEnbDJz56AIDhNPhqS+ITnrAyDLpITmQTZFHlKeU6VAmLF+OzSzQF1G+nPTC7gLWFmwyVKiEYaFholRTOueZdIpFEAdrxNfiTO/PTnRMc/4MZIFTzo7I2PURgMlsZllRLrtS/ZXVsVPN6T5q0ttcA6n71se6pxTEIAt68s/RHO8sb0FzguA1B7xp1wS81u4DopMeMLIWbKEszNogjygPw2IF+Mq2zQIJkbPaMUzPx2DAW3ZRVhwlN5HaEahJl+qnbEKCOmjCtrhvs9DiKEPgakVUB85a34WBBWx9ZYuk5gvdRuZwFZl0Djq3FDuBI2Ap0WaJYrEvFQgp6O5ymXSua6Ax+3oc1JF6D/gK1tfBm46Ip1r4eUF00gPGNAgbDEW8DbIJagGj+FgbhDqRAiYF2JOTPl2EjgaDvOyCU4GVW2BHq6sTsAFI0qzlHSabiVZOuhqQ4loAeig7oKuvT7ehzZ+lun9fCz7BDGUmoKnu47DDaQPgKaeSYK9QBGjKAU3ed8ECUbq7/jNdAEa1QRt8pD6uCl+MqlCF0kIJrIa01u4DopMeMLJMep9vah8R5VkQ6kQKGFlfz5n04WCQ16RznKIiS8VL51Wvt4Qgk+1nLvjQV7Ddl53p7lSZH1+0PpUVQFaTnjmIYYmI+qpJ99J/OgtYDotMOk8fcKksr9smxTEpj1tlo+t8A/CzqnLhOIFyEC4KOUcZj4STLqV3U2c3lPV7WXVeyK6noPm8IDrpAaOgu3seSAcUAiqB1aSXFhV+xmEDR+S6KVS6+2DAT3dfyFj3rtoB0mvNYcdbpNrDS9DeO7r5cTgCUlKUVhMc6u5jc7EfyALHmyiTB/GjzMZoMCgE/DjouULnVELdncMppXCwJQIhSZLk7/A8uOZhTuaoSefovQ7waANIKfmbkKi3b4MQusBI2p0XRCc9YIwCyz63gVnPF4oz7KsdxSwIQd09Oz1pJj39zBnt5hbYkQjK+Ar8lF+CEjbL+7qqLVON21dvcZ2tQXPMMm2W5rhd4Wvh5UP3oZgLeXVipOYPno4K/M8chYMtcf+ox8zLVARu1FJggCEAQ1ce4bZBBanyEROh1mB7E1QNeK3dB0QnPWBwRu2lkE0EC0ITPvI0Yc0CPSPnaQzT8zEaDoqyC8aFV7GwIDeR2hG43ir7QP2ZG17o7pbv1jWzxdHXF5AsOyg+U7MCQmMi+VN3l5+3x/lzPSg6rrA4dzKBDxZ1d7O1mUBNeqv5RqAFm60zisRjW6y1imU9xdzHMZ9KsJ3K9yS5CSvMWyqUNa85Ll/0f6nrMC+ITnrA4FTVlkIpUxoIK8AX9WcWaOq7AdDdC20EPjvZwoKLkiZSA5dT92UdKh8RcivdvWNmi05szU8GRS+poMo4GUHOQOapYOo9Jenuw0JEs9d0d4ZgUllJm37sFM6PRFZPc9I90N3VLgQUzwcHfVuC7eStNWmga0tfave+3sfzguikB4wig+l5IB1QFo7zOZoCvhaZsyAEuntmVhWO43yRci9mJF6cZWqyp0i1gF21BVXBHGh+HDWqTtez2bzWJIdtZJeaFSBJm50FvtTdfQSksvsypbun+0SErrgClgI16Szq9wTXXqZVXPGZO/is2Z2aoO5CwCGyK7H+CqblWCBzdij0fyltgHlBdNIDxoiRZiwFk64ZzCIz0GgnoL/AfI3LujBleZGmW246r+SiQDrr6UNVXn3B58yBFt+XgzVi1gCK0d0ZMumlcpBApilfC1EftfBqwJKT3Wbe/1xfjaWjgmA5UW6jhQkJ6q06TsmuDOb7B6Bhv5XZB92PWRZ1635ME74SMSXGRyBrS2+CqgGXlvYB0UkPGMPAKI5tkKsTC2cX61DOBHkaiAUcmY6myK6bXpNObyf7rgsY27ylx6VfaJgoHCpZuruPzLFqc9RBb0JXd+8+LsCfA6kH14iOGaimhy9xPg6Hodbm9LtqpT8sdG6Z+5ZHO8GwIaDu3mq+EWCA6DXpcu+CvNyKOJPOUccv0SbTh1YLYCtREjFbC/P9Kieo6sfuvCA66QEjC4j2OfKU0zUDq68Pme6uZzo8jWE6oQ8GA2ZF4yyIw7uYkayBW8Asgle2q/8sUv84sTAtWthlyT4H4ECy0d0DWeCYw5CiMEoIf5VsqjXpnMJxAuJrXMFpCSothR6BRCBEPWT2LpB4PMxyq3QfgZPOcM4k3lmlAKfQ1OkrWF8Hf8FrP8GSeUF00gPGXLVgi31+Z4ZK4/M1oWXXaTgo7kOe3uLplrufrITgVOaUZy9nMcfFw0swMzEadqMAS4hYST1DWgs24u8i2W95FoSi7i7xPslMDNWApQDdnTvLS2lD4rpQBFpFMumKjYWCgrl2uju9k05yTIESLTNoIVeDrdsNZc3rSzjO17tiXhCd9IDBqaothWzsofX5DbomXaW7e6tJT7fDwSAXBuPM7CzgDARYxs2xKCi1y5pjoZpC/X/QKZiosUaIxu2L1jdmeG6zw4yGYWt6zHNWRr3XeYXjBBxdputmrlE4rkvJwe4YFEx/5r2OkokWM4ML8GS9ObLzHI9x9t0XCs+d5Qx+IHO2AFPHalfgmZtnRCc9YHDSjKUwNl4coSwyQxX3AHgcl6bIrpum7s4ptsZIDbNdW066O+f5stqdvnwlF4TZdxsOunWh4GhbJqE/YINek04UcJgeZ1FoQU6BjKTVrmFGpE+6cq8X+gv0dsot2OhtlGvHeTLpHNelVNva4vyY2WZ2urugloTKbrKNpfVxGcqHJLoB5CxO8W4rRrA+kElb4pxb7Xp6V8wLopMeMLKAaCiObRv4UryuQ8gUHI6MXFPkdPdh0WWAYyhlujufDRUsdFWD7i69KJB8xvIMb0cKsDpUOnV3+UVBmb5JdFyjXCiUBZ+vciEfegMFm4FbnyPdcj7HXNocIi3YCGyYuiEs2gJKsJazPKJkNw8m0TI+yuyVzocsrbd46e7D/GcfrfBCYcL6KgMLtSVdXxCd9IDBqSQrhcSYsEJhBYRMd9ccF08TWtGCbYCBhHAcYz9Z27XluNwF3V22TKUcuZezmTItMLXb/KSq9xSdY2vYEKRE5zYJbrAkSQoHMbj6RvNnPws+CbMa3X2o7+Oww5mBKy+YaY5bdrpojqsdk8DJyB0oRgq0qucyFBQtKwLrtOw3DlFAiVaKOYuTmFlQhxKjLpg528+aV0IHYp4RnfSAUUTtPQ+kA0qR61CiikELx6mOi69MerpVnTDehSk/pR7g7Zjg6+Wct3wRFMgZ545LMU+1MateG7KsnodsK0dgQD3EosDU3UNocydl11rawVr6wxeQKdWOE5eYcLIAKJ5ribkyG+ZgMMCIMKM9q129BIlgHmLIeku2YFug1OhLsqoWBh5Y9dU3PqS1dh8QnfSA0aX/cCjIHsjQlOqLF+n054DOMYfj0hRiC9NMWJCRzqsek5PRkQXTpPUXsq/CyUYo2yye67YUYDVTDPRb3d02r3W1qx6zqKHtdEgy+HLSffRnz2t9B4O89IeFJm2Wywhk0qnV3TkDlCX2RqvyGt1x47mOlnenROBUobtTaidItGDjOD9mTTogxapKt6HpMPnq3y4hEjjPiE56wBgG5ti2QU53D6ymMs/gBtYaDtAndV+LcpXO3KXF1qx2OPvJqsOWWABLt8uSYCOUbabbLsKCtj8nydJ4YMlYnfSO119z0gPLypTozULjKspwpnYFrm0iNBdm88UCRkeXK4OZHWcR4/xKQZst6O78jIiRdr+QmykhUe0SlqhxBHbMbDPH+ck1YobCmXRjTRMa3V1a0K6kEROID9AXRCc9YHBSc6UgIdTSBnmbjMAmUsCgu3saV2Z2yJ09Ml8cjBF1gPd6F5RPviyNDWYHBUkKcJe2VLZxUtzvJXqdYBaL0q6aBQstK+MrOzL28IyprCvOFmylFo6B1nXbkLN5GAOFJkOozfnJ23It4Kz7T7fUAm6z2qW+TzkCcqYWDWcpnZpJl6xJz79bIOwn8xmVC6zqP4e01u4DopMeMEZzIBxnOmGhfJeSkm4gEymgj8VXgKYQS+JdmJavA28GhvPFOTayA3J9WdOt5Mu3oLcqjJ/GmXR6x9Z2DIkpx84K6HrM8n0bygLHl6ZHQSWVY42o7Sg56cvmd2MR0TR7JRPZKLVaFWABtLEhUjuvvDslSxZ1MU86uxTBERNlrSLGoDlx3/g6mMy2UNa8Zbq7UCY9YP2nPiA66QFjwJjBlMI4rzmW7R1dh1L2MZCJFNAnT9/CcaPhgLXsQkQsSTkk7+IssyFLJyuXbvDbtDEtmj5D9jruzkPzUi9te047Z9JtdPdA5k+JmlIbyjXF/Hat+guMwcQFguru1K0CF3LWepsZuRZGykwMPueQu2WfCWvrN4agJ0lNuqG/wFLakdPdlUy6CMss3YbWNtMX3T3kTkp9QHTSA8Y8CMf5WFTNAl8T1iwIQThO77nKWTfGHyxRW+JQtqYxYQrVSLel4qSamqAQKbINk6SG0ou4mMVJ7ywcV3yWFvupg4Q6s9WuyVYRvLZqZpTDbEGTZaxJZ3o2smefc36leK5ztsICzmBLutWZF+RmStDYb4TXwTzvtHR3uW4J6j5O+FoH1MEWSBPpG68IKaY/s5ucK0QnPWBwtr6SQon6E8gq06b8GcrY1Berb7r7cMBbdpHXSTHS0NUMQ6bmz7kAli7tyDP4gnXL+f0xVBk/zexa67g5lIMFKdEqui6A1HEvCIzxU6bACt/rglmqiep0sQb50i2n/oB5+1Cru3MGT0rCcS3OT7kWuvu4XDYGxLTzWrvKfZq9sykuAwdrplwe0fmQJUi99112Ob9bG5hlcYBsKViIrNU+IDrpAWMgSJXigkqbVn/2jbFBtwLCCYaow/A1pkKEZtC65ng2O/xRZ/W7FJkwPjvSpR25Uq5gf3ZVHCl7hNq0YCsdl+Cc+aiBK+j/dHbVZ4FTjboNKJS228AU/BRpbaUELIcCQb5C3JLchFWvgWIulGCmUZSxSPSwVgPcks7hWHFKKUWHOVuwcXZC0Wr08zay5GZKCLXE02QvAJ6CFoGcj74gOukBQ3Ji4YKEencb+JqwZoE6Dt+ZdO2Fz7kwFaBJqn2OOZWTOXvwVtuVp1bqC6DumXRKKiXlMWe1uWA4JFuYa2rNgbXjLNcHS9k1nUF+m2qNcZGh5HMqONuCcpRlJElSzpZJOOkd6O6cTAyV+i8p/qu2JxwSBmw5BMfydzJnAsBadiB3HUIrpTTnTkBWeDPETkp9QHTSA8YosIVZG0jUHrVBkZFRMumBBEM04TiiTEfjMSh1RJwsiJzuzkgRn9gWL4yLyEXiNenpVjJSrd4fbQUu1b+nzDiVMz+dD1mLoiUdXXDVptYs5QzXwZcYkNlLXLa1Fa8+h6Ti9YgwOK3+8wW5Mn2nQ1pBUcZishU42WHUKuv1dtMtNWPMLMOgVHeX6AaQit9O9wmWgi1g7NLQBuY6Id0nEbRIt6EJ6fUF0UkPGPnCtcc3dVEHE5pwXLpdNKJbrFDBXNz7GJZtYcq5oFnIGAjQRM44WygZ97o43V2QraLT3dsFPlS2BiVrSM1Aq3Y4kZlQuyFQqbuPhPstz4KSmJRwTbpoQEoL8un7aO2kW84MnEnFBbo/c+p9vpCxVWC5xKL5McwsJ29NumyHnuz8jIiDSaVMKCndnY8RozILJBkNY/O7BTJnmwEqQPa+XMQYwJtnBOGkf+xjH8N+++2HJUuW4Oijj8a1117r/NuLLroIg8FA+2/JkiWCo5XDPGTSC4GQ4mUVQmTRpCYD4QRDuBR4m0BbmDJqI4yN68CT4U63Q0VAhrWdnDBrxIddK9294Tm1MhwIqZSctGET1kBQ55r0dDtQnsFQ3gUldXehcSXG+0QkIKVeW4F2lBL10ovU9x5RMAng7TBBS3fnrIVOt5peh4guxvQ+HYKlJp0y6y2hLWFnwMi9G/M5KjD2U/ZeBKSZBTGT3gbenfRLLrkEZ5xxBs455xxcf/31OOyww3Dcccdh48aNzn+z22674Y477sj/u/XWWwVHLIeRYBSWCzZ6XQjrTFtNegjBA8BG1/XnpI+GA9YuA6aADCfFk7sFmy/9hbJSrqCT3iHwweHYquNYKNiSTg9q6ftaH9PiHIaywDG/mlRAyuwlLkkjHg55a1tzx4VRedyeTetmSKe7y9XTt6K7Z3PDAr77R9dzkaM8c9DdkyRR6MqENemGw8jDGlGYBYLCxWa9fSjryqK0UGXRyAU5Y016O3h30s8991ycdtppOOWUU3DwwQfj/PPPx9KlS3HhhRc6/81gMMCKFSvy/5YvXy44YjkMBKN/XLDVwYTwkPoS0ZgFvuo9bTY10RVGB5qzxlStTePNhKVbSQE3m12JyH2RLWof+EjyY9BeFwl2hgk1aEGle2BjswSTSffE9jEzodIiibw16emWMxtt1hcD3ed1dZyLODPpxjlvYyNnYnBm0hV9Ck4Wmgkr3b0zS6L4TFmGUQRL+OY1lVkgyUoNVSx5bAQPANnSuJzZFsg6uy/w6qRv3boV1113HVatWpXvGw6HWLVqFa655hrnv3vwwQfxmMc8BitXrsTxxx+Pn/zkJ86/3bJlC+6//37tv75AUnSEC2ZWS93nE2NFgVWyTcosMC+3l0z69PwMmKPQJSoUY624mPCT8HNbBDoEM+kEFGB10UCpvzHJ2yvKi4tRBhy0DG5+T3U6JBl8iPOpz5OkcnLB+FBYEoyZPwkxLcrgtEZ352QBEASvizmHM5OebqUFH60laoTXlnI+LbLznMyLdDsY0Lakm9VuqOruasceydK4mElvB69O+l133YXxeFzKhC9fvhzr16+3/psnPOEJuPDCC/HP//zP+NznPofJZIKnPOUpuO2226x/v2bNGixbtiz/b+XKleTfgwuSYhdcmBgvxXSfr9EUsGapAhgXYBHI8TAuG32XU8iooLuTm7AKcHG2ehOnu+d2PdC7hwOF8dPuGIMBbaZjYgQtJNXdVep+V7u2uv9QFjg+29wBsgEYLsaHCTPIx1mSo7yOu2dblftcQpk+Q6s+6dN/sijP4HYeVgmJ5X0jQXm23addzY6tgbFuxwRk7nUbs0AygE11DaigroM4O/a47HKKNc4zvNPdm+KYY47BiSeeiMMPPxzPeMYzcOmll2KvvfbC3//931v//qyzzsJ9992X/7du3TrhEbdHaBneNiioLrIUmzrYet+GMC7AkqXyMC7thc9YVyeRBVYDDpx1YgVdVVjdPbfrI3MMZCSZtsJx2jNI2d5ngaC4mBrUosqkC2Vw24CCetzYpmLCSykDIY3YhsSYPzjr3rWFOlEwCeANUJpzw7iFCbPun8U5VIKPnC0/3XbpSm5segMkdHczoM0YnNfayAoyGsLLpKfbTHAbkBLeTLecukPzjAU+je+5554YjUbYsGGDtn/Dhg1YsWLFTMdYuHAhnvzkJ+OXv/yl9feLFy/G4sWLO4/VByQnFi7YVNRDYAaMNTo3gHE4k4c5Dh+T/FhZmHJO6BJUKKvKK+N3WSjYaiSxLJDF1cxb0vtVWijlYjZnZ0wX4iKiTUr5THb+u1NNi2NSOf5UGCsL4Eki6ywDercQfrvpVtcGoLdT6oTCWPeeBV/HSAjKMop/z5oZNdkbrTLp+vuGk2at6bkIZixHqrp7x+83tjxzlL3XOXuJJ5brIFuDHWbyZzQEqVBrHcwSm1CCFn2B10z6okWLcMQRR+DKK6/M900mE1x55ZU45phjZjrGeDzGjTfeiH322YdrmN4QmlhQG5hZPiAMZ1iLsgZ2nilq77rCFoXmiHabEfUkoX9hq7XPnCrZuXIyY5bGZROQfQnqlM52ixGu/vVmL2TpbCvVdynKAVS2T6dDkoGjLdOsNgFh/QX12jLqTUgITuXP3HCQU967Ph/qOPtCd+e8b9WSAsm1hY391r0NpCUAQ/BdSpl0jns9Kd/rkvPFiDEA0Qa+uoWYibpQ1tl9gddMOgCcccYZOOmkk3DkkUfiqKOOwnnnnYdNmzbhlFNOAQCceOKJ2HfffbFmzRoAwDve8Q78/u//Ph7/+Mfj3nvvxfvf/37ceuutOPXUU31+DRbkL9Ee39Rmz2IgjJoUTUQjsPZGQQjHqS98Rop4HlFXyiEmSUGhprFRBBw4A19mdkAyag+oWSx2swo7oX120UpHpFgAmuwM0Rp9IElo7GqCZdkiM5Q5Sllkb9k+EWVvAMLXVnFsKQUOXXZ41d3pg9PZP1dbjrEwDSZZ0Cq12Uo4TqAWWi0pEKW75+eHTux1oj1zdEFPUf2FgWzmOLO7KLDMsc7wyPbJzZ+c13qe4d1JP+GEE3DnnXfi7LPPxvr163H44Yfj8ssvz8Xk1q5di6Hi4N1zzz047bTTsH79euyxxx444ogjcPXVV+Pggw/29RXYUNQCpy/XjHbcJ1iFagJ4SCfqCy2wTHoIdHe1fQnrwtTIHmV21DYhXaFnj/gF6ihpgbPaBIpFlIRdtRyiNd3d1mGBYgGYOzt+sq0gWgDlzk+Ic5QZkBIMDAFKOx9p/QWBFo6cZRrqc0vlQOrq9/xlSwuHQ2wdtwsM5RoojCJWenlVtk8wg0tId1fPzyLC+dTMrnKcHlXAjUrtfja76VZtExnC+t3WJlRy/pQU+5wneHfSAWD16tVYvXq19XdXXXWV9vOHPvQhfOhDHxIYlX8MlYeaOrsoBZMqOJ50r4GjQF7vKdwmZRb4UE42YaciM9gxsp6pHVpDeh2mbpcSRZZGnmYNyNbAqcKLbRf7VhoxyQIw3S4UfK7V+SQx9rU/ZhFIlKQnzgLzXpfIUKlOKyet2gRHKUOVHQl9jiFh4EesHCBnbwywddzuWchp1ipza5LkcxgFuBhC9XYxtUt3HdRzTLlOyg67iJE1ogVLBNXMs+d2NNLZo77X72owjVKotQ5luju/zXlC79TddySoL45QFmdNoVPh0s9hOOmW6H8A5zhJkuDo7pxZvCLqzCcsmNgWTSxU0nSrilpxZ7U1uruHGuyU7q7vmxVFzSDtosFHvbRKxaVq86eykELLpGf39SLB0g6r/oIoSwJ5NowlA2vW6XKwfaz6HF2PmW65BbrMxX4rdfdsjl6gMLfY3jeF6KqE+K9ql2q+0EvF0n0U787yteS7X6R1h8y5UcpuHVTNAskyjFDp/31BdNIDhkr5DeEhb4OxNsmH4wzr0X99n0/YhuBjXNrLmXFCL0S++AJSY8vihXURKai/oDsucguRsbIwb7sA0haVpOruekZSMtuqOj9Uok3SKtGzoDjHcpl0VQdBkv2k0kSzdwVn5o+zVZEtOE2VSR8p54dj7KZKdBsbRctPxvdNNjcKt3dV2W9Ua62xbV4j+C4Sc7SqDcBZsleyOzWhrgNCWPNqJWqifePTbaxJb4fopAcMlYEVggPZBiplM3txhPBVbC/SEM6xppTrkYavUzz1fZQo6O58jq2dFUBrAygvPFI7vPeUrQWbZHRcp7s3O0b29yNydfd0K5ptZcgm2kty/M9RQNmhlM1oF6wsGd0HKHb5HWhO5XpVXIwq4KCxahjp3dkhu1Ckiw4cxRxNPVSd7j7dJ+gcUtLs9fp6umc9n6MZ73V17JJlBz7WAbNAD9Dp+zhhrvFCOBd9QnTSA4Zakx7K4qwp1MVrSAtNG4UxhHH5aqlVHke65RYZKaLOeo0gqQ0LxZOX7i4XQbcpXkvcLlYaZMP7g2txX+43LedA6gvCjse0UOhDWeCUqdmSTjovu6dkd1K2yyM4pt+3nDXpI8LgtI3xwdmus8tiX4Lurp6PgWACoBB7pQtGq9loynen6chytJbk0jypg9kCNLXLbrYWWump4PxpsiVDeYf1BdFJDxg63d3jQDpA76ec7guhpZwqfCU5gddBHcICj5OalRbJsPAq1HaVgBTbool3cW+2lVH3cUGrSWcMQJjIFuGDDos3XX03O273sUvUO5ooaKEgy7balLhDmKMA1aGUr/tX6ZrSGXxOu3nAkrGEgGMu5HD87XYMx67FuPP7lpGKnFjOB4cTakKnu+v72oLr3VmaPxjLI0ZDNRFDbqYEW+IhpASQN2ZBLqjLbnKuEJ30gKGpuwfwkLdBNlGq2TIJimIdbE5GCJOHuvijbHnSFDYRGhZFdEvdGJe6+4Cbup9lFxfIZdJtPeAlHZdRh/tDpRFTLRqSJFGolHLPNUd9vXWxH8AcBRROR8FW4LeZ2O4XSRrxkJdmb1KxecW06MTFtBZsnEHQbH4dtg++mY4+QH8t9X7lPDZs4KC7q+1LKQMOZkCbszyCu2TPRL4OUDPpAazf7UJ6EnbT7cIFYQWa+4LopAcMtSY9hOxzG2gL8YAWmr7qc+qgtdTySHfX67mm+xjFkjRtAOL7Iw8EDOkEdWzIX0aSwnEWSp8khW04bK+YbxX066o0rTFRJLO86ZayzZ9NzyOExR5Q7jctGhgaDlhV1l12pZg4ixZk2UVyE9bAWPdnrsw04NQvyRb7bUzkIlaMJUm+OsdoARgy8UoUx8zWSSSZ9HTLucaZKMES2aBeMU+Z+3xCZa7JCukZwbVA3mF9QXTSA8aAMbsoBXUxL1mfVQc1Eyg5gddBHYNPunvh2PK2f7ItLPha4vDWlCa2lzPzPaVn+dovXpvCpiTc9KtOLI5+ZzViT5oO1t7IZAtk5Bm5EOZOQM0WSZZYZItuyNLdLfc6h93skJzCcbYSk+7slXSrOXKc5QAdFvtj5b2fOyrk75t0Kx041boQEGW9bQKhFNfW1F/gDOqoaxiJ+aJ4jvnusTawMtcE70vJbivzhOikBw6u7KIU8no1QjVZCtiyVCFNpABvv9w62OnuHHYwtUPbh1WFVOsRU7BM3ccFm6iVZJuZLo6LJkpELGIFyArVqAEaatEm6RrsWWAqkctk0tOt1jZT8F5XM3IcX1dl/Kg/U0IVa6RaqGtMJQG6e5d+y2rANnumqK+ljSEk8dha2YGENelUc5BakrSAMZCqB4/kmDdjZW0Z0vrdKvAoEuRMt5L6JfOE6KQHDq7sohQ0sYqgMunplpsC3RTqGHyq4duirpx1mJwOtOZQCiwi1dpV/kx62dGVFdNq32ZIdX6oMsW2chFpIT26FmzK/RQQ2wcoL7yk2/5JsrKs+gusdHfGQKKt9IesLIO3f30pI9di3GNtjua5lla6u3AQi2rdqL2fiRlCgFqT3umQVnCMfRb4uv51GGvvbPmghWS7znlCdNIDh9Rinwu2VmchfBU1AxmSurtd3MOHk14svDjrl2yOCL3abmajeJ64I/dSL0F/2cXyYrfpfcqhFaDXpMsHLSjLZzS6e0BzJyBDV3XZVOdsSbVmbv2SEjtBaI6iUwBnZioRBIZ0RzY7LmNQWLBcUWs1SnQdtGw00TNnK0kSK6UT0WtJtymzZDqWACbu/Fqq72xB/Zq8jCcAVkGfEJ30wBFS9rkN1AkrzD7papbK54hS2GrAvPRJtzgdvItGPkfEFlFnYQVYAlLcDqJapyubXUy3XRZvicXpolIjBlShmk6HnAlqfT3Vc2u7b0OYOwE1OyKYSdfE+QTvdSX7ypmRy2uuR3wBGRsVuzt7Jd1S1y2X7XQPDBVlKXxrKwpRzTZQA+tUTpi2HiGqr1bPd5d2evV20q0aXBNpxxkoe1TTkRF8n+RdK2ImvRWikx44OIWuJKDXwaT7QmrBloqsTPcFMS5lgs8i/R7GpUZduWr3ALs6OSvdndF5tmaUmB9ctRZasicvBeODQ909sSwAZSmOdPNJfm2FM3KzYGIsvCQCnL4yY6pdzuCbRO9ou1J9t2OqgUJOphIF00CtF5YICkuWK1IETk3YxBq7rt/Uf87JGtGCa0Rjn8mu9RnzP2/r7+x0n+R96bNbUZ8RnfTAEVK9dBtoL/BQJ6yA6j1z5oGgo2fDRLluEgtT3VEjdtJVGiBrzWS61TJuzC9Bm3aAiFOqUdWzsTSzyzF2q7q7SPYk3VKyNYqafd4OC22QjW2RpxZsojRiJSPH1V9YE9NidOx0SvR0H1FmVCv14AxiLOhAd1eeU671iC0oLBLE0kr4srHQsyQ6M4SUMS3q0E6vDvagHr0dExrdPaAyJRurVVTdPZu0EUairi+ITnrgCKleug20GriARDTULJUUNXkWjJUXrc+ghtWBYqAF6nT3zDb1oskSkGFcAGv0OuZrpzIvfKi7d7GrO/o0z6BVlEhYLCifT7pmsSwsEx+dHmwwKYwyveiVrJ7gezHRrkO6j/qeUg/H2juaITCm1S0zJhXymvQO7EKJgIJNQV5Ws4GylEG594mFBgHe7hC+6e6ca6c2UNcKkvpQhSBm4W6GkKjrC6KTHjhCy6A0hZ794IuaNoWtTUYIE4et16lP4TiNasu4MNUXjaRmNIdywPRdUjvKORPLpGfPF6+olctul4Worgqt7yMZl+ACySbaREZ37yDOxwWTeizZCo3bGTQxVu5TLt0HGwOEpbxIoQBTBcZswROOYFL2PHQRG7Mpb7MFhb0xPgiFOCeW+ZTomABvSZK69uTUonHZVRlQQa0tlXe2ZAu27F0hZXdeEJ30wCGVkeOCusAJi+6ebkOLdtqF4/yNQ83oU1829XxTLhpNaCJ4rNT9dKsHfsjNaLAxVUSd0g7CizZ1d1qho+xadzrkjHbT7WBAl6HkCGJQwRTxklh0JZZFt6S6O6dd9brmNljLi+hafGrOEGPtb0mAqg3dPZsvVSE04hfbWIBSb7VrDVBSHZNuPWJjjXCWRwyEg3q+ynLqkM9j0qVxif7cpnbZzc4NopMeOLiyixLQ6cyBTVi5g4DWTgYHxhYFYx9RR4kXnOakD0DWK9uEhNquejw9sMF77eyLKLmsTZe+4NrcQFXvqAkvyi9ERoTfRaufDSgjAxTXv6Bm89u0CZTJCkHxvcPUwy1ipbsr9ykDJTpjKnG8s8yOAq0y6TYqMlPAhdJZngUJg3PIsX5T72vegFS6VVkTku9GznusDVQhPR/CmwsVJz1m0mdHdNIDR2g0xyZQhxxqxnpAqMZMAa0GzKOgnfai4aIFKi8uTkV0TW2XKfBhZsKkGDBq6y/JBaFeLz0dS0PD2jGIst7ZZaB0lmeBdh2oFrM2am4oTnqe1ZSnu48Yn2Or3YnlOjCxfQAz40Q9T6VbXUui4zHVTimMz1x2ihZ2yqQrwXmma6lqGIjS3afXgVKfRC2PoOu9rgQxGIX1bIKxEks8qxhuaGtLwfsyZ8AodPcQfIC+IDrpgSO7r0N4yJtCc1xUsYoQoorZgo+QakuBYITjNKbBdB+3YyuotktPVy0+S/ZHnUw8LQgti92mcxRHhwXt+REMvk0sgSCqxaymxut/igJQfLdFgnR3WwBTMgAjxSrSnHSm2vcRYTBJSgciG3uRSW/OpNBasDGtrdT2rj60EygD6xztxGxrL07WSBe2Vxvoazh9LD5hDfqKlCml2+y5BcJYa/cF0UkPHD7bcHWFOiEOlEVBCAGHic0ZDmBcifIC83m+pBemA+3FQWrG2pqGmiZbpu7LLM6s2UWBuUKnQba7bjzq7pbMj8gCOd1y1G6qgochzFFAMQ7ZTHo2J0E4M5ZuOTNyiXKvLGQUWNKV6mmeDxuFnrVPurrYbzznpFtO5pZNnE7iPi2CeoQib2qgkMixswVKOGvStYCt8LsxpPW7vbyM325RpqLQ3QM4H31BdNIDR0h9FpvCSXcP4MvYWouEMC5b2yUfPSVtdVXUw5iY9wcXrV5x3Piy9TorQCrzaXNcRJxSgtpv/R7L9lFlfuQU9gEj6021mGVQVqZC5uzI9qIvzvGA0Rk0odJzueYPN92d1Iw9y9v5mZsec8A77+W1rcP2i3219SrXtbQFQqR1QqjaynJQ6FXRUV7mBUp2JDUsONmBbWALYIsyoNTnNpBgcx8QnfTAEdJD3hRmdlGyN2MdxkILi6ZQa1u5qNmNxsFIG1YdDs5Fk62+nr4mvfhMSXmutStQb2+1q9LdW143Wzuo7pkfTMdFV+c+CzRRM6L7mMPxp4IpBiRJm5QW1VQDUlwlJerxVFool3YGR4mJKujH0lIra+U0al/bqnWb4WJuqRlLH86Q+nx0XDsUnVHo1iPWVmAsGgblgK20wKVP8V8TtqCvSNDCEiwJoeS1L4hOeuDgbGnCDVemNIQJi6PWigJaayuP50ul3cvR3cv7Ke1oisZM4nSA/l3E6O7D9rTzNtDp7tlYmmbSbc9gt3H5yj5PCM6H65hqZqxNHS4HCic9o7vL2UwFyqb7hK8tn4imGhRVMulsTjphL201c8j4zqKgzdqCeFwigEOFzi3xzGp6A0R2dVYAzTHz54mZETNW5gtJfRJbKVgAU7Y2roHQ+gRwsFZDOCE9QXTSA0dotYhNoE4A0i+sOuhZqnRfCBOHlTroIXhgozNz0d0HA4M2zbUAVtvtEX8X9Z7mpvGp0LoU+KK7t3zxqsETqgCeje4u2huXodZXnQvS/Z0OS4IsmLJA8ByrAZiB4GLPKpLIKm6p7Gerl1aej44mpDqSZHPsogXtM+ka84i59Ik7U2xCd8Jo7HKUR6jdVji1JYpnSjbZFSrdXVPq9/BuHCoixCGcj74gOumBQ/JhooY6IaoZghC+i05hDG9c0r0sTdjEb7gWM9kLlIver6ve6vuo4KS7M2cYx4oDkWU6ROnuHRa7aqaYzLG1CEOJqrt3ULs3kWfGlEUmEEYwMZvbJWvS7WUr7Gatgkv0FOnyAhrgLv1JP3fOjKqOHKMIq7WVU8P5Vaf76/uokN8vw4FoiZ8tYEsX9KRbi9pasHHcL3a6u0AwUSmpkHwn18EWPJJpwYap3ZhJb4PopAcOSRVbapTo7gEFHCaWhVd4E6m+TxI2yhYn9TLd6vvp7CC3w5XpKdPdZe4pvSevZHQcU7vtaztVeia1urvaq15G3b2cHeoabNIyY8qbOoT5s1B3lywpoGcrzAKdVaSPhdpGxhLgYtDprTVp6e7a4p+j7/V0mBrdvWlNuk0Hg610wc99qjKTun41Td2diB2mlhxw0q5tPd4l3sd2urv/OTs/74zBRht8rVHmBdFJDxySKrbU0ITjhmHV56iLFaoXGgV80XWd4xjytUlR6e4AXw2xhDqzakOSej5W1XcF7+OJugBqeX/oL+92xzChCUMJBt+sgSCigINaUkBxXApk1182k265tsLBAS7HTl3YZ7bU/VSwiotRlpgwZsqKFmztmQY2B4qPuSUrHFZ8N5A5vxwaBhKldIBd84T7MqjHHzHeY20wsbxvJZkFI63c0P87rC+ITnrgCKm3eFOoYjjpNryMNWVrEQpo9Voez5cmwMVFd1e+q7ql/r727AmpCc1Jy2yl+3mvXeFAyJbGUCze1HpHqqCGXRG90yEb280WyJ1Vsy1UUyCMmnQzqynJ3tBYEsLOD1cmqFDR1ucPcjsMz5zOSsvsMGZGOwTCrGwMxoDLQPA+5aC7q1RlanX3EeE47XbSrWQGV/0e4bFHiyCnqKiqJSgTwOnoDaKTHjh89sruipLj4pG+bUKl/owCErNIlIWoT+E4WzkAVx1m9j0lHGgJRd90O93PfO2sdXeimWP1urVbMOsMh27j0urfvFCi6bJn6lygJNKDmKfK6u5yiz3p2kYtoMtE51YX0ADf/KE+cwMip8sa0GXMpOstxhoGBlU2BlM5jL3NHakJK8bK+5Rq3Wir4ac8JqfzrJcdgM2OZlM5N4NhcY+FsH4vystkOwfl77FId2+F6KQHDqoXqQ+YNcc+nU4Ttn7kIQQP7MJx8uNILC9S+sVMuuWmu0uorarCYYCcMIuWGWO6TjbYFZ3bHWNE6HT5aq2oB/2IMpRqBkKluwcwf5oiXqJ9oIVFNccWR4U++6oHLNlavWlZzHRf92BS2Tnk7JPepYVUHlxkdFS0+1Q0mJRu9QAM3bWl0w1JtwOFdg3wBkukasOddPcA1pYqw0Myo63rtUz3BfAO6wuikx44Quot3hSqI5xuw4micdRaUcDavsXDtbfVw/KJJfFSPAtnR0DRt/RdSM2UoDul6T5xh6nlfcpRcuI720raqshJd/c/T2VDWLRAcLE3KZ8PCbs6zZ6rJCfdss+FlnmdrO81I+sqPWbmMKrXv+Gco4qrcZcUqPR/kYyljWnQ7Ziq5gnV+bKJ0an7qWClu7MHzYvjh0p314JHkgH9wBJifUF00gNHr+nu5sJDsEa0DhMbLTaEcdlq5jwMLGttNBrwKQ2b2SOucgiJ2jST7i7lINqCTUnCP1+oWZu2C5FsAajWj1NlaUZD3vrYkl1rvWzHYyrfJcuMAWEEbHN196Ec3T3RnuP0s0xNevkZ4yr9ya4z1ztJfeaoAgE2zQ+WmnRLgKF5Jt2WXSUcJOwtxiTmZK3khpiaTlnDr2oVDYd885otGCAVNAf0Li8hOKVqkFMywz+x6hr4Px99QXTSA0dbWlcIKNHdBRdWdbC1TApiXLYJzcO48oWGmrUgr8NMt9l7WoLiyd9OLv2ZSxHfZVd1dNP9rGY1p7Rt3Z1eUtHuGKVxWeqHJZ6fseW7UInglcuFOh2WBKbStih7Q3ixpzs/PIFTtR0hwLe45+hRLdV/WS0paZux1+juAmyFoeSczMD4ULOgVBR69RroZTydDmuxUzy3UrXh6qlRA2EhzNk63T397K00zv9SuzeITnrgCIku0xRlMZxwnOEii8srXtIUE805nu7zIhxnyx7xLEyzlz8XRVxCyKcIauisEXahGrUFm5qVEBLI0Ra7De8Pu/5Cx6yejRIrneUlpoXmmg2BzJ9qL+BMOE4kU2h9jiUWmZja5evrXCqX4WL8KM8cnbq78q5gZK+ouh9tAuvq90wp4elnrtIF1UlL9/Peqxz9qK3lQ2RCg3oQQ+I68L+PZe6xNvDV3necdHtud3REJz1whNRbvCnUyC4gV6c7C1QHcci08GqDYPqka85f+pmNjpYvTPX9VLDSMZlrSqWCa77qlq3aCY2F4zA9Bh0dUYKabIPm/FDVpBv3VCisKtV85qQDEoGhdKtmCiVOhVUYjY2Jk80f6X76LC9yO1SitLbnmLNPelsnVB2TOl9SB5dsDCHTPgesjI+uc5At+9rxmIny3h8qHggfa0Suna3rHgtC7NNS6sE9LDWgOwxsrd0XRCc9cISkDtkU5sJDso6wDlILi6aw0Ze99ElXa9GY6uqKyTvd8i2AMzt8L4lyaYdMcE1b8IguCNOtXgvfzCaHurutBZts33i6hVlJ8TuQeUo9nwsYa0pNTCwZOEma/YCRzq1mmwC++cOm7t79mSsH7DgeObWFVJsghtbDekgXpDBho/eq+7mglXURMcZsXV6oBDHV5wmgd2R1uruMs5wdfjBIExwDxuehKdQgpxQrSz28Vm4YwgnpCaKTHji41KglYNbphhRVDJXu7qvPswnbyxmgfdmYYklc1yGxOFDU2RPzXh8IORHFosCgDgpRK9VsSCcRJ2KKOHd9rMuurntAc8wy3b3bcbtCPZ+LFhRLCO66S81ZFpwbVXou16Lb1B/gmj84Ag5qMImqbtkGzfltMXb1TzmzqzahUkBiTp7aHSrBaKoADGl5RLrlPj95UKeDhkFTuIL1ISTZtCCnMNMvsxtr0psjOumBo8+RJ5UyDYTFCtCUYgOaOGzqsz7GpTl/THV1Y2VxB/B9X2vtM/XCrER3121zQRWc0rI2kg5Ty+dap4jrx209LiXbJqvunm5pF8jTYwZHd/eTSbdmUgXeJSpdk084Lt2O8vmDZxE91p4PqsBYuh0wnh/VTlsnQ71vVbVy6oCtjVac2ic1U2l3RLRutJ7zrnN0Ur4HVVtUUIMWUrXhISemKN7ZbW0C0FqwheAD9AXRSQ8cIfUWb4pyzXFAzrCyKApqIlUXUR4nND1YUN5PgUTohaaVNjBTHE1qMreYlq3uDhBwmCyLt6YmbQvAzk66hVkg2iedcD4x589Q6O5aTbqaSReiTmoZbcFShpR1le7jzHCntniudWKZC6no7qMh7+Jfa93VYuzqGiqlI5f3U0AVEdUDp1IOIuV8qmSjid6d6nUEOMvclPtFaI2nvtOA4h7zPWenY0i3apCTXe1euVd8s0P7iuikB45QKI5t0Ieoou9WZyb0DH+6z4u6u5a1UqPddGMxX2hc10Gi97yrk4FUJl1VnlbHwwWV4tr2u1oDUh3P19hyrUUVbAmp+84gVkA16QuHKt1dzgmRfC/aWEXcwnG5fgtTJp2yo4Im1sip7p6U30lNHEZ1SJyaFZroquCcbO1H3dGkpqif6yQQZeezgDbTu3JsWePxXwP9OQ6pO9NEWyvIjEsX0vMrhtxXRCc9cIQkttYU6uIm3aY/h+AM2zLFYQQP0u3I84TmqhujHIq6YExtZTb4HGiuyHZ5kU2zSKq3m24zISSpe9lWH9y2Jl0/RrdxFVksWa2J7HaiFOVRA3bq1vcCR12kZ33SAT+dDCT7pFO2oTIxUdpFZbYAvoClJgTWtaWWxRnieMWrz0Obd4U6J3KKZ6lB4YESPOVe92isKqIA/5ghADM2HFkuRsPEKiJKaqJs0wysCrK56sDxvq2DLtbIx0SaZ0QnPXD0OfJUogAHNWGlW5WSFsLEYYtc+6S7D5TFHEB7H0oxLax0dyaxoJISt1h2UbcvVR+sKuY3zbDYOgjQKU2rNaedDtnIrp5t7XbM0j3F5CA2hS91d5WqzaUtYbdb3KdcGTlTRLOYP0jNGGUZ6T6yzOiA912qBjLazK9meywuEUCnoybkEKkBSqryIcp3p4shRH3L6O040338CvvpNpufuDoItAHH+7YOiUl3J2Jj7EiITnrg6DXd3VV7FMCXsbXzCWBYLLWt7caB0jgArhZs0+wRU3TXRt0nDwTkTlr6sxi9zpXBF6q966KdYHW6CIWOJINcRfaM7hqESncvGFKmWBivXY2q3TIw1Abq9+Wic6t17wBnJj3dajXGRHXLQ8J7f2Y7TTLppfs2/ZmzF726FXMQB3TlQxzvzrHxzuKapzmCFrU2S3R3iNidBfn7dshXtmPCFGvkWuPNM6KTHjgkxY+oURbRCM8ZVlWxQwgeaOq7QpRpG/R64WI/qbq7kn0E+OnuWr0w14LA+C5SLdjMBSH3dGFra9f0xau390n39VbdPeH4Luk2tHIhX22GbO31ZPUG+DPpZi0rZ+kPVcmAU7+EKZDRtp7ceY659UmE5qHEcn6ohOOywAZAEdRJt+XgPF+wRKo8RkoMtw10HaZ0n2QLtsFA7l0xT4hOeuCYB7r7IJ+w0m0I30WrbwvoHCeWF4ufTLr+cuZwEMzsERcFS8/A8WT98ppk5gWgCSfdXUiwbtBhQWhrVUS1qFSDByLq7ppYFM01KGWcAlnwlbp2CAlcauwNpaRArIOCGtAlNlluV5rt55kLtcwokdM1UNgrAEMg1FJj3Kgm3ZgruVt+mvoC3NOQqrJP9d1sQpxd352q6CjAF5zX6e5CmfTSdwvHKS2y/HLvRvWZ427ROK+ITnrgCIku0xRmTXpIrABdCTX9HMREqr5YvArH2bNllKfITXdnjKiz15RObUkJ1ZQWhOl+qQz+qEO9H4VCvAlb1lMy20qpKu8OYnU6bGcUAZr0Z6mstq1ECeB3fqwUcWrnWSmXAPjmQnXOpRIiVBf/A2VFyeV06fPF7P/epCJzOVDme02OaZJuKZ0hlSJNrRtSJG94g/OjYfE8cZfklINtYczZgFFeJjZnFzYBPpHAeUZ00gNHkfnr301tPqAhOemqGNAooHOsRTs9RmFLDjTDpF6mu/O80FQKGhf1sFSLJlyHWBackssutr03rNn4rj14LQsR0WzrgC6gZT6DoSxwctZIFhgSz8rwZmxddtuqis8CNesHyLCKiuBKt2OqzrN6XagdoiJL2Y4xVHKexejuQg6Rjc5M5FBTqrtPzPmDyWG0MTwkS3KAcNhPgItFw2tTqoxnnhGd9MAREl2mKVyKtSGIRoyVF6nUInMWaAsej33S1QURoFBaOeju3BF1hlo9EyXHhWkxb0IN6qRbmZevWi7SdiHCImLlqI+VyrZmrfAAugVyKQDjeZ4qiyPJUknVYJs6Hja7NpooF9unFPggNWOUg6T7ugawbHOBup8KWgeFFvOrFLOvbCfdzx0ozOc+QhYeR/mQ2UucqwRNPR9Sa6lSKVBA63e9Y890n9TcyVzSOM+ITnrgCIku0xTlGrB0G0L7BRsF2odAm4mxrbbVw/kyAywcL1KX6Bkn3Z3PhnGvCwvVmFlNKRqb3paq6THKC0CqReVAyWgD/M+QrfUbGd29FIDxO1G5WkxxB1816q0qUMbOkpjaZZyTy8E2fT8VVCeCTt0dpWMCfFT9tmUHJs2aqzTIZBBKtcUsMsf0bB6VJUHp+GfHVvdTQc3iDoTmTpPZJhWsnwWapofQ2tJd0shqdq4QnfTA4TOb2hUuWqRvuiZgz7iFcI5tqvNeatLNhQbDpF5uH6bvJ7OjXGtusaAB4/mywQx0yNHsi2vXVjHfpojeOaunXmvBbKv+3Or72kJ1SgG+IFZTqNdN3fqqSZeibJqCdRw2+NXd062a9aZsFcjVrhOwB8KaZdLTbfZvuenu2anIHUTuemjluSTT+FDea1QaBqXgfEajZ7vXIZaIKa5B+nOIa0tJtXuTWRDV3ZsjOumBIyQqdlNI1Ry3ga46me7zvfgF7BOpj2tvthLhuA+lXmi2tkNcdFVzAch96VwK4GL1j0O01nTIFkyjAR1FXI3cS2Zb9XpQalaALK28DmOFRQEIlnaodHfGjK0JGzuDa47irtPlUHe39a9X91NBm3NaOelGUJgpq1d6boUDpyO1frwzS6I4JtU7zdUnnbyTQWK514UCiSPme6wNbKULUuuTQp9hOpYA1tp9QXTSA0cbFdNQ4KJF+l5kpmNItyp1MoToHsdivw1cfb8pJ1cn3Z2R9sYVyTWDGlRZhzqUszb6fj67mNrtru6uOvpd5zmbunt6XO7FGUp2u5osUaDzhWa343aFywnhL+1It9z9uE3YOoHQs33SbTkgQ2pGm6c4MqNc7TpTO7Z3Y5t/D23LxVYw23HyvwvSre6E0TjpwwFdFrTcgo3n/KhijD7ei+lWxu4sUJlIUusT17UO4Xz0BdFJDxwhObZNUaY1hUHXBPQJKyx193SrR3/lx1GiUTMsGk1FYy6mxUQ5p2zq7qWsJ48dEyYlWr7/afue1Vb6KmG9o0aJZn6GrOKERM6PmbH2HUxUWxsBaF3u0NauKhwmYZfiXp/VRkl/gGme0lpqde2oYASTqI5bsmMJ0jQ5P64SLrZa6OnzIecgqs8HUQAmO2eE786SNgBbCcn0+APJQIn+3UJav9t1mLjn7MIm4LeEs6+ITnrg6DPdXW1zBgQWVVQX8wGdY93JSPf5acFmLjToJ1eVJgnw6S/YHDfqU1rKnuR2ZByXknaAWH92XaCtyaWzZsa6Zn4sdF6K49ahyBjQMUKcbbk8L3DUkgJAru5SL1GSzI4VcyFXLXxZn4OJVaQsmqm0E0pUfaagjerctTk/bro7z/tGskwlSRLluaTLTnN0RpHSUbG1G2SfKyaOZyEAp1R9TqXV7qVLP+YJ0UkPHLmjFsBD3hRmPUooNZWA8fLJX/g+R5RiorxYfFKDJF6kaqQb4KOI2xYabHR3M6ghluXD1L4stVLN2jS1O7GyRmgWgGa2VaoVXpeWdKVjlur5eDJOTeGqKfUlQsQvyJVuzf7sHHMhNxOHU929tBAnHLsa7FRbajWab4xgQvFOIxpkZqek2cD/3KrHVufTrreoLcDdPTvP78iq94uu7k5mwgpXCV8Qa96OQa4uNkusqx6W7/pCdNIDR58jT+aEJaVyOgtsNem+M1QAD2221TiMDC0HC8KtaExmQjseZ52/q3e0VEbbvE7sPXk1CnB5f7Nj0Cmiq4sCrZ+yWD2o4kAQOT9mv2XfdHeTzisVPFCpt+qW83yo9415r3OwirJ7h78tFR0DIhfoyoJJDO+KsXEd2pwfJ82ajbllPLeMD4h6HtR5j5KZpAYburxfTEo4z9qi+Ex5r9fbdaxpAljzqgwoKRFnk3UVEpu2LwjCSf/Yxz6G/fbbD0uWLMHRRx+Na6+9dqZ/d/HFF2MwGOBFL3oR7wA9IhSxoDYws4shtV9QqfgDgZforMhOzWjQvrUVBSQytKaDyRWQUsVLuASnnDX8Us6hKcIjResbtFdRVwNSdOrujmCJUNAiCw6o+9rC9V18BxNNBWMfbf80u0LOj6lzQPl1nfocXMHEId37pXjP82VGNadr2E74ypXl5BO4S3+WeG71IAZh1lthSejt9bof0xTWYwvqDOkCp7V2zQBmQGveiWUd5C9o4f989AXenfRLLrkEZ5xxBs455xxcf/31OOyww3Dcccdh48aNlf/ulltuwZlnnomnPe1pQiP1g5Ae8qZwRZRDeEBV5eSgaPjquITqi21w1p0SnqIy3T3bz7MwTWleyn4WVgCmW2nHJf1ZWklYpc41tWujEXcNRpa7Ekidj+weI/wuZuYvEFZVydkRuufGpWcsGw+nk158VllX6ngo7ZQdSDITAOzZtM4dFZRSD4Dnfaoea6TUGHeiuxOxd8p20q1k61n1K1DS3VWWhFrq0eXed+ovEK5z9OCavJp5sW6ajieENa/CYBCfswMMWvQF3p30c889F6eddhpOOeUUHHzwwTj//POxdOlSXHjhhc5/Mx6P8cpXvhJvf/vb8djHPlZwtPII6SFvClPZMSyBtnSrLaqDGFeRlfAZdXS9SCXo7vR1mMjtDJVFNul3cdDOxTK4jAvkKrtmq7NGwnEWkTfKdlDZsVNbnQ5bb1epQ6X7LrpT4bMlowqX4CO/OF+6lQwOlBf79t91RfmcMmXSFcYHFROhlBllcLrMTHEbJ3TiCnpx1f0LspvM+5SKQaSyJKhKPSbGvc5RDqAFdZQ1HvcSz+wgEEpgVRUWHAmueU3x6JhJbw6vTvrWrVtx3XXXYdWqVfm+4XCIVatW4ZprrnH+u3e84x3Ye++98epXv7rWxpYtW3D//fdr//UJoTzkbeDqk+5boE2dIEYq7S+AiYND2KcNikVj+jPni3TIXYepOoOqQ0kauU+33Ivskl2jTnfAsEC22iUoIVBrE+nV3dOfxej/lqAFVU26GXDw/SpIjHmdy9kx4XRkxZwfo5MBx1xonFMuKvZAqa+nK8tIf+YIxptOaDt193RrCrpRr0fMlnRU57kK6nkYDEBWwmdrkwl0+y4mI4aqp7sK9WsPBnwJABNltk8ga17F/lDRLOAXVC1sqtuYSZ8dXp30u+66C+PxGMuXL9f2L1++HOvXr7f+m+9///v41Kc+hQsuuGAmG2vWrMGyZcvy/1auXNl53JII5SFvg1Kd3VDf7wulhZeQ8NEs0NqGeIw6lrJWHJl0I/vMJSyoOoN8dFU/L+dSBwWhl69aqtC2hGCsBk+I7nUfok2a3SHdotPlDPte4PguKSiXlHDaLD6bjgqtGnW6LTJOmX3qgGW61buaEDlynJlR5Z2giTO2CApy18eadHcJ7YREOT9qprSrXY2F1rKsqeqY6pbjfZwdPw9aCGWOQ6vBLgW5xMri7OyVqO4+O7zT3ZvggQcewKte9SpccMEF2HPPPWf6N2eddRbuu+++/L9169Yxj5IWoTzkbeAUtfI+YRWf01Zn6Wff4wKMOl0hGql9HK6XDaUN6DaYs0eqSCDAxArwRDuXppOpGbm2PasTy73eXd19ekwj2yrZr55qPjFrfUOZp5wlBUJ0d0n6v6u2Nf0dnZ1xYl5rZir2gDIwlm45BUBLNektxi6hKq4ez2QWSN6nVFlvlZmklTV1WAeYLdg4stwmW1LqPVBe82b7fc/Zyv0xlEtMla91ut93oq5PWODT+J577onRaIQNGzZo+zds2IAVK1aU/v5Xv/oVbrnlFrzgBS/I902ms8WCBQtw880343GPe5z2bxYvXozFixczjF4GoTzkbaCKoKXbUJx0I6oYyLgAnSrnc1wSQmhl0bPpfq6adIPuTkqvc2STuJ1lF+NBrv9psTDfniSNFm9WdXeyTDq08UnVS1OWz5RqfYUWmnUoLbyEsiNlgTJ9Pwf0FmyY2h1gPElY50KufsJaiQnRs6F2NgB4nNJxol+HNvOcOWdxOc+uYBIv46M4eEp31xljbRf6miAmlePvyK6ytmCreL+Mx2Ns27aNxO5gvA377jrCnkuAzZs3Y8lwjH13HWHXBQk2b95MYqMNNm9NxwEA27ZuwXA6zkcuGbCOK9me2tl76RCbN2/GLgsT7LvrCEsGY6/nQwKLFi3CcNg9D+7VSV+0aBGOOOIIXHnllXkbtclkgiuvvBKrV68u/f2BBx6IG2+8Udv3lre8BQ888AD+7u/+rndU9lkQUr10U7ioP77jDS66u+/FL2Cv9ZVmUSRJUo4IM2T1VZE8gK51ldOOcq0B6kw6pjZ4F4AmTAVwqdq7Ijgw3Q4HwCRpWCOqXBeihazJLJAKdI0ZvovZwjKUd0HZodT3S9mVED8y6e6Z/TGxXWfgg/i7ZU7/aDjAcELDjpJgEamOneowNnk3mgFNrvtHZdVw2tFsKs9GyaHucH2zcq2RwhBS7bVBSRuAhaWnBi3sQeAkSbB+/Xrce++9ZHb3HmzH2565N5YsGOLXv/41fndx+vNOC9OffWGSJHjbM/cGAKy/bS0WjNOfFwwHrONaum2Mtz1zbywapXaO3nOMg5+5N3ZZPPF6PiQwHA7xu7/7u1i0aFGn43h10gHgjDPOwEknnYQjjzwSRx11FM477zxs2rQJp5xyCgDgxBNPxL777os1a9ZgyZIleOITn6j9+9133x0ASvvnBVQLPh+QqD1qA10p1q9Am4nspTjwOK7EsjAt1FH5HFsuYUF10ZRRs5OEtyZdune0mbXhvmXMhWgb5gCPuruZbaVfAFbZ1ZSVu9LdHRRo3/okPgTc1ONnz9ZA4N2o00TV65CwBPnM+5Y6cKwGztu0MbOhxHBguC4u1exWQUEjk059/5iZ4jalQE3hCkB0tasGCgdTR32SdK1zN+aP6VBJ38cOSr1qInPQ9957byxdulRjH7TFfQ9vxYL7NmPpohFWPmJn3PvQViy8fzN2XrwAj95jaefjt8V4MsH2jQ8CAPZbviu2bBsDdz+EBcMhfnfvXdjsPrhlG4b3PIzFC0bYb8+dcecDW3D3pi3YfekiLN9tCZtd35hMJrj99ttxxx134Hd+53c63VvenfQTTjgBd955J84++2ysX78ehx9+OC6//PJcTG7t2rUklIG+Yi7U3YOrzyk+64tqTwNSUCxE4W1cJtMA4FENN8shuJgDtgVMU2p2HUoZXKGarxLdXVgQplhoNZ+nVMeEinqrZgoBucCg6kRQqVurbd3Sbfqzb8aPM/jKfs/pdiVYI2bwTbXPMn9MlzrZmo76u6kt2KgYEGZmlGPsbobM7MeQKr/LzwdjzXXZph401bRXOlzfcjB2gEnSjDFlwmyFx/HeL+aKqQ3jPTAej3MH/ZGPfCSZ3YfHQwwWTLBg0UIsWbIEi6Y/jxamP/vC9vEEgwVbAQBLlizBYDTGYMF2DEdD1nFtTUYYLBhjwaIRlixZgoVbgcGWBAsWLvJ6PiSw11574fbbb8f27duxcOHC1sfx7qQDwOrVq630dgC46qqrKv/tRRddRD+ggBAKxbENpJywplAXuaPhIKhAiC27KD0u9fKYmR1aRWM92s2VcbBnm6lrStNtKespRHfnzErYYKW7o9n31dTdiYSyyu2gdFtc0Fuw6fsojgmE8y5wiRWKB4YE5kczg8tl1+x0wSaiqWS9qb6H+cxxvOfLZT3ptk1QsAjyND/GbHaMaylwn5otU9u2xTRhnYMm3VgkY2P+4GDEmIwqM3CU1aAvXUqb3Ta/QmbXd2BVxUD5v9ywVKvl8zSPyGju4/G4k5O+46aoewKuF4kESlm+QGjlOt1dRoBoVmh9bIUcPdcYgHIkmoPuzhkIUI+XC9UwXO9yQCrditfpCgXCzDZcbRai6uKeyrEtBy1kAl3qIpmKRlwKhAQyf0oIP9lQzoTq+zlgOimaXc7SH6bnWM16U9PdS11cCM9PdihT9K2NuruZjedWd+dqLaqimu7e/rgTg5lUrAPaH9M1Vsr7JQ8Al8pH9L+joLjbMDC2vuEKHojblTEbBKjureikB46QsrxN4coEcdeH1sHMFId0jjVhn8xx8eikm1nuPtZxu2rfKe2YrACpe6pMc6TPSsxit42Cseroq+UBXQJBLgE//pZ0hV2q72LWpFMskClQUslmKIWxoeSoCTxjRfa+2DfMF/yEToXrXUn81SaWZ46qCwFnGYKZfW3j2LmCS+R091KNfrqfM7hWSXcnyaSnP1NcWycjhpSll25L4+ZmmDlyxP5XlgVU59E1XjJkz1xuXNsdMQOikx44QmoP1hRjISesKUz6cyg0fEB/KUq9WMpjKD6XM6WEdoxoN5eDWaK7MywifdHdzXpQLpqsiiRJ3FneRpmt4t+SZX4IFvNtoAZpyL8L433bBqVMGEPnBxvKLdj4g75WujtDUKLc8hJTG7TnVGV8ULUGM+vpObq4uLpYNMuk6/+W6/5JjDm5EPPkez5Mlkkm8gZ0W2+Vg7FTeyR17unPHBoGpaCX1DrazNQ79vvCwKCdA8B+++2H8847b+ZjXHXVVRgMBjOp4udfe6BtIhogOumBg8M5kkKZ7p7+HIqTHhqNFDBrW/0ENcyeq9l4AB5xF266u0TPd7f+ApkJK8zskETAyR7ESX9u5KQrGdnMAW16jPLYXOej9SFnghqQVL9LN2Vl5MdUt76ddKe6u1jdP6Zb/nnbRne3tXPqCpMlwBXQVt/JVHT3cv0vx/lxsDeaZNItImhNjzELXKwITqZJHvBU5h6KWvixcr9ox+w0R0/Hx1iz7xItBmTqw/PpIgvQkBxzUPnf2972Nue/zb/yQN8mCfDDH/4Qr3nNa2Yex1Oe8hTccccdWLZs2exjNz7Ncj6aBAPmGUEIx0W44YvyTIGJErVPt2Fkgtz1f75GVEBVU/U1rkSxxylaVRbY0fdTodS3liHwRbGIbIMS9VjgGXO3pWqWPXP1r++0qHRRsbnLDpR7TF0QjicJFo7aHdOVOfYtQuR0loWc9KKDgr6f06ZKH+aYp8xrzfUcj5V5Khs/VReCopxIt0UBlwZGE8e3THfX91OhFCgUYjcBtmBSN5E3tQWbenwKdXdO3RCXmCHAO09xzoB33HFH/vmSSy7B2WefjZtvvjnft8suRSu1JEkwHo+xYEHm4k3vyelPakZ7r732ajSORYsWYcWKFY3+TQn9c2e8IWbSA0dIWd6mKNWHCtXL1kEqot4GakbFF91dtWe2fyJdmBo0yQHDyxqoEDBkYAVIKvoCftgqNmHBNs+QmpFVKeLdFpX6eHJHTrAmnSrgYO9K4H+ecqm78+svpNtSP24B1oh6TTmcCrc+B5kJzc5gQHfdnPcD5fyaBQI6sDfMAB63OF/Rjz39mZXubtw/gPp8dDiuuVYirEnPgyUMTINSK07VSZfIpBtbCq90xYoV+X/Lli3DYDDIf/7Zz36GXXfdFV//+tdxxBFHYPHixfj+97+PX/3qVzj++OOxct9H4fef8Gj8r+c/E9/61regZrRNuvtgMMAnP/lJvPjFL8bSpUux//7746tf/Wr+ezPDfdFFF2H33XfHFVdcgYMOOgi77LILnvOc5+COO+7Iv/X27dvx+te/Ho9fuRxPP/SxePfb34KTTjoJL3rRi1qfj3vuuQcnnngi9thjDyxduhTPfe5z8Ytf/CL//a233ooXvOAF2GOPPbDzzjvjkEMOwWWXXZb/21e+8pXYa6+9sNNOO2H//ffHpz/96dZj4UR00gNHKI5tG5Sj3+n+4OjuAam7q45LCOruJbo7abRbPzZHrSfgzthz1MCVsjRC2UUzayPRlgroJhalXn81U0mRSTezNGJZXuW57WrXXfff+pAkcDrL7E66P9aIje7Oos9hfDdaMa1Eq5emprtzliFQ2CgH8HiCXokRtJB4j1e1CuyU9Xa8o7ucMlMEkCOwbJZgqOfFZiZJEjy0dXv3/7aMsXnbGA9vm6Q/b9uOzdvGeGjr2PlvKIM3f/M3f4P3vOc9uOmmm/CkJz0JDz74IJ73vOfh65d/A5dc/h38wbHPwgte8AKsW7t2+sXtx3n729+Ol7/85fjRj36E5z3veXjlK1+Ju+++22n3oYcewgc+8AF89rOfxXe/+12sXbsWZ555Zn6uP/GRD+Hzn/88PvJ/PoF/+PLlePCB+/GVr3yl03c9+eST8R//8R/46le/imuuuQZJkuB5z3te3l7v9NNPx5YtW/Dd734XN954I9773vfmbIO3vvWt+OlPf4qvf/3ruOmmm/Dxj38ce+65Z6fxcCHS3QNHSKJmTWFSjjhq1drAtZAH0jFzteWYBU4K8CTRosESYxgMyvRLjoVpWQiK9v4we8hyBBzKVFyZrKeb7s5n06b+n92aTRYc6mJNv9e7j60IwMk4kKqwFdV3KZdppPt9092Ley79WeKeA1QGVPqzSEDKlqGUFJ4knaOKz8PBAMmw2N/lvedqwUb6rnA5do2E44zniSDTbEO5VSB/oqWqVWAnNo+DfUDJdmJhXjiYKUA6drMC6eFtYxx89hVk9pvgp+84DksX0bhi73jHO/DsZz87//kRj3gEDjvsMGzZNsaCDQ/gdX/9Fnz/W1/Hv/zL/4dnvuRVTnX3k08+Ga94xSsAAO9+97vx4Q9/GNdeey2e85znWP9+27ZtOP/88/G4xz0OALB69Wq84x3vyH//D588H2eddRae/8Lj8Zt7H8bb33Muvvev32z9PX/xi1/gq1/9Kn7wgx/gKU95CgDg85//PFauXImvfOUr+OM//mOsXbsWL33pS3HooYcCAB772Mfm/37t2rV48pOfjCOPPBJAyiYIFa0y6evWrcNtt92W/3zttdfijW98Iz7xiU+QDSwiRSh13G1gRjNDaSHkoiYD/s+zuhjRXiyCJ818iaafp+NgUWBNfx4QLCpscNHdaWvSpzZKGVw6G5V2BbOaVqZFi3lKo94S3esudXfJsgP1uSFVVg7kXWDWv8pl0qHZFXF+LBlKzsxfUUOb2Secb5VjqUyt1H7740o4XS59hkblNY5sPFfLT+7gs26zHEyiYGOUqenplmKONoM6pAGpjO5ulD1R2wkNmdOZ4cEHH8SZZ56Jww59Iv7gkMfg9/bfFzfddFORSXfgSU96Uv555513xm677YaNGzc6/37p0qW5gw4A++yzz/TvEzxw/324686NOOqoo3L+/2g0whFHHNH8C05x0003YcGCBTj66KPzfY985CPxhCc8ATfddBMA4PWvfz3e9a534alPfSrOOecc/OhHP8r/9rWvfS0uvvhiHH744fjrv/5rXH311a3Hwo1W4Zs/+ZM/wWte8xq86lWvwvr16/HsZz8bhxxyCD7/+c9j/fr1OPvss6nHucNCosaUC66WJ6EsMl31Sj7pJepiRHuxdBCgajsG1XHiqDtNzPuDqeZ2bFxvlj6+E30xIyXyVVp4CtRgW+nuLa7dRKkbpFN318clleVV7zFNOI6Cakoo2kSBUuZUqFzIh11rhpIx82dSpDkCAenxoanhjSeJFqxugvIcxMc0MPUZmpgozw3pzxwq9ICsloRV3Z3Abpma3v3ed3dCob/XrXT3CUrpyZ0WjvDTdxzX2e6dD2zBhvs3Y/edFuHRj9gJD27ehlt++xAWLxhh/+W7WP/NToQLu5133ln7+cwzz8Q3v/lNvPs978OC3Vdg6dKlOOv0U7B129bK4yxcuFD7eTAYYFJBObH9vVpek+8XbMJ26qmn4rjjjsPXvvY1fOMb38CaNWvwwQ9+EK973evw3Oc+F7feeisuu+wyfPOb38SznvUsnH766fjABz4gNr5Z0SqT/uMf/ziNigD4p3/6JzzxiU/E1Vdfjc9//vO46KKLKMe3wyOU3uJtYNITuTKlTeGKqAP01LemUBcjVAJUzcegO5zpZ/4XKZ+Qj92B5qS7Z7akaqElRRA1urtht4nZslZA9+virEkXqpfOSkQoNAlcGWvfrwJXRlvuXk9/lhCss9LdGTN/5ewimYlSmYoaBCZhfOTPXLqfoya9i+hbibrNsLbS2AoDfStzn9qCSe2P62aIdZnX0m2XgEsdintyaquGqTUYDLB00YLO/+20cIQlC0dYumiU7lu8EEvyffZ/w1le+YMf/AAnn3wyXnj8i7D/QYdgz72X45ZbbmGzZ8Ouuy3DnnvvjR/+8If5vu3jMa6//vrWxzzooIOwfft2/Pu//3u+77e//S1uvvlmHHzwwfm+lStX4s///M9x6aWX4q/+6q9wwQUX5L/ba6+9cNJJJ+Fzn/sczjvvvGCZ4K2Shtu2bcPixYsBAN/61rfwwhe+EABw4IEHam0CIrqDoxZYChyLcApkLy2Thg/4z1Kpi0IqAaqmsNHdRwyLRjOiziHIpEZzTQV0jj7HXTLLbeBUlRfILgLd6O5jy0Jq3LFlkNORYzwfpiBXZncyTkiyWJwZyjYoAlLpz9KdDEQFuaaHVhfSbQJS9XYc70qGbHRuh8pJN1uwcYzdYCp1La9Rj0HrHBafRenuxrtU/UwS9DSYSV2+SqndIIv+gsEAMJlaTKzE/BsMtI037L///rj00kvx7Oc8F+vueRgf/8AaTCYTsXFl5+PkU/8ca9aswYqVj8Guyx+DL33mk7jnnntmClDceOON2HXXXfOfB4MBDjvsMBx//PE47bTT8Pd///fYdddd8Td/8zfYd999cfzxxwMA3vjGN+K5z30uDjjgANxzzz349re/jYMOOggAcPbZZ+OII47AIYccgi1btuBf/uVf8t+FhlZO+iGHHILzzz8fz3/+8/HNb34T73znOwEAt99+Ox75yEeSDnBHBwW9yBecYjjBLDJ12pv6O19QsxJUAlStx6Bmjxjo2zlrwKwzZFqYclJJXRQ+7tuppAotEBxQleyLhaj+uzrYgicUTBsz4ybBaCg5P/m2Y8DBXCAzZCjbwFlTyk13d1BYJQS51LmYI1giQxlXs7z64pgiMFawiOivi0m7blVe48jg8p3jdMtxPsp2pzZtdHfKoCfBu1NCf8EMXmf2JonMGs90PV0Cbdw499xz8Wd/9mf4n894Opbt8QicevpfYrL1IfFxvPb1Z2Dz/Xfjtae9GoPBEK848RQcd9xxGI3qoyVPf/rTtZ9HoxG2b9+OT3/603jDG96AP/qjP8LWrVvx9Kc/HZdddllOvR+Pxzj99NNx2223YbfddsNznvMcfOhDHwKQ9no/66yzcMstt2CnnXbC0572NFx88cX0X5wArZz09773vXjxi1+M97///TjppJNw2GGHAQC++tWv5jT4CBo0XfyGhGKBk/4cSju5KuVP38GQsSJ44ivDb1KGAR5nJzEW+5z9hwFbpofMTMlxkepkUMoOCTxjZkZT/Tzr82MLnlBclxJLpoXAVGOb6j1mOABdzLrYGf7V3dNtmSHFa9cXS0K1qX6mvKckmDjqeRoOdHYARUeFvJyIsxzACAq2obt3aRtZB/UrF9R8kNsxUUl378SSMILABOfMpb9AGiwxmBdAwW5K7fPkkotvoAeJqX30k08+GSeffHL+87HHHmt9L+y3337413/9Vzy0dTt+ufFBLBoN8c7/968wmST48e33AQB+9d//jZGSqbIdJ+uJbrNljgUAXvSiFyFJEtz5wBYAwIIFC/GRj3wE73zvB7H27oew08Ih/ujpv4eXv/zlzu/o+k4Z9thjD3zmM59x/v4jH/mI83dvectb8Ja3vMX5+5DQykk/9thjcdddd+H+++/HHnvske9/zWteg6VLl5INLoIn6ycF10vRtyNsRp1DUndX61CpxLSawhaFZll4GYs7ikyqCV3ReLpl+S76saVEEl1tumSUhNUgTjNHzRo8Ibgurowbp2Nrq0OluP5j4zyHR3c3nXTmgJQP1khF/2nKe6rcxgzkNkzGh3rkTs+cIgCpbllaanW49uWAZrolvY4V85q0dgLF2rH8Xkt/puy9zlF2YIrFFvYydhOPk54/VAP7bm8wB6CMT8K1uO22tbji0u/hfxx1DG7ZeB++9NlP4de//jX+5E/+hN94z9HKSX/44YeRJEnuoN9666348pe/jIMOOgjHHdddITGiQEF39zyQFijT3bP9vjNB+uJXzSj4ZiyYPb1HwwHGk0T0nNmzR90zgybGRpuUwrGhs5EYC1PVDkfNJCUtcBaURHgEHDlTyV61P6tda/CEYOzmvSuh7m7LnlFkW03xoyLj1PqQJJhMXOPiZo2kW8n3iU1Ek+M6mE4WC6Vee+YGmnPa5RyaAocS5QBtgmAupXKOwDOgBp8FnPSKYFKX+7QUKCQovywLDdKfH5OZon7mXUtP54vpT0yhgMbIz+xA24hZHg2HuOiii3DmmWdiPElwwIEH4Vvf+lawdeAhoZWTfvzxx+MlL3kJ/vzP/xz33nsvjj76aCxcuBB33XUXzj33XLz2ta+lHucOi1DalrVBaeEhkPmYBTYnNHeGPS+AzZcihZhWU1jruViogQ6mBTPdnUM4rpTpGer7uSBBNTVhBgZUu7N+38rgSaesXnY+6LLztTYrSyros1i+6e7O7JpQaQdnxrbOJsATHDCfKQ6hTvO9l3UhmCRETlc+B+n7KVBqm9rCsSuVFHAEhW3tKQUChVa6O8F1KErSsmMSMISMgDZnQMoWtOB8J5ePTJ/c6IJBTsMvzgvn0LJjP2rfR+MHP/gB7n94G2757SYsXbQAj9/b3pIuQkerFmzXX389nva0pwEAvvSlL2H58uW49dZb8ZnPfAYf/vCHSQe4o6PXdPds4WHSmnw7wpaa61Ba3ZmLNY5a8DpYzw+D0+miH5LS3bV64WzLEQyYHrtUZ0dmwgpXpoPzNrbT3fXf1UG9LpRCTqY4lLTafWlhTlAPKtlebxbYAomAHN2dc3Fftjm1ZVvsMzgVnIrgNgowxX1apurT3w9jQ2uilbq7MU4eMVRlXjOCwpzBNZN1k9rtfg9l57dc2tL6kO5uKwzXQT8f9HZcyDPpgaTSbd9YpGd5xn4q7e6fP+MLrZz0hx56KJfE/8Y3voGXvOQlGA6H+P3f/33ceuutpAPc0SGVkeNA6aUYiCNszxSnW9+MBZdKuI8+6db6NtJFY7rlVNu1ZjYY7kMfPZyB/tLdrW3cCII0ErThkk1LTXpOcSUQ5CoxkQLRzSgCiTLjKmXwGbLNZZu686x+ZnEqjPuWI5BoaydH0fe6THdvfcgSSm3/GmpgABYFfQanbWyb1yTmIIPKDxAFCo17huLdaQZ1OHRDrHR3EaHJ6QfDK/XulGbzmLpvoP2Kx6xhK9/2z53xhlZO+uMf/3h85Stfwbp163DFFVfgD//wDwEAGzduxG677UY6wB0dFG00fKHclzTd+s4EJbYXWjABBHuWynefdA7VcInewFrGVmARWc6kczsuRnBAINtqZqvVz7M+P+o1JlV3N8sOGNgZZZvFZ8pAkEvg0ne81gzSSAWkyqyRdL9IhlINSDHOhWb2lUPx2ubIdXnmXGKNpAEGAoFMc97ibME2GMiW3JhdLQAiZlJJ3R3djykQSLXS3Rme2zoEkkgvMLB9FGQWiFmcH7Ry0s8++2yceeaZ2G+//XDUUUfhmGOOAZBm1Z/85CeTDnBHh0SPTS64KMBJ4reucmwEDwCZaPcsKFFcGZRPa8dgrW+jX2iURL4YF79AOWMroe7O7rh4UHc3tQSA5pljm2NLcY+V2oMJBEtMQS6gu5aIOj+Gpu5ecsqExlWqjxWwa9Vf4BCedLAEONk+qj0KgUPOzLEZsGql7l6aK+mDXvn9Ynl3ypQgFfsovp+LzdOtzn06Psaafeu9Ljh/ms6578BqlXnOoSmrL+X/EU3QSjjuZS97Gf7gD/4Ad9xxR94jHQCe9axn4cUvfjHZ4CLCaVvWBmbGWutHnhTUNWlY6e7BZNLTbammVnBcY2MxnI5jOj6OaLdJ1WaqezfrPUlrEc162YG+nwsm60GCemzSRoHiWZ712nE4tkB5zpEIclm7IXRkDdnauknWVFYhv+dKGUleu6X6WIEMpVkrnn5OtywONGPZik1rhKTEJAuM5c+xbo8CrsBQs0y6EUxgmCttGVxRurvl2lJofFC2Fi2SJDprhKPdILWQXh1KTmlgXunA9lnCS8+N8Qes5g2tnHQAWLFiBVasWIHbbrsNAPDoRz8aRx11FNnAIlKEQsNuAzNjrU6Y40mivVAkYVK41M++2xu5hMBk6e7uhQan2Fp+r5NSPKEdW7XHQXOU7OEM2DLp/E4phZiWq8MCQFTvOD2uTI/iqS2LEGXbhafGNGCs3WwDF3uDe1yl+lhBUUDbfcrj3E1tsLCKMLVBywooU/Xp71Mni6JJJt3I4HIHhTNIltwMbMGBLvNpqXyo+30p8a40g16A0Fq6dP2nzwKfxZlgrZUfAEi4x5ZoZkMLWvQBrejuk8kE73jHO7Bs2TI85jGPwWMe8xjsvvvueOc734mJb+nuOUN2U/vOnrRBie4+VH/n7/tUCqP5zqRP9MWIVHsjbQwVTAPaHuaO7DMLxdMWkOFYnJkOBJmJSrv5/SLilJbPadOyHJvSNAX7QCIjacLMDAHdnxd760D5gJ0Nvlprmot7iVIw07EDeOjLJiOGQzDWlm2lERfjvx9KgaEWz5ezPzelUKktECI6Jxf7KIJ65juaJKjjEMdlaYmqrvEkymOMn0Wy1Q0wwADHHnss3vjGN+Zje8L+j8N5551X/e8GA3zlK19pbM/82rssWYh/vfxr/oX0eoRWTvqb3/xmfPSjH8V73vMe/Od//if+8z//E+9+97vxkY98BG9961upx7hDQ2qxzwGX4rX6Ox8w69sAP86wDWZWwgeTInuJDiwvfNq2OgbtTckCU2VhxkbQA+D6LulWuia9HAjjX4hULQhnXZhXKk13chj0Y0k81zZBrq7XQXfSjWN6Xt+YTCSpmvTy4h7sdq2sIk4nVEDUzFqT3kE7wSVwSBnQdTKGmtDdTb0XxqCwFnyUCBRa2IEUgXWzxIRjjuZIkFSyRgTWUoPSh+42X/CCF+A5z3mO9Xff+973MBgM8KMf/cj6e7v1dHDfu/rf8JrXvKbz+FS87W1vw+GHH15Ymp6HX92yDn/wzFWktkxcdNFF2H333VltSKIV3f0f/uEf8MlPfhIvfOEL831PetKTsO++++Iv/uIv8Ld/+7dkA9zR4aMmmQpmqx51wvTpC1crf/o9zy7HVbRPuhEoALgWNNDscGgW2DIbHBm44l7PbKRb6exi09rwdjbTrR7karZo5lKanhjXwXcWq61dm7CeFK28Dk7auXBASuLa2kRGOYIDroA2u+J1x2cusd6n9NclO1TBokh/bjLPlVqwGUFhNWDYFrb2lByCqCZs7zmKbjrlZ316zC416Q4tGspElK2kUeI6uHzxBN3vsVe/+tV46Utfittuuw2PfvSjtd99+tOfxpFHHoknPelJlcdQrWdD2WvPvbDTolHrcVXBvPVW7LMCD258MBhmQR/QKpN+991348ADDyztP/DAA3H33Xd3HlREgT7T3UsOp1GT7gu2elipXr91MBcjPoI09hc+Y2YnqzPUnHQaO/b+semWle6uUGIlW0Rl10nGZvv7g0tp2pxzJJ5rW9CCNpPOl11tAzOIJzV3lupjBebGqtIfjr7OZsCSk1Kvfm4tcKj8OzPbytFKs4vWhPn9zaAwBewZ3OnvBNhNA81ut/tUa5NZqknv4vjbryWPNkA50SBCdx9oGxL80R/9Efbaay9cdNFF2v4HH3wQX/ziF/HqV78av/3tb/GKV7wC++67L5YuXYpDDz0U//iP/1g5kRx4gE53/8UvfoGnP/3pWLJkCQ4++GB885vfLP2bN73pTTjggAOwdOlSPPaxj8Vb3/pWbNu2DUCayX7729+OG264AfvusRSHrdwD//T5zwIAdl6c0d1T3Hjjjfif//N/YqeddsIjH/lIvOY1r8GDDz6Y2zn55JPxohe9CB/4wAewzz774JGPfCROP/303FYbrF27Fscffzx22WUX7Lbbbnj5y1+ODRs25L+/4YYb8MxnPhO77rordtttNxxxxBH4j//4DwDArbfeihe84AXYY489sPPOO+OQQw7BZZdd1noss6BVJv2www7DRz/6UXz4wx/W9n/0ox+tjeRENIO52KeI9kqhTGtSfudxoWmKswHhMBZcixFJQTub+A1nb2CbZsF4kmAhQXDXngmjv9ZjcwE41BeAXJ0MJo5AmAi9u4NKtE1pmqLeseTsCAjp2TOUmNptZzhRnvdSra/3QKKfOcrVspHTrskGA3gClqauwYDBcbFSojvep1qLyzzYOrXH4HR1obu7MrjZ8UcELpW104ME42PitstSckM6R0/tMbBG1Pdu5T2TJMC2hzrbHWx7GINtWzHYNga2joHxBIPpcZOtC+zr94VLZ1JUW7BgAU488URcdNFFePOb35wf64tf/CLG4zFe8YpX4MEHH8QRRxyBN73pTdhtt93wta99Da961atwxb/+DvZ67CGOPukFJpMJXvKSl2D58uX493//d9x333144xvfWPq7XXfdFRdddBEe9ahH4cYbb8Rpp52GXXfdFX/913+NE044AT/+8Y9x+eWX43P/9//D3Zu24ncftbf27xMAmzZtwnHHHYdjjjkGP/zhD7Fx40aceuqpWL16tRaI+Pa3v4199tkH3/72t/HLX/4SJ5xwAg4//HCcdtpptefM9v0yB/073/kOtm/fjtNPPx0nnHACrrrqKgDAK1/5Sjz5yU/Gxz/+cYxGI/zXf/0XFi5cCAA4/fTTsXXrVnz3u9/FzjvvjJ/+9KfYZZddGo+jCVo56e973/vw/Oc/H9/61rfyHunXXHMN1q1bxx5V2NEgtdjngEkBDq4m3eqk+xhRgbLjKr8wt2aPGJSUTZVwjvujUAW2ZI9IBYP0e119GXN2MiiVDDDUg7psdtEsqLrHSKiUglRsqyPXcWE+1hbI+nfxTaoynZ2uAYlZ4brXJUoZuOnLLro7bS/2iuBr65r04nMXB7oOpXryFoJ3ZYG74ndUQeH8HrW9bxgfD9Px1ey2vA7aHGSK7XX4LhIBqSrWiHXs2x4C3v2oznYfPf0vwwIAh9b9o//3dmDRzjMd/8/+7M/w/ve/H9/5zndw7LHHAkip7i996UuxbNkyLFu2DGeeeWb+96973etwxRVX4Cv/90s47X8fojvm2Q/K+fjWt76Fn/3sZ7jiiivwqEel5+Pd7343nvvc52rjeMtb3pJ/3m+//XDmmWfi4osvxl//9V9jp512wi677IIFCxZgr+UrMHxwC3baaYn+RRLgC1/4AjZv3ozPfOYz2Hnn9Pt/9KMfxQte8AK8973vxfLlywEAe+yxBz760Y9iNBrhwAMPxPOf/3xceeWVrZz0K6+8EjfeeCN+/etfY+XKlQCAz3zmMzjkkEPwwx/+EL/3e7+HtWvX4n//7/+ds8X333///N+vXbsWL33pS3HooelVfexjH9t4DE3Riu7+jGc8Az//+c/x4he/GPfeey/uvfdevOQlL8FPfvITfPazn6Ue4w4Nc7HfJ7iop4Bf+r59UZ1ufZ/jvGVY6aUo6KRX1nPxZUc4NAvGwi3YOAMOM9kVrcG2OdjNjqG3LdN/12lsRgmFdN94UnX3nGqq2/MFl/ATO93dA2vEFIQEaO5TE2Uxvql9hvmWkhWg/jtKcTETpvNbBBdaHINxjjbvUdWOTDCpbLetWa4AjIvuzhH0ohYm9Y0DDzwQT3nKU3DhhRcCAH75y1/ie9/7Hl796lcDAMbjMd75znfi0EMPxSMe8QjssssuuOKKK7DutnWlY9nSBjfddBNWrlyZO+gA8kSsiksuuQRPfepTsWLFCuyyyy54y1vegrVr15YPaAkMTn+Bm266CYcddljuoAPAU5/6VEwmE9x88835vkMOOQSjURFB22effbBx40bL6OuRfb/MQQeAgw8+GLvvvjtuuukmAMAZZ5yBU089FatWrcJ73vMe/OpXv8r/9vWvfz3e9a534alPfSrOOeccp1AfJVr3SX/Uox5VEoi74YYb8KlPfQqf+MQnOg8sIkUo2ec2cGWsx5PEazbIJu4i0XN3FpT6pHvJpNucDn18FCii3dmWPiDFsXixwVycjRi+S7VdaFvWBaFF9K0p3Z2rDWI5WJLu56X/p1vbPdaVakpJX6VC4VBiupVjKwDlTKi0KCCPPsf02GZdN4OjaxNMbTuva3R3gwXAoe5ettEgk27S3Vlq0t3vTs61hT1QqP+u8TGZAjCu7hAcGgYjtatLlZ2FS9OMdkesvfsh3PfwNuyzbAn23GUxJpMEP7njfgDAwfvsZmfULVzayMarX/1qvO51r8PHPvYxfPrTn8bjHvc4POMZzwAAvP/978ff/d3f4bzzzsOhhx6KnXfeGW984xuxbetWADDo9jY3vR7XXHMNXvnKV+Ltb387jjvuOCxbtgwXX3wxPvjBD5b+1nVFm1zpjGqeYTAYsLb6ftvb3oY/+ZM/wde+9jV8/etfxznnnIOLL74YL37xi3HqqafiuOOOw9e+9jV84xvfwJo1a/DBD34Qr3vd69jG0yqTHiEHrY67d056+cUxCmChWSUG5DvKWup7zZBRqR9DurVmAzjEgIyXNaUdU+0bYM70WOrreZ2XqV3jHEoIpXUJctnquJtm46vGJslEsYoTdrRrloIA3YWgqOCsDxaouVXtSQRWq0sZ6OyYVPRCfI3QRkXdcls76r8zrwvlfWqyANrM4a5zDNDNl1baueCcbG/BRheAoWAcmusLiaBX+jn7ncXOYJBSzjv+lyxcimTh0mLf4mJfsmip/d/NUI+u4uUvfzmGwyG+8IUv4DOf+Qz+7M/+LD+XP/jBD3D88cfjT//0T3HYYYfhsY99LH7+85/P7BQfdNBBWLduHe64445837/9279pf3P11VfjMY95DN785jfjyCOPxP77749bb71V+5tFixZhPB7n3rglkY6DDjoIN9xwAzZt2pTv/sEPfoDhcIgnPOEJM464GbLvt25dwSz46U9/invvvRcHH3xwvu+AAw7AX/7lX+Ib3/gGXvKSl+DTn/50/ruVK1fiz//8z3HppZfir/7qr3DBBRewjDVDdNIDRyiK6G1gOhCAolbv00mvoHP7Vp03a6k4lHLrYAuucLQtK9Pdy7/rbMPq7KRbjpp0GyuAMejrxWGy0t0bLpptNYMUKr+mgJKMurst26r/rvUxrbWtvtk+6VaS7q4eukR3Zw0O6DYBnsCPKerG0oKtqkyFIJOeHZfjHW8GwloJxzmO0fQ4s9iw0aw5X+GJ5dp2fRdUBWC6nC/zXudgxNjOhyQrcWBs00HRHHuXXXbBCSecgLPOOgt33HEHTj755Px3+++/P775zW/i6quvxk033YT/5//5fzTlci2PbokNrFq1CgcccABOOukk3HDDDfje976HN7/5zdrf7L///li7di0uvvhi/OpXv8KHP/xhfPnLX9b+Zr/99sOvf/1r/PjGG3DP3b/Flq1btN8nSAXalixZgpNOOgk//vGP8e1vfxuve93r8KpXvSqvR2+L8XiM//qv/9L+u+mmm7Bq1SoceuiheOUrX4nrr78e1157LU488UQ84xnPwJFHHomHH34Yq1evxlVXXYVbb70VP/jBD/DDH/4QBx10EADgjW98I6644gr8+te/xvXXX49vf/vb+e+4EJ30wKG/SDwOpAWq6rN8rjOtGf4gxlV8LtHLJJ10SxCDo/92Ee1Ot4PBgLzlYJVDyaEma6W7czoRHmuwu2QXbUrTtPWOkkGLdEspTlhNs251SDK4Rc74bar2ZEQSKwIwpEG+6bEZAxDWwFjHYJIucDg9JiNTqQjQlO3XoXyOi9+Rv29UmrUAm8fan73jfGptA9kxqAO4u0NwBL207iEC16Hq0JRWX/3qV+Oee+7Bcccdp9WPv+Utb8H/+B//A8cddxyOPfZYrFixAi960YtmPu5wOMSXv/xlPPzwwzjqqKNw6qmnlsqaX/jCF+Iv//IvsXr1ahx++OG4+uqr8da3vlX7m5e+9KV4znOegxOOfx6OPezx+MqX/kn7fQJg6dKluOKKK3D33Xfj937v9/Cyl70Mz3rWs/DRj3608fkw8eCDD+LJT36y9t8LXvACDAYD/PM//zP22GMPPP3pT8eqVavw2Mc+FpdccgkAYDQa4be//S1OPPFEHHDAAXj5y1+O5z73uXj7298OIHX+Tz/9dBx00EF4znOegwMOOAD/5//8n87jrUKjmvSXvOQllb+/9957u4wlwgKO3tFS4OqF3BVcytJdodqWdDJMVNHdSSmMjhfp9iQhW/CbTqxqj5YVkG7z7IDynbjuqUrmhUjWptjX1MG2qmYTPIOmCrSEA2lvwUaTxbIxDbzT3UuZMP453doOarrlPB/WjByLE2q/bym/W6Xj0tGRGwyUACVHaZShg9BmrjDZKVlQOEno3q9VGVyJQCGlqnxVAKbLpS3pL7DS3Yt9Eu/GDNnl52qZfMwxx1jnhkc84hH4yle+Utr/2we34Df3PgwAeauxX2x4AADw45t/gV2XFHXfBxxwAL73ve9p/9609b73vQ/ve9/7tH1qq7bFixfjS1/6Etbd/RDueWgr9lm2EwBgy7Yxfrb+/vzvDj30UPzrv/6r83uaPeEBaD3dbTj55JM1doGJ3/md38E///M/W3+3aNGitK+8Ax/5yEcqbXOgkZO+bNmy2t+feOKJnQYUoYMj2isFW+ReQuynDtY+6QyZ4qbQFZ3Trc8+6Ta6O6cievE5YV00cWR6XI5rKpLI5aQXn02hNM7yCJtQWlPHhU/dHdpxJRzIqrrlruruNnE+32VPphijxLgmlntdstZXc2w59TmMAATPfFvs63oO7e/4bs6hDaXgWx6wmv0Ytl7i1EFhU5tEtcd5n9rfc9MxBRaAKYnjMtwv9mDJ1D7ndcg/DZRPAyRIaFPpLaHFDPIgJ58989C5/Z75Mj7RyElXi+cjZDAYDDAcpJN/fzPpvAucpih6Zxf7QhiXjdI59CIc575ulMECa7R7CGBMqe6ebkfM96C13nMAjMF37dTjcrY/ctm1tTDs1CedgI5oZuglghYc3SIqmQa+a9LNNpHCwnGmo8Zbk+7OpFPeUrmzazBxWOq6CSnAeYabkEVigxksaVOzbw0oTBdXVPdQ5VwgwDSx0t07snms7Usp6O6GOC4La4T5vpwJad7Bq49usz1oqe7ezHD5vszGkyQJG9NgnhBr0nsADqVXCVT1D/aZDLJN4AOBBV8dbNkiH4rO9gw3yMdha+VFXTdmrdXjoKtm9GRBMUJNfddshyWStSn2tVd3L/bRqLvrjogMFTvddmlJ5zqmLYPrO1ZbEkkUyGjbWrBJ3OtSJVvmO4mld3QVA6Yj40OfXzN7jEyDFgErDrq/Cdu7cyCwfhszONRV6wAS4TgzsCxEd5eYpywJa4SQSre5xJyjKmXSGW3NK6KT3gOEkkFpilBrv23j4lgUNYUtW+RHOG46Bmt9G31mh1MJt3KhwVJTWuzjrodWjytZk27TLGjqYFvZGgT3mPlsy7Skc2dbORbIvunuJmtEoq2mrQUbR8cJE1IlWy4xPg5195EyR3Vlak0MVkV6TPqx5yUlZhCjTU26LaBAVl6VHZd2XqtD1Xza1qEughrFPor70nx/cNzrlYKxAtOnLUHsNZOeGVeDR6Vf8kE6ODBPiE56D0Ad7ZWCjVYeQk26rYY0CLq75qSnWwknozSOKoeTMrPDUCNZsmFZRHJc6+pFAX8mvejPLucwdWFAcF0XMyPJfQ3UY1PWLVc6/t5r0tNtme3DbxNQOyikP4s7PwzzR/YVigCEbp/Ghvu7tGVIVTqHDEyDorf2dH8DG1bGC/X7xjoXpFsRgUNCgVRneUCHY6b/Vl9/cczRVlFay3MrwVAs6rDZTdViYPmBNZNuHFwLXgRwPjhBdW9FJ70HCMGxbQOpF3hTVLUr8ZvhL2eLfJyvKjEgWsd2emzbi5To+1qz9az19ZbMp4CTntdgizqlxb7mNelV16Xd2G2UaMmgBWWwqVB3L/b5KH2xwYe6u6/AqrVki2H+KNHdGepnxwwlOVxdGsp20q35XkyS2Z+HyoAL0VBtcwGH6GrZLqZ26Zg3XOu3iXGOODLcdrp7uh0nCRYuTNXMH3roITqjqPY7/c7aZeu27DYXiluosNovb6Y5tm7dCiBt69YFjYTjIvwgBAeyDawvjgC+i53unm59lhSMNafLzIzKj4Mzww3IUNGLqH2xj8ORraa7Mznpyj1REhpkrbtLt12e67H1uqTbriJW6XHNIFerQ86Eaopru2NyUOipUBbn8+MsDwQCUtJ0dzPYxq3u3pWpZROj43G69LGr9saTBAtUDn/NMWz6JDJ0dxITVlQHIFrOp0zrABcTh0PDwH5fJhiNRth9992xceNGAGnPbgoRs/HWLUi2j7FtyxCbh+kLOtm+Dclkgi2bNwPjbg5bW2zdugXJ9q3YvjXB5s3pS3e8LR3rFmWs1EhtbMfWLUNsHiWYTBIk21PndfPmhzEazmeeeDKZ4M4778TSpUuxYEE3Nzs66T0AB9VYAlU9Zn1+F3t7I/6FZh1MyiMgU89mwmcdNzWlV6q2t5Jex3Tp9N7RelZTQmm7S4alem5o6zAUn4t6x+nvJDLpw/I91pVGTNnWjQpFz2r9HEuI8w0sTgjn+bA+14xBviLYVswdVCrIHOru1oB39swx0pfV8zFOkpkWsuZ9CzC+b7Qa/XQrQncnDEAktu9CkMwYG8flmD+qSjuye2nFihUAkDvqFLjzgS3Ysn2C8X2LsNOi1CHfeN9mjCcJBg8uxsKRH6f0gc3bcN/D27Fp8Qib71kEALjrwS3YvG2C7fctxN2LeFzBzMa2exfinsULkCQJNt67GQCwYNMS7d6aNwyHQ/zO7/xO57k7Ouk9gMTCmwPVtc0eM+kWQZQQxPkq29mI1qSnW+4yhYmFaUEttmZVNGa4B23njJvmONac9HQrEdCr0hKY9bpVs2y6jQuQVnenzzgVTmmxLxS6u5ktlKDzSnSCsEEqg2/OH+pzkSR2IarmNsqOy6Bj4KeqRR2P6J2efQVmn3OsWW5i5pEvVXHT8dXttjymRTGeQh/JDCjwPE9u1oSqb7DPPvtg7733xrZt20jsfvAL1+OmO+7H2194CP7gd/cCAPz1+Vfj7k1b8fE/PQK/u3xXEjtN8blrbsGnr74dzz/0UTjjD38XAPCJS3+Ea399N8487gl47hP2YbH78S/dgOtuvQdves6B+MPfXYHxJMFpH/oOAODS1z4Fy5YuYrEbAhYtWoQhAVMgOuk9QCiCQU1hqznOJs3w6O7hZPh918pziNDYUE2VpDFkUzQWo7szOxHq/TIwFvehq5lznK9JRdCC93xMbVkprt2+i6TGwaxwqbuLt0ITvLa2QCKtpoX9nALp+R4SVJDaAmNds5gcFHobTAdbPT9NdTBsjizVI1Xdn5vGhg0cjAYO3RD135aV+lsf0mID2rEB9xpmNBp1rhvOcOdDE/zmgTEGCxZhyZIlAIC7Hk5wxwNjDEbFPmk8OB7iNw+MsWk8yMfwwLYBfvPAGFsmI7Zx3b0Z+M0DY0yGC7FkyRIkSYLfPDAGAIwWLcaSJYtZ7M4T5rMgYM7QW+E4AlosB8xFJhCKurs+FqB7nW67cVhezow1knpQIt1SOSJWWrXAIhLgdxB92ATswbemtHJTfEw9Xtux21oYSjB3OBTATXElwE/AzgZnuzABuruNestbk265DpldykyxKaY1LP+uK6oc6rbsjKoSLQ519+z6a+dnRjtWgUdipk0l7bxnQayiPKDYRxFwMEtXeII65YCMxFrKLiDLPz/WwRReBGTGZT63g8GAZf6cZ0QnvQfg7rfMhaqaY5/fxfoiDWABbAse+BhXJnAzskTlKam2lYwGavohc22vtd6RoTbTatOSbeWkRFc+1zNntdLtwHKPdaWIq+MRoWJXME/aU/f14wC6orVPONXdGef06gylxLW1ZeQYM8UqnZvIjjUw1vH5sF0Xjv71ZtmBlkmf0ZBEUNOXk8aRELGeL6I6d6A49zm7kpvuLhLALtv10UbXhPX+8FQaJxHUnSdEJ70HCCES1wa2hTjHAqcpqoSevNbKV1CAJa+9LYgxYBhH1aKR6sVhy57wBBwsiwJBurtpU3pBWNid7Rhmjal6jNZia5PyApCDSmnCXpc7HRMp3d3/Yg8oOyIStfJVGUrp1lYcc7IZ5FPtUX29avG9bvcpt1OSGPOFqe4+C6oYdFT3rjXQLpnBtb1L2wZgGJIGOtsp3XLMH1a6u0BJo12cMN361BKpXJ8wnpCcaWPVweiXP+ML0UnvAbgzclywqskKKAHXoSqDG0S0k/BF22octsUMQ7ZMos5UqpVV9T1FZkZDdWaIxybgors3u0+tugdEddzpsbJxlX9HDQ7Kr53unm59B2vNIKfEnG5rqSTBMKsKDlB+XXMRrT7T1HMhpfhe1Tuek+4+GAwaZ2Bt75v8GETn2DavSZTSVb5LuwYKtTkaHY9ZfM7p7oyldNKllrZ3cggsTZtuisS4xvm8Vr4OPXNnvCE66T2AhDAPB6wLzQC+S2JZWHAIozVF9UQqPw5bxoWD7m6bwOn7pNNlj2a1w/0StEXtfdVgN80WVdGXW6sRK45OSUhPoO6OUmCpSrDMt7q76eyJiBXaujSIZCjps4k2mIEeXb2cOGCprPq6qrtX0rtJ59eynaYsGVtdLjUroup+YaUVV9Ldux2TstuMtQMHZ006YwLABiuzJAAmrK1sR6ZGv3wdQqD/9wnRSe8BQnAg26DqBe7zuxSL6mJfEIJ2lsW+D+aBTTCGOuMA2BcBA+IXh21xz+HIVpUqcDlVdgpbuuWlAHdfAFU5oaQ1lIJZLFsHAVp19zAWNy7hOJlzzMuIKdud2rLQV0np7sb1Vp8tMgfSGhib/q6lDXs5EYOTXjXnzJpJrwgMUl1KW1tRmY4bNrvZmOgChV1LuGxsJw5mir0lXXkM1Kgu42IzWwtriZpE0KKC/u+bEdYXRCe9BwhlcdYUvpyIOlhfPgFE94psbLHPB4vCpojO27aML8ttc6ByYSNK6r4lwNKUjtnYZoUjJ0Lv7nB/cIpYWZkowtnWrov/YpFZ7FMDnH7rG6fjMYXjPGVkOOfGKieUU9NCU0Emq5dOt6RdCCrmII5yANtif+aOEhbHjbo+1hS4A2QSAByMD5t2T2e2k1aTPmWNSJWfCcwXiTE3qp/DECUu9kkkzHxdh3lCdNJ7gBCyvG1gpZcFQNm01uZ1VJamgDVb5EEJ00ZD5+mTntkp9lEv8Crr6xkWBTZqINc9VfV8SWQ1u9C77U4XGh3DPS7lmMy6AKldTO3SLf5NoSxAv84hZWXyuUH4HEswzKwtHIkduyRJrIEv6k4oleJ7hOwVjqDN2HL9m9YyV4mIcrb8pGaH2VAZxGpp1na/dNcwKD4X80f6MwtLzxYEFr8OYLdbByvLTMCvsIs0y69p+4zopPcAISiit4GUaFdTULSQ4oCV7u4hk151fihfpFZKGnkmPd3aSggoz2llr2z2THqxT6QGmyAqb1dB7hbAy5wZa7cACSq2JhaVblsHHCpqsIEw5s/sO0rUXNpVk/kzVNbgAHEGyua4APQB2qrMaGsFcIZj2mBjRDVdF1U6KsTvG8rs80x2M5o9Ib3bNkd3LXuztWDjLD+zJQA4l1L2Th/hJKakM/xVgoZ9ayntC9FJ7wFCoIi3gZSz1xTWCSsAJ70yMyqZSa+oI6LtDWzJFmb3OvHCdESoIm6DbVHAQatXUdk7mlXxWreVfk63TfukUwbw7JTPZuNqZbdStKnrdyn2qfNVCNTJXJxPgIXEkdWbBVWsK2pBN0DIgWR55op9HJlD2zup6bvRNj9Q93SvymhzOmkcGhYcuiG2FmwczrN97NPfSdDdrdeBzWwtKlkkAueDsqPEjobopPcAPhw1CkgItbSBtfetQLS7DtUtySTHMbXNXEdU2Cn2UUedJeiqgD2LSx1wMFG1IJBwSm3ZxZnp7hWL7q7q7jZHTlxcrGOWoqpMA/BNd0+3ec9qZVxcC2ArbVJgkWlv28WT4QaK7wTQv/crxfdaq7vLMBxsJTZNS1ms8wM1c8uaSdXtc8D2Lu16/1TP0d0cf8DSgYOD7k5Yoz+T3QpGXQg6THZBO75xWVuwBXA++oTopPcA1LVpUrA5EV3pUhSwZmUCCITY+qT7iDpKUcWqW1fR2KiiH1Ke0kq6O1tNui2ok2790d2bZbUGtmewI5WSm3prwspo6Pi8WB1/5fgh0N1z4SdljHylHdBsqp95A1JTW9Y5mcaGOnzOd2Xxfin2dVV3t5dl0M+vY1spS8PFvpUBRHwPVbIVREpu6J4PjrLAqpaoAD07xRvd3Sb+G9ja0leNvsQaZZ4QhJP+sY99DPvttx+WLFmCo48+Gtdee63zby+99FIceeSR2H333bHzzjvj8MMPx2c/+1nB0cpDIhLLAVtNUxDOcAXdPQQaqW/VeQ5apAlbbRpAn/m01ogxnNPqBQ2ZGQ3WelBlgczX+m1qy+oMz3aMyhrj1lTK6VgY63ptqKyX7ZxJV49ZfPY6TxkLUY2Gz8YaKWfGugpjzQKJ4Jutd7Rmh2ourHi/dL1PtfaDQvNrU+fHHhTWj98VVWsLziUPhZiniWq9gVaHdLwnFZuMwRKZ8piy3exjCGteW1CcVyuhIngUM+kzwbuTfskll+CMM87AOeecg+uvvx6HHXYYjjvuOGzcuNH69494xCPw5je/Gddccw1+9KMf4ZRTTsEpp5yCK664Qnjkcuhry4IqtWW/Am3p1kpJ85rhT7e2+h1ZdXd3tJu6PhKwOyJUDiZHD2sTSZJUZj75WrDpdgD9mnHdy5UlBDN+VxvLpmvNYBUllld5vPv5MFGVnQd8ixClW7OFEsB3nseWd4lEYNXGGqFedKv3iO1dSc4qIny/SInDUtCIJTRypPrGm7DS3TuXMmTHpLu21mMyMHHGljWMRMIjqVg7hUZ3l0iYZXat7+R+uTPe4N1JP/fcc3HaaafhlFNOwcEHH4zzzz8fS5cuxYUXXmj9+2OPPRYvfvGLcdBBB+Fxj3sc3vCGN+BJT3oSvv/97wuPXA7U4iZSsGXcBsQLjzaozsqEkKGic1zaoKg5LvZRC8epL6wutc11sC8ip78jsuGiq0rR3W3PV/p7FrNKRqrY1/T+qFJ37ypKZBUJlFggEz63NmquRnf3uuDT7zstMOQhICUhfMRpN1HehdYsN1XAskp8jUNcjPC62BlR09/NWmJT9f3JArbTsQlnUqvEXtsG9Owt+9Jt+64V1cFH3naD6Va6FCyEtaVdNHH6O4FSMOlgyTzBq5O+detWXHfddVi1alW+bzgcYtWqVbjmmmtq/32SJLjyyitx88034+lPf7r1b7Zs2YL7779f+69v8JFNpYBdOG76O5/OcGW9kv9x2YXjJDPpU9uMFPE6iidnCzbyxa9yHMlrZwumSNYHW4NcFFmtlsO2LZBFavQt2TMq1WzbfdvluBQwr51E8IDDCZnJbsW7gsqsei11Yafp7wXqdDszPmztBwmvS1XQavY5R/93+jEIBolqWrFEFwIr3b3ttWUoV6xSv1dtdoVNK6EoBeMPlgw0Z5j2HmuDKlYr57vEV1eOeYJXJ/2uu+7CeDzG8uXLtf3Lly/H+vXrnf/uvvvuwy677IJFixbh+c9/Pj7ykY/g2c9+tvVv16xZg2XLluX/rVy5kvQ7SKDvdHdK4REKVGdlfIwohZUq5ZHubptYqYahZ5/Vz8QLYEt2ddTRGSzZUJ107dqlW0kxrZGAw2QTaGu6IOTI6lUtKjkXZjb6f9d6aRt9VT2uz/WNmdVUxygqkigwN9rYYNR21fmBszQspwBbmUvtjlnZ1owhk24vB2gaGLQEQohroa0lawLCcXa6Ox1LgqPOXb2m/ae7p1vOtrJtUK0jwz9/+tZZ6jO8093bYNddd8V//dd/4Yc//CH+9m//FmeccQauuuoq69+eddZZuO+++/L/1q1bJztYAoQgPNEGlVnMgOia6mef4xrbor8exlXZqocl+8xnp9KBYqa7cwekrNdJFRdjsmunuzfLFlTNDZ3bltkCMqyUPkztts/ymbCxkNKfM5v+5imTsSBKd7eyblhMpnatbDDae0p1sCifBxOJ9Rxmv+v2zNkV01sdcmY7w4aBMOv8QK61UhG0YHxkbaKZXQN61kBqx+9SF1imeydXBPUY54tK9oHPNa+tXEQgyGkva9N/F1GNBT6N77nnnhiNRtiwYYO2f8OGDVixYoXz3w2HQzz+8Y8HABx++OG46aabsGbNGhx77LGlv128eDEWL15MOm5phCA80RT16t3iQ8pRTFjFvkEAE4dN5Gzg4XzZqXPplkxgx+Gkj4jtWAXdGKn7dro7iRmnXZuzDOi1rrR2060tW9RUadnOcOjm2PrrjVvs4+iTXvycBKHuns3rg8EAg0HqDLD3SRdmSVSpUZOJW1qETAF6mjRHpwsrrZjhmbMKxzWccziE0Eo2rPR/3QlV30VUsAWj8zVNxznISt3veExXCzbOMreuAanZ7JbPWQiaUrauAxLdMQrWXbFPYt6eJ3jNpC9atAhHHHEErrzyynzfZDLBlVdeiWOOOWbm40wmE2zZsoVjiEGAmmosAXWytS1wQsikW3vfBhbtHHk4X1WLGTK6uyaWpH6mncDt9cLplkMEj1I5uQ61dHfmDL619nvG+9TOcJgen1LESmCBZBWi7FyTnm5DpLtXd+3gselLCIqj1tdlwx6QoTunlZRowhpjjraHFLRZa5CC/Bzrx00/q7/nnZNtDnVXvQFdmBSdjmm7X7IgX5fjmsjHLpw5zoJWvksWTVSugySE4whLbHY0eM2kA8AZZ5yBk046CUceeSSOOuoonHfeedi0aRNOOeUUAMCJJ56IfffdF2vWrAGQ1pgfeeSReNzjHoctW7bgsssuw2c/+1l8/OMf9/k1WDEI4CFvCvW55xTtagNbC7YwFDjTrZ3SKTcuq9gH08I0tcOX+bQ6g8Q0dHWoNseVrV+5TUyLIStRskuw2LfR4AYdr0tVX1+JNl22rA1lfb36cxCMH/O+myR8JRZW2qQESyLd2gXLaGzYxNdSO/rvu4JH3d0doKKc92wOY1OBuirRMk66uyn4yLHozph2tvdce3V39zHbl/GUj5n9PE4SsuCjrbRBZr6wBZ8DSAARBLm62OVm2swzvDvpJ5xwAu68806cffbZWL9+PQ4//HBcfvnluZjc2rVrMVSetE2bNuEv/uIvcNttt2GnnXbCgQceiM997nM44YQTfH0FdlBTgCXgpAAHsMisrFfyeIqtwj4MWYnacVicHer6arfYGu11sC7umQIBqR0on3lfRrZFJ5C+BMeThD1rYyshmNVkVda7vbq7LUuD6TFlHbmuAQebiCRA77i1QSVjge1et9iUED6yZKCog3w2ZwjgcCDTrbXlZUsT9mOmW8p7tFIlemb2zvTfCZQ+2cYJ0AV2TNjmi0HH909VfXX3TLpxrw8GGBOW8VQ5y5xLKY7SJwpwsL1mQbWuQX/8GZ/w7qQDwOrVq7F69Wrr70xBuHe9611417veJTCqcNDHGg51qLYHNAS6ZnDRTls9mwcafhVlL0nS+3BgvGSb27A7mOT1nlWLe6pAgHIgznZyLrtmjeNwAIzBSa3M7LTPahYv72Ifp7q7L0eutfMzybLz+v4Q3gVV9eHcHQWsGW2BRTenPoctGw0w1EvbgsDTj62fOctzrAq6UbwrAOXZ7uBgW+/b7PsTn2NbIITSjttusa9wqLsd0+ZwUrZgS48LYEzJGpkeVzBznCSJXQOH+B5rA1vbYV9Bi65aCTsaeqnuvqOha0TUB1zCYNQLnDawUcNCiHZWUeW8t2BTxW8IhuLKHnFlNrRFJPFLwlXawR2QsjnL6s/cPaut5RCzOukMDIfqmnTOTHrZgegecEi3odHd3ayRdCvaUUBgbqwKSFGzikxfVqQmvaPTVVVOlB631WFLsJaoNbwOVUKb1KVPera++D3382HT+Git3F+VBW3JCHAHlqmvg/u+5LoG6mGl30F1qGJ7SdDdQyst7ROik94DhKCI3hSu3q8h9Em3Z2XSbRjiHpYXi2hNOkrjUJ1PirHYvitA/yKtaj1CR1e1Zwe4tSRcdgsHkcWsne7ekAFha1tGpu5uybZlWT0O2ByIrgEHJ93dczDRxRrhbq3pg2Kf2q1gfBCZTSzPk2aHOrtISPe2Zg4ZdDFsdN2mAlRVbdyoRKxsAUzRjhuETliVg0V5TIBeeLIqOM+mEeMKYBLfY21QJUos0oLNFsCOTvpMiE56DxACxbEpdPVuugwTBWxZGQ6xm6aw1cz5UHOuEuACaCZXm7ALUNwrdAIy6Zaz9/zY4VBxa0m4xMV8qMo3zfDas3rT33UUsXLWg7IxGsoOBJVqdonu7rlcqI41wnbPWQMwYLUJOBgfA/133W2k2xLdnTggYy0H6RiwrCp96HJct51iX9PrL8G0qcrgArIB264Bfts6IKcqd5zXuIOPVq0E7vIz1UkPjO7O0U5vFvjqVz9PiE56D9DHGg51QpJug1EHDqotBca2Cc3DuOqdne5jkaK7W2smyWs9061Ze8n9EnRlJQbMiwJbP/IiwzLjMSyOLYe6uy+1+65ZG3cpQ7r1NU9p8zqjAJfLrm2xlzCyJGx9wKnLSYqgsRlsm/6euibdUj/etZe27d5Xf98VVSUls177qtaRrOJ8AnOQ7R7qmrHkUMOv09qQobuTmCjBSXcPIDFVzSJhzKRXrBV8no8+ITrpPUAIfRabQh2rne4uPaICNmpYCCUFPuqobLDT3Yvfs9LdibPPtppJ6kiujeKo2mHL4OZOqb6fPzhQXmg17W9vE1jqLLZmy5QxZPXKdsvfpesCyJY51I7r6V3gonR2rVWtQ1UWOB0Xj10rS4Kahm5xnlU7ZCKaVeVUrZ+58vlRj0+dGW0rVpkkifJeK/azifM52unxUa3T7cjyzm57CXgYQunWFXwkc9JtwXnulqguunsA63erkJ7AWtwatCIOPs47opPeA1BTgCWgLuRtD2gQKurC1J862PvY6r8TGUdFBD39PY+N9GfihWmF40Zno7yYUW3y0c5dgQ5uuyjZbdqzOAuQcPdsVu8vvixWuqUM+rlq0n2XPqnnUFIMyOqkeWNJ0C5uXb2ji5piIjvWLG82hm5Oly2Dmx631WEtdspOV5P6aPVPOLOctkCIaoed7k7YGaaKFUA5RwP07BS7c8ibOXbNjWEkptwBOm7GHWDqP/HanTdEJ70HCIGK3RQuOnMIohG2CSuEkgKKWl8K2KhzWhsZgnNkExxS7VB9X3tbLv13XeEUw/FEd2dfjNiocw1tWmvViKi3tgw/IFwP2nkxm25NCrTvej6Xs8NdH24LWsiwJNKtvbc4bZCPW1sif26tAYdujI+RxTlUbXZFlajqLGPXHCirw0AyTOdzO2B21IoOAeXno+01qLq2XbPzTro7cVBHsk2kVCCoDXyUUjpZVwGcjz4hOuk9QJ5N7VHkyRkxDUDp0tbeKITgQZVgm48+6Tb1e4Bm4WWjoas2qe6PauES2kW2ufBgz6RbmBeqXa5bmcIptd7rZA6D3ZHjU1Yufxc2urvnYKIrO8KttG5twaZ85i5lsAmWUTNxuMtWbCryXR0X2zw+YLgutqB/k7WEFBXZte7hfj4y53ZkOT+U7fW6vjttc7R2XOKgjq0Mg/u9mNqC8lk+0WKiiv3GNXc6hfR6mHT0ieik9wBD5gmeA7ZFFUBfe9QGldSwIDL8xT4fNag2J2wwGJAKkrmUyalr9yQCHy5nmfsl6CoZYM8YVIhpzWrSTl/Oftd2UVk+poSysrUFW8dnxdZyCvBPd69vMyTHGuGofXbZtZYyEAf5XCKa9ArpdIExGyNqMBiQl7VZA3ANnB/1TzjLyYr7VN/Pn8V1O9Tte5pPjzMsz9Ft51IXw7Lr3O+2o9hgdpad7SmJn4U2sLcd5l3zqoeVFPCbN0QnvQcIIRLXFE66e1DOcFjRvUqhFkHmgU0ISx0LBSWtqMPU93O1YuGsEaujnXPT3UuUaGbqsZXu3jCYVCU4RdkySKJu2eZQUzk/Trq7r5p0h9aIjxZsHLXPLruc74o6MS3WuZCJ8UFdg921hZSW1SPMNpuYWOYggL/jhs0p7RpMYlF3t7A5AHqmQVV/bgm6O6XKPgXsTCSZwFFqC6XPfUo6+kR00nuA4iH3PJAGcGX5BswTwyywZb5CiO6NqzKUgufLVg4A0C5opOowK9sOkS8g7eeLK8AytjiH6s9c90xVT96mdHfrorvlsOuYBdy0Pm0B1NX5cTJN/M6fzkwYYQDPhjq9AX7l/rJdKpNOR5c4oG1TvKYSOOS+T20tpDKTswnHFX9jd1QIBgn7/QLIzUG2rHf3Fmx0wcfarhWM7BRqlp4J23sR4F8HzAI73Z13znYK6QUQtOgTopPeA/Qx8uQSBgsh4GCl/nhQUTdhdyjTrQ+6u6uNDMWL1LboSm3QLoCr2g7RUzH1/dysEVvZBiARIU+31q4NTTPpHcTnnMd0BX4kKdHMAQdf6xtbrSfAX5aTn2PLPSdhl7MtZh3dnd6BpHvvuYJJ1A6AlarfYLGvaSkQOp0lO5b7FKBnb5Xt2pzSbt+tinE4Sdo5u3WsM6pnykp3Z56jbAwzIAz2aBXdnXvuVG0B/KyreUN00nuAEKjYTeHugy2fGTbhg/ozC6yUTg+Z9LosN00mPd2aGQcuKqltYUq/IDAXHtkYmBYFjmdsyBwIs4ryNFy8cajvuijiTTJurezaKNEdn5Xsn5WDWOnWm3CcM1M4/b1gzS1H7bMJ2+KWmrrsutbUi/ssW24rMelck+50Smnn8bZZXZfDIJHBVX/mK7nJ7BT7qOZTl8ZHm8PWBVLJ2SlWLQkaGybcJUrZ70Nb86Zb6RZsIfgAfUJ00nuArm0vfMBF/ckXzIHVpIdQN2Sb5Ln7q1rHYaHdA7TZgBDaDiUtswEm6jNhclk+gD9yb1Ojbrp4m1hEiejU3fX93Nlnq7p7R2d6ki+qZDPWdZhYesIDAvfcpHzPqePgFoOy10JT2zCvdbqlCwZYntvOjpz9mRsSv+eLQJhiowHTQKuPtYl6MdbOA8X54e7RTdlezlYe0VWs0dkJRYTunr0HuIO1+v4QkmxWvSNmZ7leZJTF7NwhOuk9ALcKIwdsFFAgFOrPdCyEDgIFbDXGPiZ4W09N6rG424elW6oXqbXtUMdsgImxZfGr2mGnuwsvCmzMgab1wfa+rbP/e/u4ZAI/Jmx1ll0XQK5ncMS80KyDr4CUi1bN3X+6kvFBTnfX91NnX1nU3YUYc7bymEaZdKm6/xpmAXug0FaC1Fk4Tl2PlH/fBK4WbCM2dluxb8gcKKltvxdAAsjaCo2Z/j8Y2EvjIt19NkQnvQcIIRLXFE4xLQ/0bRN2B8H/ObYtJHzQ3SXaP4nR3W3tsZQTTGHHKZ4kJMxS1n2Y/l6QZq8u3mY5p7Z7rKuIk+t8+GwP1rVVkbOfsKcsRF3wgI+9galdxwJYMCBFTXd36XNQq1FzdDVxUXypAxm2IE2TsTudZ6ZzzN0H3EQl3b01M2l6TAtVOf198+O6S8Nog49VASlJ/QqAfx0wC6xK/czvEte19h1o7huik94DhFDT0hR1Kp4+4w3VdHcvQ5ratmR9fdDdHQsvygiok+5OTIWyLe601k2EAQduMZymdtlofQTntKsQlH1cKB2T4rh1sLZg63gfuzsGpFtfWQgbM0X9mW/BJ+PImijEoBSb1OUyjvIienX36XFt9aEtTbhKTOjV3afH1cauj6EKNvVzgLaEC6iiPE9/Lxk47XgNbI5d144KTro7scNYKXrHnEl3frdASzz51wn6/hASYn1CdNJ7gBDoMk3hjpimW68Tli27mo0riAw/XXaxDSTol87FzPRncrq7ttAoPlN8F3ev4HTLL6al7+e+Z6xUwqY16Tb6HdGicsR439pga8HWdQFU13/aVxYiu6ecCvqCteEA//vEqohOXC7jum+pqfx2pyvdtn026lqwUV2WvDyqJVXfSXcnnqNdwTVuxkeVU9r2GlTVMQPtMsNuujtXUKfYx66wX0Pl99o5yLLmHXR89uvgFI8OIGjRJ0QnvQfoY+SpLlMaQqszSjVmClhr5ZmzgDa46gwpF15S2ecqQZ10HHysAPZMutCCx4S1J6/y3Zv0Laas43Zfh9nH1c5uutXb20xtdmQFuFo5+VZ3d7bWFBZJHDIHLSTKZdzvSjobLjtd33t1Ldjox17sa7IuSuqeJ+Ka9BLdXarkxsL4aD8HVQeo2hy3jgJNXkJiZTcJz1EBrC2rNB34SzDC8wH6hOik9wDcEUAOuMS0QpqwbCq3obWGGzHT5Gxwiv5RCseJLe5QstM1G2Ci9mXEFbmfHpebJlu2W752+jmd3UmnXDTYaihVG+zK44RUUyet3LOT7srwc2dlnHXb7KwRdzBJHVcX1JZpUAnHVcyF7QNj5WMCtGUZSZJUM29mKa+pSxoQ3bZOMU/uLK41k55u2z6TY0t5RFcWmlsAMt3Sq+yXx879XnTpMI39TNmpbevaknfN62JNDJjn7HlDdNJ7gBDoMk1RR4Pz+YCOrXR3/xQcW/TXx6Lc3SZF/30X1AVxyGiSFTWl6ji6wE3FZX4JWu4XdRz8Il7FPm3x1rImveu46+j/7AtkGwOmIyvAvKe428nVwZWR5NbOmLieMSnWiGWxDxDNhZPquZBO8bq8aO4ucFieXwFaerc6NHtNbf0xXAwQ6jna1U7PS+BU+dyGaWILOAwGg07OrmuOJg/OW4KJ3Amiuhagftmj6dZao8/8Xiy/w/TfR1QjOuk9QAjZ56ZwZwfSrU9lR9tihVqwrA1s9GUfE7wEbculIC/SL5WJripNcXRlbdhpfZYSgsFg0MjJrmI4tGU3eKP/VywIO7MCXNR9XzXpnmpuXQEpH6ryTUs76m1UB7SpTmlVNq1rR4WywCHdM6fe620D2FI9rF3vTvbAacUcBLTMelvmeaDbfFo3R1O3wpNc47kYdSGUq1YG6Dyxn/rkz/hEdNJ7gBDoMk3heikOOi5eKWBtwRbAxGFbAPvI8Nf1myYRS6pRNCarEaxxdiiCRXV1dpKiVoAAvbvu/phhEVQs1pR/3zEb66T/M58PW3a5a5bCGcQKpCbdFZDiGpZzAczs/BRlB6rNYgwU3ze/f5jr/O3aCd2ejfqAbqvDalDv9YE2X5R/74IzaUBek16dTRVtA6kGo1tlvcvHVH9ul0m3H5OaAl3dwUf2vcg9R80C25rXV9vMEIIWfUJ00nuAEOgyTeGsAfO8yARU6qQ6gU9/55XuPh0LYXaxDVz0S8q6Uzc1Od2S9Uutq32npKsyf5ey3XQr3UvbRncHlJfvTJn0ioBU2xpKp2OLTsed1a42n3TMLNe18/HFRHKqZAsFpNyt33gXmm6Fa7r5w13LShWwtDku+hjaHtNJdycMgqrHbWrDTXfPbNA66e7ad7mspfq5jVlb+Z163DZrEicFmtiRtQvG0too2XSU8IWQObbqphALU5Zsuph+AZyPPiE66T3AkHmC54Azu+i5plK17bv224RtAeynT3rNQqNHFPE6IR/SgEMgdHd2gZyJffGW253h+44tz2BX56eO/s/d/kjLUHYUzrKJfKk2/GXS0620untdSzruOlObABVAMy+763Snvycu/VFvqe6ZdEf2kInubssUz9QnXYru7mCI5e302AKntmtbfG5FTa8JFLa59+tasFHd68X6s9jHvcZz6jAFkDmuLC9jnjtDPB99QnTSewDuTBAHXBM8ZTa2LWzZ1RDYCjZnz0fwwE0tzSb17jac1GTi0o56p4LQBvN3MeHsQyrklHYRR7LRiLsK+rlqKKVa4dmohEnSLktXG8TyNE35WnhJ0KrtdsvXtqn+Qh1sQePUJu0i2sY04VJ3HxGqu6vf3zZfzDbf6P/GPAbd+8aVPcTUDtcchKnd8tqhrV2XQ91lPVq3tqAuO5Bc47l1RHjnqFlQ3X6Rx6bEOnJHQHTSe4A+0kNs9W/qz6G1YAtB3d2uOl/8XiqAUKeSzZk9GhILCzqdCoHvItY7WtgptdW3qeNoltkqDqLWm1LWO/IL5JTtqvNeu8VsNUvCF93dVStPTVc14RKc4g5gOxlhhJlRlxhf8Tx1twEo38UWBG7N+HA5pXRzn3qM1pl05zlOt1TPU13Aheu5raW7t7iH6tiQbZ51V/kZuUiiB6e0lhET6pqXmf1U9gGmY4pe+kyITnoPwC3KwwFbDYz6s9/6HH0sgHKOPaq729rZaIt9oXNW1FbxBVjcUXraF4erRRAlJdxF+aTMtlXb1fdzBwfyhajj2s1i1urYKp+71Du6zgfX42NjwKjOQJvLUNfKyVuf9DoKLDt7Q9/vo5QBoH2PSdVu2gJjXRlFieNdMSB0iNRj2FgAswQxbE4KQH/fSgVcTFSVMqjjaoI6dXeOFmw0LfsSO92duXSwrkuD31JKfSyAJONO3x9CQqxPiE56DxDCQ94UvnoWz4KqnqJhqM6XgweA3PWvU0Sn7H3LXXPrbBlFWl+fbqXrh13CPlIZgy4q6lXtBoGWasQuujvzdbDVu2r19ZSsAA8aFSqcwTX2BXC6dards9ek6/spRZecLAHqemnLO7l7q0C7Y0I596nHaCsE5tLRIO/PXRNw4X4+XCy8LjXplHouTgo04XVQT7FtjcfmlNYIuYaQSdfet+z3pCuT3j9/xieik94DhECXaQpnzXEAD6iV+hPAObZmOrSMnMzYnFRbwmvncvQKWmBnE6kdR8CBUpCvcA71/fwtTuqyNnJOafrz7HZrMz8txu7uKKH/nho2iuuo43epY4D4mqbq6d9+slS+6ioproO7TCP7PZEDaQkGdA021Olx0NTs1wX8Z5lv9H+TYUT9vsnmglLABVM79Deq+syp885gMOh0D9U+cy1YAc7sPOG9rgkNtgzqtEFt8NojS9P2vuVn+qXbENm0fUJ00nuAPt7Ubpqg/ntpJElSSbVNEp/1ntOxuLKLYjXp6ZZzQZxn5JipUK5sc9GXlS7g4MoO8GW0YbXLXR/sprvPbrdKxApo5+y56kHZBYMsizM1YNOlR3FoQU6nOB/7vW7PaEtRNt2ikITzR8lxoX3v15WYtBI4zB1/fT8l02DsWEs0eRZc53hA/L5xKnwzsiE1YT1Ch8jFXukS4K5nWNI9T6YddY5iCZbUMQ9CW/MyBw+KVsf6/hBKS/uE6KT3AL2ku7uybZ6F41SzLgfB+wLYkV2UmtTqetxTKhpzU8Tr6Ie8mTDe59a9QGa267o/Grx88+tvyXQAHWsohRdJVVRCoJ0DWSt46GmOqhNHkhYhYmeNuGqZGejcnMwlwD6vd33vUZS+1NtAZxuu9Qh5eZXLMWFkfKjHHBDep86a4g7Pen1pR+NDllBHdwe4rkP3YBIH6ta83AKz7o4K/fFnfCI66T1ACHSZpnC9WItFpvSIUtT1XDX/RhK2aL8P4Thbeyz1Z8pod/n+0MfQ3c70uIwvTvcCMBsDr3Poesa41gR1C9FZ7lOruvugW2srZ796oWCJM7jWwmyx4NP3c6tE18HFTOEu7XDT7PVx0dpMKujuxd90t2O30UQYbTY75Xm963uvTiuA5F3hqCdvVl6j/5sM1HN0nT4JB+NDHbvzuexATS85nQTZec4EgHo/aKUdzKWD2TnmXtM0hXPNy/xedM9r6Taqu8+G6KT3AL4p4m1Qn8H0u8gE9Kizj4y1CXsvy+L3odDdKSmMzuwRcR1mmYquj6OTDWdpB3OWzyFUw18L77Dbhn7qmB+6qbvzZfXsdtOtxgromKGsddy8zZ/pllP4yW63OgDD46SX7WSgvA51zCXqdpQu7YROz5xTNb35MU24mAZNghiuczwgvn+SuncBI81atZOhy9znDFB1CDg4W7AROm7aGk8NnKolSIzBEu41TVO417zFZ471uLM0KmbSGyE66T1AH2/qupr04Kg/zFHWWWDLSnQVf2k3jupFESWF0eVgUmWP6p1Buu/ipmN2NmGFhMBftd32GYNa2mOr+lhUHpMr+FancN2qn3DOVnAFfhofkgTFwkvfz01hrKeE09t01bYCinNHYNc1R2WXnk6fIzuuPbvYrcaYL3NMUbPvCiZQv2/cLCN9HJTQ6O6E95Bb5K3DHC1Qt60+k07NE8ZgiZPe7WnO9lXiGXKHpz4hOuk9APdinwN1Ylq+WwgBJt1d+RvPY+OkZjcahyvrQFI35nL0aLNHLro7qQhe3ctIvDZ8Oi7uOt0OwYFa2mOHLI25UOVXd69bnLVfzJYpvrpNaUg4ZXa7sNtlDA64VKJVu5T6HNy1rLbAufre6xJMcrKuCJlKXdgbzmeU+L718Xy46N1d7dY6WS3WAXl2nnCcJlzMgq4lSPV2y3bUn73R3Z1r3m4BujrU1ehHuvtsiE56D8C92OeAqz4ne0B9kQK0CVy5+7sKPVFAQvl0FtTVf5JQPJ3Kn/rvqezw9mV1sUaYs4ueFgWuEoImDpOT4ksgdORP3V3f3+VeLp5Bfb9vESLXwqvolsBs10GT5bjXZ6K7EwrHcYqvAXbthK7vvbpab5ruGdkx7TZm6ibhWI9kP9LR3bOx8QWFyzbtThigBpOaH9f9zLV/r0kGdQDaFp+z2uVe0zTFbGteBruuGn3P77C+ITrpPUAfb2q3w5luvU1YymREqXJLgfrIo+w4XAtTigVxLd2dukbQuXihoNfVLLLZM+n6fu7ggLNWMQ8OzHKMjDWi78/nh1Z0d/4FoNUuwfkoH9N+T/lmIrmDr9Pfs51jxwK4A1thVpupHf13lM4dR8bSbkc/LtD9vVcEKPX9lIHC2q4NBBoY1C0/JUuQ1EO6yjLaBT31Y2ToIvwlQYFWmV4Dx73OyWjgXtM0hWvNyy6kJ/TMzTuik94DcAtBcSCPKDsWrv7qvu1RZ3Uy9013L70UhSc114KYMlvmpLsTMy3cWU7CTJjTSUu3fIrXmaPryvKxmK0Q/5n9nNpErNRjtOrZnF0HYXqdi0nR5bl1l1BkNhsfkgRFWx19fxdq/0x2XQtgMeeHL8vt1GcgnvfHlvlC7ajQJTPKmS1z0t0brCVc55h6bijeN+ZcMB0HR1mGMnbK4BmLurvzOui/7wJ3ELn4zLGWctoNiT0qWOLpZrZNf9+jpKNPRCe9B5AWDqOA62Xlm7pflR3xT8WfjsMzPcglwEUZLJDKjLmznOmW4rskDseFO+vJIVg2C5wiTA0U851Zmg6BoFpmAbMDSZk9qxdW9DNJ1QXX5Fuw8dl11XKqP1NchjrKONW7spZV1OqZ049hHnNMcX5c76MGDDPXfFPct93GmNuZjqVLQKEpXEFCoNvzwSFMWncdOIM6XVt8zmpXku0zC1xrXu4ST9e8Rt1RYd4RnfQeYJ7o7r5bCKmZVbeD4IuWVH3O5NXdzRdpuqWhMKZbV/0w1TVwZjlJqfsOZ5mYrlq2C6vdfCEiLOLVhOJaq+7epSbdcUyux7o2g99pgew4P97YPvo4MvC3/bOzRgaEzrKJxLG4VX+WyBSTZdLraOOt2CuugB1dMJ7i/LiFGJneN04nlMSMhmI+Lv+uC93dxrxI7bR/1seO80OZAHB1oFDtcLyTfbB9ZoFrzctd4lnfCYTc5FwiOuk9gO8Mbxu4MkG+2y+4aPhAMZn4jniWX4rpVq5POn9G0r3wSrfUvYHd34XCRrp11aSz9Y7OFwX6fu7yiNra75kyW46AVCcqZbqVpJqmdqvPR7cWbPp+30rBPmpu1eOWA5j67ykxE92dpFymJqBNzSoqBbGmv+8QGOMUZBvXBAIa1aQ75koycb48U6zv52RDuliLQLdAoYsV0IXt5MzO5/Na82OWbejHtNkRpbsTr2mawrXm7VrqUgdfnUDmDdFJ7wEoqblScGeC0q2vB9RFEQb81/6PHZOpNF3KLRhDF2BxC4fRvkTrspyUAQfTWeak1qnH9SZY12HRzKHu7srScDuQde3SSOnunrMydeKWXDoITro7I8tIo7szBpsTxxxF6biocwFlycDExYginMdda4km9dZ17DCybiIeHJM8WFvhpHcpH3J1VGgn7pkdg2+Odl3r1E42Dk6n1LDJHDSvQ9Wal3KOMVHHbOsTM9gnopPeA/iuaWkDVybItyPsqhsC/J9nl+MqSXfXF3P67yj1BMauKD3xYt+d5Zz+nnURyXvd6mjn8mrm6XYmuntNVq/N2F1ZGm5mgbM/e4OaWRPOIKdnJpKzkwHzvO4UK2Scs133k2aXolzGNUcxOC6pHf13FCUmrEwDRyCgybV3vW+onyep4LNuM7NR/l2XQHFdyWKba+sMYnDQ3S3ng1XDojbwTG5yJlSteTlLPJ0t2JiTF/OG6KT3AJzRLi7UiUb4c4TTrU1khbt2tQ61PUQFBqZOnJxqw3V1hlTUMIne8066O/N1c2XwKan8JZsziGnNVCPqyP50uf5FDZw0s0C3k6HL8+Kmu09teqtvTLe+2Aru55jDpm5Ds0vYcs5Jd6d0XFQnnVA7wcWqoazBdgb829DdXQ4nMXPL3dWGxIwGl3OojqOVQ+2YT7u8O+ta81K2dzXHre7jLI+RDtbXoXrNm245W1hSlrTtiIhOeg/gm+LYBnWCXaE5woD/ydSXWrcK9bpwRkCdWc8OmVQbOGjVJpzOMrtgmeu7pVuOGjgtiNPhnNb2UO2gNO0ODDY/5kx2a57bTiJ4rmN6W/BVL7K52RvcLbR0mzzOjwnXIpqjLRVQkcVs8Xw431kMdHe3vk29jbpjkNHdXUwTifvU4oR1mS/qSkxazWsOcTUO1ohVd4gxWOJmUejjkoavEk93uUT//BmfiE56D+C7pqUNIt29OdyLNTm61Cwt6kjFklwLL2axJMrARy01mU04Lt1ytrMp2VSDOC3LMpIkqaC7Ezi2HVrDtUFdjX6bYEldnbL3IKc0W6GOZcRYk25TiaZ8xlyOHWWrInWcNgEp829mhcuRo8yMUpQ6uNhO1A6UK/jYhXZeh6qyjC7dD1wMj26ZdH1cGSjXOC6tFtUOp4aFTyakDa57Mt3H9z6R0DbaERCd9B6AsvWVFNxZrXTre8Ky9hT1rO7uqm3tIkDVFLqTbnegKIZRV09NXSPormfsbkOizq7KLqdok4mqTHq+IKw5p7Nk9bpRKe3H5Jo/Oea6OlqoL7p7/XPLGwhx0v9Za315M3K1rBJCG4CNNl7+m1mRz0FOujtFZnR6TMdif5Zhc9RX2+AMtLMGk9KtnR2Ybrso97sChV3E6Dgp0IUqffl3nA5zLd3dt5MuTP8vWtIZNj0HLfqG6KT3AL77d7dB3UvRV7yhqs4wlCy/i+IqTXcvUwPTLa0Cq76furTD3YJNH0cXOB0X5qCPu2SAb1FQFcTJWp3VLUTHFY5+l0WDM5PBySyoqNHvsjB3tVXyXfpUS8NnYvvU9SD2RncnnD+c8z7FfKtcF5cD2SUw5tTjIHG6XEwVzGzDqTRN7Dz7aDtVSXfvsHZ0tmDrou7uuA6UTIOqRAxvUK+OeUBuciZUrnkZ15ZuhmG67ZM/4xPRSe8BfAuatUFtDZhnR9g2YfkWtXPWawmOqzLjQpiRrFM0pu9by7gArnk5c93qLupxF4pjHXTNAv13s55T7R4jpKY7MxmemAVd1N1dra2on4+mcDpMzAFOJ62aMThQVRpF6lS4BLoY6nQB2iCWswUbw/zaRd3d2ZWAeG3lKvPjnZPt7x+g23xRmzTocL9wBh8rg2sd5uQ6OIX2POuIVLakY1xb1pVG9YkZ7BPRSe8BuGtbOeCsAfNNKXdkVgH/tTK19VoCk1qivLycAlyU2WdHtp5y8QvwBotci2zu6+Z2SsFmd1xxTmddiGpZPcfCu80LvAhy6fs5s1jjioBDl3usvgWbp/nTNS7mDH9dKQNnAMZeGkXvVHBS+TV1d1dwjbDEhEPdvYsOgoutQL22cgWTOEvpZivL6MKSoDums0SLMPhYrKPKv+NMEtUFib115KhY83IyC+pKo/qkseUT0UnvAbhrWzlQV3sE+ImkVb3QQlF3l6R0lsZQRWdmEHdx1mGSZ48MO6SZnsyGLAPCB909qbo/ZpynKrN6BPWObiG95sesg/pVy1lvfVxN4Oy97pvtU+OE8PdJ1/dTCpSZkKKJ1mlLUFKAB4OqVpHtj8upaE2x2HeynYhFJeto9Rz36Szq3e2U+6fHIGT21VHCKYUYq1qOcaqZc5bWtcFMa15GJpK7pJHe5jwiOuk9AOfEwoW6TBDgZ6FZOYEP9L+Rho9ewK4x2MeRbjnp7pS0QPUYbvEbSnqdvl+9xzizuJw0WRPaOW0ZHNB7NtuP0aom3ZktS7ecir6pHboMSp75c1xbb2wfTyU5+UJT9F53Z6BmFUmcBfVUfor5Nt3a2lINOrz3XKJlHAGGLjoI9aKSVD26q7PPnIwPexcC/W+awLWG6xKgqu+93viQJbjGDfBmtevay02I7rHG46qs0ee/L31qLM0DopPeAwwJFwRScItpDUp/I4mqOsNgVDgZ67VmHYMt4yKp2At0vw5iSvWu+nrlR5bIvWOBzBnUUWsuyy2jpuOq+a5VJRVdFveuPrWc2edJRcChy/NSJ7rjW9zS6YQwzVES/bhNuJ6v1C7I7LqEvyjLr2ap023XKtBxnwqUAzRZ7OfBBIdzmB6nwyBhtJZkZKGZqGJ8kFDTnercjQ9Zz8QhXFtY6e4CAWwXU0X9G0m4dBIA3rWl63z4Tob1DdFJ7wEka5Kp4O5tWnz2sdB0ZagA/7UyElmJOlRSo0iz3NWLbqD7dagU9SJ0dpz19UO672K364hUM94vlVmKGV/41erumOkY1uMKiRGqmDAFHIrFrL7ft7q7RE2pDVIttOw23e8Kkj7gjppRWsp4Rba1w3tv4nDkKOcgF/utyWLfTXdX5uiO95D6VV3rHp6yDPszCXSbL9xie7rdRseso7tT3i+VQYvOZsp2Be6xNqhe86ZbzjIMV5AnZtJnQ3TSe4BZM1QhYSYKsEfqD3fv2zZwKuILiu1Vi4zQTa4uJ0QV3+pqRz1fpcwfQ6anSn9BsuZLIltgFV6c8f6o7CDQScQqG5tc0KIqENSlFn7sWCD7XuAkjgUf99zpopL6Vs2myIw66e6UJTmVvbTb23Hepyzzq+Oem8GG691KuR6ZbS7gCBS6M6Vd7iGX2F4ndfeamn0xujtjANtVbsVltw6Va17G+7K2XCJm0mdCdNJ7AOq6KQk4awg916RXvdB8Tx6uSKxsn3SZCd2piE7o2Or1044FMGWWqoq6z+IgplvKTEcdXAwZdRx1t8dECQRROqF1NYEsbWYqAg5dMqG1i1lPpU8up4w7w19Hk5WkawK0NHsK9fI6zJJtbVdiAutxKZ2uiYOq3obu7qLeznqcShvqXODMHnYyYUU13T3dtvlqdcGRVsyLmhZs/aa7V8+N6t9IonLNy8gerSsx6RMz2CeCcNI/9rGPYb/99sOSJUtw9NFH49prr3X+7QUXXICnPe1p2GOPPbDHHntg1apVlX8/D1Af8r7UcbjrdHmzi3Vw0TUB3gl8Fjj75TLXe6qooruz0C8rXmhdJ3E1oFXKoCiBr66YOFRw1a/GUzNbl5Xgs2nPyKXbuvt0lhrKburu5rjosp5VNt09mNs7P+WAXbr13XO33OZO/z2X3dK1ZbzXZ1GJphQbY6UAO86fZqcN48M5j6dbCqfLrew/+/lxBSkokwZVdHcJNk9lq8A2Nen5ekTf36VtnWv9Rbn2GlecD14R0cxGYIkpRyAN8Kvu3ieNLZ/w7qRfcsklOOOMM3DOOefg+uuvx2GHHYbjjjsOGzdutP79VVddhVe84hX49re/jWuuuQYrV67EH/7hH+I3v/mN8MjloC7+euKj12aFAT9Rxeqa63TrbwGcjcOfk15F8aRV7IXVjvrVKenunJTwOgcC4K6Z1fdz3i8u5xForu5uBqOaHKPquLI1+roNFV2ug7O+3jPdvS74yt0n3a2czHFt3XMhbXeIdMuZjXbRvVM76bYdJdo+91EGGFw04iaL/dk6cHQYJPR7UJTu7sjgAt3uU9daqYvj72wbKsBsA3hZicUzpu+nFCdsg6rzMWB9N9IzMXZEeHfSzz33XJx22mk45ZRTcPDBB+P888/H0qVLceGFF1r//vOf/zz+4i/+AocffjgOPPBAfPKTn8RkMsGVV14pPHI5+HZs28BdZ1d89vGQupR0gW4RYgo4FYwF6e5VPVeHhBFQ16Kb0rFVaW8uSjhl5L6SFSCpJssYqa5ysGd9+ap097bHsMFVYpOdHha6eyWzoP0C2TVP+Z6j3LRzbifdbrdLFritTXUfq4gmIQXYleVT7bRhBbhYRJT3g4uq3sRZdFKRNQeK5n2T2tF/x5nBrdIJ6SJw6MpId2JeOLU20i1pe9eqdxRr5ti9DvAxb1eteTmZWU7x6B62lPYJr0761q1bcd1112HVqlX5vuFwiFWrVuGaa66Z6RgPPfQQtm3bhkc84hHW32/ZsgX333+/9l/foCle9ySV7opcDwYDr0J4lcJoQ7qFVxu4FHg5XyzlMUxtdnDCZrPjWDQROraVEXXCCLIrm6rf653NlOBWPeaLVFMIL1bXx6ZbyuwzZ5CrSjW7Wzu5dOvK/HnrQOFaiDJn+GuvLWuGsvw7jnrxcplGuuVs8wZ0rDGuCzAQjt3dCqzexligJElnbgnOQcyBQtd92UXck1M3pDpoATI7JmbRPfAxb1eteVn7xrsCukqpYV80tnzCq5N+1113YTweY/ny5dr+5cuXY/369TMd401vehMe9ahHaY6+ijVr1mDZsmX5fytXruw8bmlQUoClMFvGWnRIAGZrMea73tMpjiQwriqKJ0cvU1sQx/yb9jbc34WS5lW1mOekJ7uuFWfWpvr+mO2FX5Wh7JTVq6uBY1kgY2qz/F26KI+7sxD+5k6ggtLJnkl33euMAamqmnSG0h93xpIiG13/3HZjfOj7B4TveCfrqkGG0jVvDQaDYr7sXJOuOullO6mNTiasqFxr5UG9ZsdMksQtCtghQFVPd298yBJmobuztsKzPAs+E1NVa16JrgNl/ZL+JR19wjvdvQve85734OKLL8aXv/xlLFmyxPo3Z511Fu677778v3Xr1gmPsjso66akUEmv8+gMu5R0Af/q7q7FmuS4ZqN40lHSqsRuqOiH1RmGTiamx6jP2HMqi0tmF10ZKXUcdc911TM46HC+6oT0OOtBqVkBbmVl/ffSqG8Nx2M3ccyNMjRi272ebkmy3DUsAYqv5nK4VDtNz2GSJLXZMsrzU0VVry2xqaT80oxVvfddZVw87KZ0a8+UptumTqn6XShril3lUqTMlIl7TuYM6s3U+s3D+r3y3mdMIjjfYcPZn9sIYIFP43vuuSdGoxE2bNig7d+wYQNWrFhR+W8/8IEP4D3veQ++9a1v4UlPepLz7xYvXozFixeTjNcXKOumpFApujMEMPZcn2MdF282qA7FAljfLykc51qEa+MgjHa72huNkXSnu89AAySlu1szGQDGvDXprpcgJ93dfn/of+NCZTa+wz1WXy/d/Jh1qFLN7uL8OOnugnOBDe5AYrrlGpdfujtvQLdOf4BSN6NaXKzZMdXbuizqlm5p1N3tNtQ2Z+NJgoWjimPUMl6SzgEm9Tl3tsUU1sVoew9p1H1HwKFVn3THdaDMNKtaNCY4tTOq2pMOhwNgkgRHd+cMrta1YAP6k3T0Ca+Z9EWLFuGII47QRN8yEbhjjjnG+e/e97734Z3vfCcuv/xyHHnkkRJD9QrKuikpzKI46qVnZFVGgTA70hRauzDBejYTLsoW9Tiqqej633S1UZn1pVxkV7wEOS5d7uyadDJGDYNK9f8ZHZeqFjkU6u6S9dLVqtnt7jF1mE66u6+SHMeCj3tOr1cR57NZXS7T3Y5rEU0ZbKvSTmhL91bHxangXEeRBurvu5m6lpAFhcu/k1DRrmwr2ziTrl5bmmOqx3WtcWjfx+45mWOamoV54ycxlW7t90e65WSZdXluIzxn0gHgjDPOwEknnYQjjzwSRx11FM477zxs2rQJp5xyCgDgxBNPxL777os1a9YAAN773vfi7LPPxhe+8AXst99+ee36Lrvsgl122cXb9+BEVjc1SfxRsZvClXEB1EWz5IgwtVk/gfs4x+ok6aTKCYyrsn6J8EUzi9pw1yiri5mQ2tX/hsaO+15nUU910Pq6KPrWIVdzrqxvm+0Y1WyN5mN3BS04GTKz3MeNs1gzOD++XgM+SiyA+rpkzky6PZiUbinuKdecSynqVEUBbht81TLHjrpT0nr6qpr0GjPVZSk0Y60sr2INJqVba+a4pVM6qZiDugSB6xw3WqHBqncUX7CkMhDkJTHlXvNKtKRzqbsD/Uk6+oR3J/2EE07AnXfeibPPPhvr16/H4YcfjssvvzwXk1u7di2GylX9+Mc/jq1bt+JlL3uZdpxzzjkHb3vb2ySHLorRcIDJuDslSwrVUeV064OyWSnylU9YkiNKoU5WpXpPRvqyicogBuELrir6T+XYcgmUuexILwqKxZn9JSjfk1f/m7pjcKm7l4MWs42rDWYRyOy0QC45P+nWN91duvet2272e76AVFUwiWb+qF7M0mTSYbWh7mtqp4ruTpmxdIooqjXpNc9D1bxFzdyyC7ilW47AaTXNevo3DeeLyvr6Dt/F9c6iZKZUdmXI1p6MQfNKAb/Q1ryMCaA6ZhvQn6SjT3h30gFg9erVWL16tfV3V111lfbzLbfcwj+gAJHVTfUl8uQreleHWTL8fujuyjgIa8CaYjalcl47VIummajIjHRM1TavMIthk/E+pmg5Nlt5AN0CkPMazFLv18X5cWfSPTnpDnE+zrp/oMqR5QyC0V9bG8YOO6qjmySJ1cGc2UaFA9GWjVDVcow2oJtuXRRpoH7sle99MqHSGe4XxgwuZcmN+velEpMO17Zu/qBhjaTbaro7X9C8T2teTmZWnUYM4C/Y3Cf0Wt19R4Kko0aBYCesWcTEPNPdnTVgIn3S3S98WkpauuW8Dq7Fr2qDRN2dILvcBhILnpLNWeof62rSZ8o4tBib43zwLpB1GyraZr0rnR/P7wEfbe5mEdKTVCcGaOcPpxifVrvZzUa1kGu756OS8UEZxMjnC32/+l1q1d0rgmlUGh5VziGnYFll5rjlc1mlkdMlQOWeP9D6mCaqNE8411KzBGm8lHh6WvO6WrCp66S+JB19IjrpPQHnYp8Ds4ju+KT+hEpJAmyRx/Lf8I3DPgZALQegcNIrggFE9P5ZFk2UPd/zxcy2zfnveNt/6TYyUFIHZ7Wp7quvD3Ufo8vivtaBZF2Y0d1j1XR3PpbELHAFWCTuc9VO/jNjiVKl4NJ0Fwnd3bGI1loVkQUsq565ZsdUnyfnO4tRCKxJj/PKMh3iTHpV6y+Ox7b0nlt/I7DpLm1f0+9WFSjskjBytWCjnD9m6x4iFzRPx+J/bVlVkiXdCYayveS8IzrpPYHv9mBNMUtvRh8PaDU9Nd36yfCr43C8FCWcdCGxtWq6O41TVeVAUVHqAUOw7L++AKzZF/jZ1wDwOoh1PWdZHKaK+2NWp3SWAA2lujvnQmSsXnsDbbMnlU6px4yMatdZG84izqcGLSSDAxVzIeEz5rKjC6N1dSDTLaUgqDomymxryc4MmcA6O1nm1O5AZX9D46RX1v4yzkGj4QC45xbg/D8ALn6lbrfh+0ebg8xnLj/nzcfqCpyTahhU0d0ZtQFc5VaAXy2R4tkv/45zXFXPnO9Won1CdNJ7Ap8U8TaoFt1Jtz4e0Ep6qsd6T23B43opitSkT20yRz8rs9xE12GWtjukdMzBAFj378BkO7Du2mIfeO6putZELDXYBHX+1YGgLpn06TEEgxaV7Y9afhfVWXKJifmmuztbKDFmZAA3TZaH7p7ZbM8aaWKnXKah/k1XVlHFc9tybaGLnRrHFDg/qp26Z1tCebs6Y6n/DSW073bvunTnvbcCaP98VJ+v6THb1KTXsJ2kWrD50rDwsXyvCnJx1uhXl9ik2+ik1yM66T2B7wxKU8xUu+rRGa5WLxcdUmqzYiHKrZysouq6UZYpzNIrm6wlDnHGtmxHuacyqvu2h6e20x95nBcUdhVwvgBnqcGeuU96h2PY4GozxblAnq2VYPsMpSsA44vuXtevnLM2HJDVG6hybEn1OVx0d7V2kyjLSxmwVO8Fp1gj4buiMlhS1/Zxpvc+H1uBVyck3Q4GA2B79v55SBtLY1HAWdhOnUqS+JgXrlacgIw2ALdQbVNIdexpYtdnQqxviE56T+CzpqUNuBScu6JSTMxnJn0is+CpHYe5CJ+M0/9A6yBURVmpqOjjGSLIFH1rtcXZ9tQ5zxZJnIKPru/H6TBV9YSf1W6Vo99l7K45R2QhQrgwKxbd7naMvjLpY4fjylv3X3yWvNdLc+GWB4Hx9tSuNN29c+lPuqUMWGanvIuI5CyoDDDM6DCOZ5pzOgwSszlDHI+t1npyW/b+2azZbT8H0QbrXYEM0qDOTJnjzmZKqGKPcgYH6jDLWA4CHAAA5GtJREFUmpdiHVS2i6ldWUbDvCE66T2BpHgYBWaJKvvIWFdS57wKx6XbStqsiLq7YnMyAf7+GcAFzwQmE1qxpIpFAFVpR3VrmmwclJkwKJn0aSaD6Z5Sr4FTKI1jIZKf0/LvZg18cKi7J0niprszspAqVaNbsgKSqsW+Z0aVK8AiRXd3ObKcwYHhYABsvh/40CHAZ1803VceW1u4mCXqz13Pa6Xj0vKZqzomB9Ogsp68rsSGwNGvQ1HCVf6dRAu24RBFJn28BZiMWweJXawkoGMm3XEtSd/HsziHjPNUld6Rj8SUP4ZHxflgXKPMG4Lokx5Rj1lpXaGgWkRF/xtJVNfnpFu/0U7bRJpuZdTdlRf+5nuBDTemv9j6AKnDOa5aBBAFJYqsb/l3LHT3oZpJn9LdmZwq9XjhtByb7ZzOQr1tXkNZfObM0piYrW65md2ZMh+eM+miAm7KMTkFykp21etwzy3pfHj7f2njoBGeTLfmOVW/KlnAsuq915LubhdNnB6TZH5Nt5UB3bo5ZxZHn6ykgDdoUbabbjW6OwBse7i1MzRTeQRhTboc8wJkdlx2uZklTVGVrKBiLdpQWS7UM40tn4iZ9J7AZ01LG8wi9uKDsjlLT1Ev0c6Je8EjuTDXIujGC58yI1lVN0b14qh0oEgXBYqd7VvSH0y6O/E9pY5bsjyimu6ebuu+a2XtXsvros6Lko5cZb1sywxl9X2b/Y2f90Cd8BNAf99V0d0lOhmMhgO91jdJlLIDAjvqPfSf/z973x1uR1W1/86cemt6IwmEQOi9g1JFaSooKlZsoGIXK/bv05+IoKL08qlgAxFQiqC00BI6hBJSSEhI77n9njbz+2PP3rP3zJ6+55x7cdbz5Jmbc889e87Mnr3XWu+73vUn4Fd7A+tfjtRiLMgafvtebLSVHP3p3QoTun41xiHXnCRlOkEWBklNswSJ0N0dQXrMBEwotlOMr+L1uSp9izAlSGmqu/u3OWwBAOQHVjQhyen3zGV092DLgvRRYqMt86SibUoaFiZ5MGLFPZqCpJOjxte3AUBtUGmAoAIdCTI/9EgpHZN3zug1q6ZLd2+VuJiNFrh/F/a7+tbuxa7j5pIWHr3F06T0qRQXC6PG2+ogPU1qttP8W7CRY+otlehzbTaARlXpXiG0BV30L6B3NbDiUQDq9sowZV6R56kv+yuFoCuBs+/3/VWVTPjV/TdHoAs2kwsAaoPxEzB+AWcCcU8vJpbKdS1ccj7xMJJxgwGgVjBhw839NJJHfuPS94yOeKaVlgXpo8RUZdSbZaH6YLfgq4RKHrRyIfULKJuBpAsbvjMrr87R8KO7q3KA/dAjld9FpLuL6u65lNTd/RSvU6WwhUALgkWcvAP9uA4g7/y424OJ46o0/zYz8eZYmPrZVjk3Xsk1nhGTlv6C7zVOm+4urIWDiQIVpwmBi8XAQXXAfg0KqNgh6sdj092btb76JnQDPsNHO0LVfhPmPNPIrYnzx4vuHu/e+jIhY3wZr1IelR1J0uhkEMa8RDUB3udtAQCUgh5FGPNdt1ucbB5NlgXpo8RaWdMSx/w3LOs9LaS7+2f/W0dJanYW3mmCaJWLOtdcdCTpOOHQo2RjAA7ap1M4LiV6XRgKcDpiWsnvm58wWlxnRmQWOJMW6T0/jVRYAeToR9ds1Tbg5Yjy11z1+umLBGnNcDI1B6toSKmTKVxTR5JPlRq1HwU4aatAv89Uk9AlxyRCYH7UW3XCcX5BCTmmWXJDatId7LeYz0daCRiv/UOl7xVGfyCdvuB0DA1Y9TRwxeHAaw9Y50J+10qWphysEN+j0ho+z1yr97HRZFmQPkosTYXiNCyMY9WSYLhJ2f+oFgo9a8L1EhwiJ3VOITXK3tDcv1M1jj9rwnqParq7owVbWsr8YRSvU0UXZWJRIR1zNsd8nfto58V/V+e5pclE8UecyDGqQ+ifCOHe10IRIr+adNXrp5+z1wz9BYEhA4isIoUJS00D10LL0rRQFOw2/ALIhNoJfmJ0KoIhW/jK/buw16cR4lwT7zchkmvp9ueGmFivD8fe53yV+xME1F7XSKXujl8pXZqAh1D7veQeYNMi4NU7ATSXDem0UCzNFFl3fh0CRgvo2ErLgvRRYqONHuKXVU4T2Qoyr5oo8ho5tjJI901qNJPu7tzwq4NK56BvllXRAt5sOqYg3KPYyXaNyX2ep1BaKg6hOAZvYR3CVNTduQDDG6WJ9JGhzBc9i3nv/WiCQjDcyiSnL5Kudkz/vYSOmfJcd+pzKBxXSGjXnEk+8t+k95r+uW+QGjOQ8xWGUlmz75MICzp3P6FS9fuN9/VIne7uKMuIuxf4+0kJkHSPMjeVJZCtorsLPpzjOW5piaffvEwxWPZ75kabxlYrLQvSR4mNVrp7mvSyOGb4bPitVHf3dXgYMpr+eQgLuos6B+s8FAa2CRyv4DGsz0uZjilk7h0t2NLKVPvR3fmvq5xmr0DU7M2k7u6ftIjJCgihmk3GbsX6aZ2HRyKEvEf1XJc79vxrTa1Jr6plFUnX3KqY5FOn7q4OTRMQXOdnKqx1DSMEFr7tY3pool8yKU3kUPAdPBgfcRMwfmJjcfyRZnSH8OvxrjMfL9EQUhO1AURtiVYix74+bxNq9EcaIDbaLAvSR4mlWTuShvlurJr4nmZaKLp7C66xH9JBBbaagaT7idCkRnc3DGDjqywCUOU0+W8S6jZrtgmadcCoW4NXgUY9NaTPpXjdqAEDmwGkSz0O094mWGnZz2Emx0Tq7h4OYCqU6BSc/zDXGLAD5maaV8DMn6p6kUQ6hk/CN0UasRRJV5rk4/YkD02L5Poc6hkffi3YlNYYK0jShNkLVGmgNLsrg0h3F7UT4t4Hf6VycoyaADZNM5DuDqjrZNDs1l8N6XOcbrI+8nk5LGySK46F0q/JgvRAy4L0UWKjjR7iV0fW2tpvcvTNELfA+fWrGWxmFlaoq6LZYJCf06CkaZoGPHk1cOURwLO/AxC/RtJpfi3YVCZk6HcpmFXxF1wdf+qK17d8Avjl7sD2NwQHKL2Ayf27sIJ1fkhxbBEr7vlx9423xk1h7bTXOXWsgDB0TaC1IkTOc1PZ09tzTJ9rnEopAx90eSKUCsbhA0gn3V0VFdsPGU2aTEo5GFLR2sofjSfHVOnuCjVQ3OPCHtdJd0+8Brm/S9xyRf6ru8Q9FXaHaPisyWm2/hKTepbvxOju4nuaaeGSRymM69uCLb1x32yWBemjxNISoErLQon9tJLu3mRUJsjCOKLN6ZPObXB1OZKutAWbrgFblpIXtywDoI414teCLQ26e86oiL9IgGSEHZPN4w0vExR/8xIhkFONtoahu4dVWvbTq4geMIjnID2vtMWCXOPSc1OHUPL1fSOtC0VagoWh2mel6nTDhaSrRMbEIMtBd1dFxfYNUhMGctJEvPieJOZHvQ695rDPcP9Ombq7Xw1umvNUluQBrGQSPbeIn+kHZsT8LmIHDvlnAgo7GfgkOZuWLBkBdHe/RHJzkhbu37WStTraLAvSR4mNOrp7iLYprckqejvV9LVWIlR+m2IzauVFurvcMVWj2EvHgT1OtR+ASqcJwufxplLdnTmRjWHxF5xwj+pg2SXgVR1kx3TbYfkF6eHG9EX14tZxh6CIp0PpI0d/tEA9Qgm0JpkorA8OSytg9qW7p7iX+K2FKpExtvajYZfLpKXurvCZ8y1bSaU0Kv44fho5qvyRMOhzOowPbtw6lyjmk0lRNT58ko9x1zWxA4f4wSoFMf3mS5r9yu3ab3CMGIvu3kJgyvdepng9WtWV481mWZA+Smy0TeowNXCtqakkx2a3owiyNJCOeOfB3TcHdU5lEkNwLKxsMw00VTn7afTj9hun4ELS1Yrt8eZCFzmhGh7JaQ3dPchhJkelIlYhykXSofSFYBYoRCgFunsL9gKbSur+XVjqceQxfQJMVVTlwHHr8lpflawivSGut4A6mqw/qhVvDNdeWhsGhrZZn6kOKfO//+Hug9++r4qlSOd9s4MSYU0W5ulwbBaenw5AUsV4/jNk/x+JCakwJtWwSLkVa7jzIkc/Ib00O8E0e9w3m2VB+iixNGtH0jDTd1Mkx5bWVPohX61wfsNQOptwWkL200OERsVGIwj5eGxoSW9DmAyySvVhX7q78pp0ctQ1jfyHBen9Drq72nFdQmlPXA0suJm8FtIhbPg5gAmpt76fmQrFMRhNVIlQiuru0T5XhYVBJNUnhoLXxnQRSjhENAeVImNsr3QoyAPqqdh+QVf8FmzWC384Dbh0P2C4V2nCxk/4KqzQpG/iS9EabV9jyRip0qw5n8Y5T2M+H+FEAaN9Jr+m+wlPJmXq+dLdm5Is0WyAw9FKsRUAkOnj86a5fvq2PWxhDDDaLAvSR4mNthoOIdgb7gWevQEY3AoAsSlYKixcTW1TTwmA/3kxanZTkHRrTJkIjUK6O9vQdHi2K0nuNEH4PN5UbtbMifShu6t+boVAt16xG4VzAQSQnmBdTteImvy93wbu+BJgmqGp/f79U8lRZU16muuNL7Mghfp6fqxWtmBT2W87cEyfADNNGqmfcJwWcq6HG8f6foYbSVeVTPRlr6gSF1v/ElDpBba/oVSfwE8ANCrdPc3yO7/nNs1SOsF3cDA+9Ji+g3+HCfE9UT8T8O7AAahg0JGj331Ile6uaZxPo7aVYhwTkmmmCbx6J7B1eern5ddRoZklnKPdsiB9lNioprs/+3vgzi8D8y8nr7VQ2dE3K99S4TjxHHhrphq+EEC5kHTyo0rHS6aEqiqwdSU+HrkYmHe50jEA+7vkDYe6O1cfrvrWCdoKvAp/dUBwxJWPy2/4wz3kxUaFzI+Qzm6YdkiR+6SHoUSnWHen0iF0Ufefug74+6eARg1Aa0WImlWHLI5Jjs1uqSR0UPDQ51BC55Yl+RSru9via+7fxU10mPye1aiTdQCw1iDE+kyZ+a0XWsj74NdRQhWqF+7ZSDSEx7iwxoWrbWrikhsZeyVuUof77i51d01TlsgIExymyqrSYd+HRgUwGi0F2QTgZe3zwM0fBf75RXKuqV4PCGPwpqqDz3+DZUH6KDE9RcQgDWPZTF0D+jeS//RtIK+1kOril2Vl59XCWk9fpKMJ18sOwtzokUoBLiG4qYpZZ1WInOA0DW0DHvwpcN8PgHrVHkPBd2GboARJTy1w4cXXHEE6ex3q1wvKMpGNG7Y+2HfzjolquVrS/ft7wGWHAMM9XNZefebeXzk3roNMjuz6PHYp8PKtwNoXhNdbq+7u/l1q6u5NoCrLTKxJF6no9HYnnU+madp7Ej9Gowo06spo0n76HEkTY6Q0asD+BVdyo+KZs1lXPiyZgCH8vr9quruc3psm44NH0tWUZYQRso2Lzgd/bqSP9Ryn2R18pC3YAFFAtgXuu3BefevIi71rAKTL0gzT9nG0MINbaVmQPkqslQFkHJMuWA717lZQXcL13G3deUmRjiaWB9AgzKVoXB1QutEIaCGrSU+H7q5rACp95D+mQZxIhfdaKvwEWHTDdJA+IZCrSoL0lBBGkQHBz4/+0I5oGHX3qI6aqzfuwn+S1n7rX0qV/p+GCrLLyaxac7fSK7zeUuHNJjJ+2HxpIsWefCYdQ3OxipT1L+f+XJbkU4VI+wa6CbUTcjpca5DKZ853b4xKd5cF0IrvpV/rxHQRXJ/EemQ2DzmqBA38WrCR19TsyX4lSOmq7NNx3Um9EdPel65jFeKLNyN55Ls3jpJ4ppWWBemjxFqpPB7HGrIgzAogtJScucjn5bCWqrv7UYCbiKTb9X/w7JOuUixJ51GYqmKKp2dAOaD0mjInsuFWd6ciQmnV6WqSrD2A0Kh2/HFhq/IDgmMeNKRr8370l8BzNwKIT79zOZVWQtBJ/09L7V5l0OpKJFblmg0tFd5sIqU3DPMijWshsDOcCCUbN9kYArooWz8U093lwZH7XMKYtEMHIKyvQLo08rB7RZgSm6RLpa+uTIpsHqGFX4MrueI1UaKyJHg/wGFxlcob3LovLV1RtGfZrdBk90E8F5Vma2cYjvViILVkfZTz0vk9uyoG6WnoMIUpBRstoGMrLQvSR4m1so47jglBGFsY0kX5wphQnwMAfetZrWdrF1JybLbwlfs8PALb2pDShVVAPh1JHFVOk0BFdgaUCtFINtclTnZamWqhxlRCd9c5p1DtuOSYc82P8A6hIHrXtwF44H+Bu78BmGZiESv2XNPAttInBNCqr4e/4GO8OSYgQY0aYJD1iTpWKut9o1oYAS7lIol+Tneqtb7eayENKFQpUQOAXh8Uf6lQRd5PfC0p2iokWgGgNiCMk/Te+NcYW+8JOHehft7jM1SVV8mQQ/7c1euTkGPBrIm/qA9zCb1onxmmPCDq3PcrNQTUgSQtp7s7tWlqQy0V+xT0GOg6Vh8m5TQpXg/fZ26Ule+20rIgfZTYaKW7C0FYjQYQ5L+teD6FLOuWZcCv9gRu/TQAKENH4pgddKmjl8UxQaRJUX2bfBzLoYEhCseZpjKnSaAiO6jZqfc5Bhy02MTDCCYmwXzo7mnVBzsR/AjXVDh3XnyuPpxA3Z1DCxwiVmn2FvcPWsX3hP5Mw+MaV8RyoZHWKjItQTuX3oBkzDScPebcumjE8RFKp/EBrOZM8lX5cRINE07zJIm4mGMNEoPSpEEXrHHiB11+grGq6e5SVk2KJTf0u5fgbgEaVztBmPsOi6spxHwcjyBdWetVn/IITVEiQGb0Wc47/YDqYEtZmgJY4dCOSLdPus+6PcqYwa20LEgfJTbaMk+i+rQDKR0BdE1NA7BpMalR3rAQQKvV3cM4Eemfh1im4FXflnwcW2yNdyzMVOo93SJn/UrRSHbvpHT3dJ5b72DZ8YylFTBJEPywDqGAjFJaOgBU+mMHP8Jn1pzUW+59qlFev+c2LnWfp7tXxXkLtFZ0xw8dSQst8gvSGLsnzVpfZ5JPoRCUiKRLknzKUF5yVIlq+dPd7f+q6tIhC7rCPmNCeZDHZ6i6l34JO/59qox+XsGQMLlUJGAclvQzPWJ0ZXuWH2IfV38hjLH74PIDBprqwznND6xIE+H3LTFp4fUYbZYF6aPE7L6soyNIb8iocA6UrzV0Tdjn4BC0G6k00mbS3YWsq9BzdSB2ACUzhhbyYwBqHWAvRFKon07+XWy6uzuDnlaw3PAKlml/5ZSSelLqHCCgZ2EdZhL8iEFo3HsvCunJlaYB9c9QKEpfZGeWHGXXB+D3gmjnqsLCOV5pJUK818Y0an0Fyq+XPoci3QwA0FxMnAFl47ja+nEWXzvB+ntJYkzlM+cXYIcWjuPLdHrXAf/8AuuWoIxm7bzGcy8C/vF5oYxHxTiuca2Pc9HdubaYscuHpOUBMdc1nzZ4/Fjqyg58zj3NpJ6MUddS35IcZay7NK+Hb7KkhYnm0WZZkD5KrJVU7DgmVYF21hy3FLHmnHkHjbS1gnYy59d6T7Pp7jW5Ywqoq8XMGY4gXeHGIYqcyTcnlfX1aSJhTjNl8xjgBGHSGTcc3T3gM/jSjqr8M+K29/H7THJuqpMWPghdTMaQ5zVm65T4vmaaX3eM1FkjPureQHrJAQ3wpLsnrhXne0c7E5Y83V1VnS69XmufB3poG6Z4SR+BdeVMjCm8L6ztY4LEkPBMvXwr8PyfgCevjvQZQSbsnQARxHzhz8C2FenWpFsfWDDd3QHiapOEqeuOu67JAn9+LFUiiTLRuzSBGLrv5Q1nsl5dsi2OCXoUjv0kTbq7XwmnnmLrtzebZUH6KLHR1rJAaJtS49SJTbOlVBdpO4pqv1UL3TqE3xeRa2JSQ0A5eaexUYVu1u3/qqKi1yRIumq6uySgVLk5uTLoxU5yTLFPuqeAmyMRlmp9sBAM8w5hkMMM+xx5unsENN71mQKlT0T1NE1LjRbtag9FIF3yWkzEW0DkmtheL4z51hmmJOLm14JNSzP4sT6vaHoLQakKngFAcyX5VKq7k6OuaUDvWuC6E4C/fMB6zXpPkqCrmt4zZ+vIuH8XVp1aSPRQHYyh7QDUJb0E8cpGzdbFqPQKwW5auhgFKlim5ciREziMXj9Ojn6MmeiCmNwaLTFViWWG4Prp+6QilGbdfx8B2VYgx7yqvugH9aUK/oURUhwt5buttCxIH6nWqAND24Bh0hu3lVTsOCYgTNTRNBtAvdJipUvOyWTOvCm25Wohki5b0JoqHCdQxEWnkadxJTkXPoiTUsQVzQ+/um1V6uemabrV3dvGk2OKm7PhufE66O6KAyabZu++prmQDmHD877ER9IFxXg+YHD2g02zPVi9Clx5JPDXD4ljRg5+uM8UEg6kX3qa4kdBJiS+HJbeXCdHP7ozeV86Cami6RbkSoXuLgnSVa1TQgDZs4ZA+NtWAkgyT7nn2BGk85+r6tz91N2DdTDgPteqc21IGhxyiQDHGiTMU+VBOjmymvR2a/9pVJGzqBpxmUnstNe9CKycJ7wWd754Iemq9qxQ5REp0t1zDSfwoG69iGOe2jyVfmVdKuTjhmBjjBLQsZWWBekj1eb+DLhoFvDQ/wMw+mo4hHoUB9LXShE84byctNgWlhT4bWDNTB7YTjhEJB1Ajguok9w6/nvk+E0DSKcOU5fMQWU0Uvtn5mS3jyNHhfX17nE9At3aAGAYqQdM7uc6vOibpyp0pT90oO80v+caSJGKzSe1elYBm14Flv7bYgyR98QXbdJc1wdorYioH70/LUc0TH0sf27KxrWChaJTNbs6ADqqKrExTQM0J6tIoaaF+MxZ7JVqH2AY8UtMBH0KH4FDRfTlJDoIYvkdLXPrEz436VopPBsurQ37v8p1QiiSTpNJbePY7/LWa4k6TJgm8Mf3ADe8GxjaFnvv9BOA5F9XdR/8mDdp6HmwcSV097T8gDAm3EuPLgzpqLuToy87dJTEM620LEgfqUYpsw7HbLTMaeYUwPQRh2pFVtEDCeSyiq2slZdtLK2gu+dQFwsmAeQ4pCfJos7/qe7MOiuswxSUt6vO1iPWexQ5vwBXk94+gRxrQzaVMqUAwlWDDQD1IWXfzzUuf01jshOEmnSnEntMp8FTMZ6iZalfD25c0xCU/eOru0NaypCmQrHvefHJtSYmE31Fz5qg3F909j02G8iDlP6oUqLOaZorKUrmkHgucU1AFx1JveTaCZAj6YqeuTClYGHZOzke5a46tWgSnabIMhGQ9L5US25MZ5BeHst+R9uBxQ6odQ2oV4DBzYBRA/o3sflCKnvCf65f+0ZAHboqCG/Wq8Ct5wILbiJjpAh2sXkq1aZpHcjm2aWi2pcqoj1SOhaNdsuC9JFqpS5yrFC6++iih7ANy6gA4M65pq73axzzE7tpZfKAXos0W8SEMTpGia/DLJK5qNcHuPclCdLtv9VcYknxFb7d45BjmmwO4e8p04DR3dW1k/MaV3NSogGBKaCaxiayE+SK+cFIOjlqEppscqEjSFvSpZW5FxNBTlZATIRShvoBLe9CISSkJI6XqoDSPS45+q2NgCunqGBcGvxYz3V5DPsdDX6SPl8CSlzzrklPTKsXknpiAJmLuR8H0d1VPXO+6v6h1d259dIhGEvnsioxVJlvAYidCFQa689Nk0mFNiDfRn60UN3IooAy5gUg1DED0fY1P/ozGwvJ74PAmlj1JPDS34BHLgaA1JLmAPf9XOrug6mOG2QiMOUow0jR5xXWtnoVWPEYSfggPWHbN6NlQfpINRqkV0VF39ESpLPMtavm2K5dbXlNpac6dQuRdJk4TlPV3S30iFE8NUaf49XLk9DF+Puek6FHijY0oZ2cIsTWafx1YHR3SjdUSKt3moAMuWiy6ekriKJvYuu3sIicrfoKB/0ufmbfT8QKSA/lFVA+h2OuxUw2CTRiIfAn9NxmMmt44++rnyiTcpHEECwj5/mpMPpxTJCrNIaJctG6U3Wq67D3IyY8ORR7DjnN9Aq6EiWTyFGWsGOvQzFV32FhETmBscDo/pRlo/o8nSw9B60+pedDCNILJEhnSHrEMYW90wKKAACVPuHZjzL/hZIkiam6D4JuinXtqUhgmnoenl1eBLp76wAgWYlamuCfcL+fvh74w2nAE1cCGH1C2K20LEgfqeaku6eEjKVlzClw0Zk5pLSl6sROBzjdrGKk83JYMxc0OgZTNM6XgWI7OTcuoE7inAp13M6adIV1mIIYn0ctlqqaUoCvSbfp7qrEk5xmes1jINXkgDd1rj80EiKtDwUSqruTowudT7mOW6xDdSCUMeexgGLVJAhlE4UkeeOHk61TWkpzThDkcpgQMKSlmk1pxIUyUCBrIW2zlJgizTvQdQcTR+FzLJaDiImxuDRsb1aao9Vq0jWWL49xWFS6u7BeVvtJTb5ifRKvNSitkhub7m7Nn7w9T6n/FXXdE9Y1GugCwroGREvW+7XkAtRR0QW6O2NNiAnOdNTMydFVky4w6tSPG2RCCzZnK1pdzTMqM+F+b1tBXtz6OoD0REbfjJYF6SPVSlaQziiOo2tSswXLRWeOXwOnwkRVbGedcguRdN6JclgzRQPpVy8KjinJyvPU9NTo7jWVATQ5utuUqVPblQfpTaC780Gpk+4u0GSVDiu2w3LS3UNm5UWHWXTuk6q7u+nuooKzaidJYMA4e0XHTPqJDBBx3gJQhq5GNUHw0U87Q/F5BdFkbb2WdBIwdpDOIZR1NXR3EX217jVbP9TR3UUGjJzunmieyujuykqKyDGJWKGw7/PnWlPX6cNvLQDUqd27xyXHvCGZpxaSHrfDRE4SpMcVwQtuwabm+ogJbIs10agA9UqqgAcb11WTPjAiACDNuTdW+lJltUqfOZosyZD00JYF6SPVirQmXa24SbOMbVgu6s9garVZYUxQnHRQSVupwNngnSiHNVfdnSLp1oafb2NZeY3rD5wosOX+Vpcg6ao2NM9aLC6gBBKyAqR0d+pkN4Hu7kS0AQfVWjW6SI5uBWM7+WaY/sGLJ2U+kbo7jxZ4o3rpiZq50bP46u7kqDmvT30YaNRbVt8oJKQkjnZqdHefns3kdet9qdHdubWwSJF0xXR3/jlmTBz16u4C3RtQQnd3IceNCtCoKXvm/BDYsIic4VmTry45L9B7JXT31PYC67xZkJ4vk+Q6eMZHxHvLsyQq4nzRY+6dQS3YVDPodIn+Qpq+FBuXAg+lMeSosK1srPPympcROrLEMamoquKOCv8NlgXpI9UcwnGqRDWaYULv6LozCLNpsS1FrKU16dZ7WnCNTT7oclgr1N0Z3Z1D0gVkJ8GpCHR3SU26rgqB4enuDuE4QRVaEZLO1JlpCzajjoKlAq363gXS3VPSMfDuPd8vJD78vq5NX4WLzRK3Rk7aBxlgAUNaz7YvQhlzHouBm1MUsC80Y0G18Qmppqq7+9Qkk9fTHZcF6RzdnTriyRFuLqBwlssodO49kWQ+cIlNd3esBYC4BinSFpHWpIdMGksDBkBYt5S2YHNcYwDK9jWn0c8Tg3QyT3MMSY/3mUJdNwBUemOz0IS1UmKq9ixPEdHhnlSDZZa0ajSPURfGbN/StNcYQEjQpd6CzSNIz4D0YMuC9JFqPN3dNFv6kEc1/hT1EUp3d2dZ080qBpmQ/XVYM2tQ7TpMWpPeJgTpKsouBESObaLW964OKEviCJS9qjyDDCRjdIhBOu1TO569ROsEUw0OaSBHdSx4NkJKgYtLsI5rnce/T2aezqygSh/vvHQn1RRIRD0PPa4raRGfmePZ1xYAqgOpih/5nhc3nq5pwIKbgV/tBax5DkCK6u5OJHXZQ8CT17Lfp1Xa4UYo7bUwbvDjNGlJDt/CURmryBrHJfLGPRsx1d1zGsTAF1AqlhVK3T0ISefXBw/Kb9rq7ipYaDKjp20Lx9mJdcpkjC0KqGku4bi46u6CRozEVO1ZjDXhYo3EL+0IHpNbG+vO57i1dHd7HZP44imyWv3p7tZ7RkE802rLgvSRatThNuqklmYU0UOkvaOpCQtDC4NhF7oan/an5Lx8HBE9JSdUZvSry9AjwWlUQHcXMt18HaZqurusfjqmQq3T+L/VaAul8himAl2yygZUl6nYSR3Y87hjIjmmqK8gCrQ56e7u85N+hpBhV9NhwfNeA0oprd7jQlnSjznIzpp063PTEsELMkHdXQOw+F9A7xpg+VwA6dHdXTXJd3wZuOebwKYl1rmklYAhx7xEOC4XUzXbaULCyiU8yXdpSDSMI/HjCFxUPHOSZJIqtMyv3CHM9TFN036mzIaIJipUuPZMhDhLFlNKFOYa7hK1XOw+6TQB40DSub0l6ucKnykxVVobQntSYU3uTX0fADifl2fEtFLviLIjqU9HjUskpyH2ST9SSJY4WCWjAXRstWVB+kg1GqQDAvI3CmJ0ccFqODbvWvh+ymmYZ90YX5/TEro7OfoJMjXjvGjiRFaTDr4mPRGSTo5CkNYxiRy5DS1pUkKsSZeruwPJ5qHJfxeaQefohiUjLSRd4iDTa1gbVOYge45rjcOsPoQcDNf7fD9Dg7d4Y1yn0smQARwqtukkLXSe0gckSvp59kmnn5uSCF7Y89I06gBTx4uWZKWzTrlasA1uJseBTda44vtUGVPNliDptIxLXSIR7oRlWvocDiq2FvP6CckkGXtFWa23g0nBWZjrw//KJWQrUH4TnaajBIlf10hgwoLQ1BgfVnDIIelx1d0NPgnsSOoAfPll+M8UfC+JqZov3onTvtT8aLGEz7vLSytiUht4cQBmCfQowo4JOJ4Ha68YTaBjqy0L0keq6TpQ6CA/p5gBTMP4TUiGpNM1ujULFhdkOJCvVorzCciow9Jq3SIzeu9kbYdUCRkJmW6GAtMgXV2yxJM1UR9GDg37fBR8l4LWIKwXQFDXpdcxrSA9xzv37BqmR6+j96SIKgDxs3n9Cd+adE9ndiA2U8OzBZvjc5UzGrzQxEr8WlextZVb08NeP5u7gAo0UsAWlBq2HK+UHD6hBZvRsOd7Jd1x2TMmYRXlYgY/ThOSfDWJc6+IFurdLs3e96Iy29hnwrTvSXms9bnqEmNC5waHhdmP+Ocv56qdV1cKI7b8lLSBTGlNZnOoIUsmUbp7tM8U1jWHujsQL6B2lfRtWgI8cTVQJzR9ZfdBAAG4BMNwb+paLQCns9PB0d1bSO+mYxZc7ZDT067h54WQxKv0AaaZqbtHsCxIH8lWshXeR1PmSV5zbFkCR1yFMVTGrAGmHaiJbIXWUZKkdXd8rW/K14xen4LB9UlnNelqMsJi8Gwt3pSqXRtUtqExpAdwBW56rZ97X/xx6Hdp02r2i1xv+WJMdd0gY8kUrW7PYy5IT68nLzkWTT75RuYEr9Tv6zR71VzziuhRAwZZ0oIa3ws6zRp9B3oW9x4IrBoJdb9VdHfXGuVE0lMrseCSeg6nG0iPRkydfbEmnQrHqalJtwNdcMKTHN1d0b7vqc9RiS9ESPfJssYl7DqnkKNKbRE/vZYQ10dk9jkSeByTQFndv/O5dbadSithy+ZpyZVMis2S8AjS45TyuAQg7/sBcO+3gaX/Ia8rFxp0s0bSFpkEuCBdgqS3UoeJMS1gr9/pdYHhnjkNdkLXbAC1oZa1ER2NlgXpI9k48bjRpO4uXbCoVVvnZJIxybHoFNFI0P5JhQk1gw5TVT8d6jzYgu7uuaoKHRGDELqh0XpqnqqtZrMuaA0xIQNAqw7GpnmKY5BjuzNIt5ykYmrCcVZygA+WWU16ivRuJwU4V2TJRJ5K6pdgse8/PMsQTDPaWiftjavp7HPT6qUtdouQ16RHHVJkmljXh7JZFNKIo5qL7UOd92En3V3xuPx6IbSDIuOmRSM2XWshRyO25roqam5Jq9ov8sJxihAnT3XzBG2p6NtLPI1WwohSlWyVloKFSOgKdHcZkq6Ylu+i/1vXO61EIUtQ8nt2nrRgY10IYtLdc7rmEo5jr0f8XFeSr3+DdVwvvJ5eJ4Oe1tDd68OsFKwVQSldPwsNJ1NnEDnTOi/Fa6cQpMN07I19owp0bLVlQfpINlqXnqLwURom1KNIekZqKTlzYcym/jhp+OllWcOYUKcNAHMvAh66EICIIKR9bnTNZHT3PE93H1JyjfzrqQeUOfv0HIWEDC0hERgd8cdgwTJ1snMlq1TForunhaTTcWGNqxeIYB3gqElX7BCya0rrH9uAIrmmYdkJ9DOI8j33vtoActz/o1yyhlAbTmt77aRFWkiGgDh50IjjsgIEunvnZPa5rUIhXDWlDjEgqu6uOhEitOCquoP0tJX78z40YkBNuUy7ziX5aE0659wra0slCSBzMecTfY7LprW+Ftpt9p+QKIx/3uTvvRPYoejuPPU2RWaKJ929Pgw06ikmTsmRisTxezYNGKMmPYVAV0Z3j4Ok82s091mucpnE9wH253m0xVSeKOE/zxmkw9b4aQV71E42OvYSAAXrNfX+if1zzkmz5zoqZHT3YMuC9JFsXK90VRteM4x/8BjdnUf5NPf7mmWGc8GilqKIRhgTa8D6gbk/Ax7+OTDc4+g/3QIkvahaOI5zANj8sJVQ1aFH5MhE8PQ80DbOGie+SBlvNt2d1qOXrSO5ZhRxVi/gRo5UPR7FdhYsC3X9ytFFaziK4Bc62LhaLRw7wVabHXL9jq9rj02lpI4ZdUbSdM5kATWQSN1dCIbZ80G/S3/L1k+XgFulOXR3oZa14kN3T6mkRBTkonR32/lXIaLZBitI1/NAqZv9vgw13SE8a9ITPBuM7s7WAn4NUpcY89NriUp31yRCjKqYGIbsuWXjxG/JGGRMWK/hZr/xLXAj1Y/zz3pFIhwXI6B2aQuwIL3Hel3NniVlVQHAcG+qaubUNMoOpL4GbB+kleruLNnYNo6sMwDy1n6bao2+85mr9Iwq0LHVlgXpI9lYVtqmu4+GzJMhW7AYEjQQa4FXZUzp0oWkt1bdXWhLxtPLhraLdPe0a9Ipymm4s/KkXlwd+iy0qhGUycX3JR2H0TFdTqT1vkRIGDkyJD0vBuk0EE1L1KpNoyhWh8gSSFlMKy9B0sOyE+wgnZtjVsu6PNcNIg6VUqDQc2tOWiiWoDwtqLv3Cc9tlPsg1OC6vkt8hD6pCcm1Rg2gTt+wiGiny1bgUT2aHEAq47JAhUcoiyJCmXRcgyX53Gg9YCfhkrIT7BIT09UeLG7ZD31/iQbpxQ4uoatuDXIxOBp19rswlHpRyNaZnFdHvRVajDkFHyt9ymr0ncaSGD5IOhDt+7FrrmseNenkv1G+islfH+6z7O4Q9DPV3Ac33d3WCVFe9sR/XJ3bG51+QAt8S5r0yDc4xou1Z+etZGNaZWCApMQko7tHsixIH8nG091H0aQW63MkPZxbSSs3aFbROi+9QI5cSUEz+pG7zot39vlNcbgHHJCe+rkxurusJl0Qjkse2OrSmnSFgkOugLJdHlAmqkmnTrYzSCfXLB+zT22Q0XlcNqv2eOy7Daa2XtB7Umrw15TXzgi+prYuBO/ck8/IcU5VNCqlFfjDS8QqHWaB0OfaEfzwDJho/YTJsWDWwDoGcAmHtMR+As+Lr1MVaOc99utIHpS5xg1C9VIS/JQjlDT4GeLeF38MOi/KtGylUCbRBW3haKrtx04YUtxnJVB3p6fE6O7cc8wn4xOfO783rpwH/Hwm8PT1AHhE1+887V/qspaGiqi3nmUZQKqCjzbdXYak22tSlGEFcU/eH6kPCdT9aGwn2J/Jd2lQ3B2CnlPOJRzXG1skMeyYAEQdERqkK+oGEccY3b3BJ9YJAEiD9DTp7rrrWUivFd6b0bIgfSQbJxw3mujuIrpE1bttpLSV38Wm/jgQfq4etpXZTs25KY4EujsL0geUoFYs0w245wdMFK3AU5XabonVTLaJlHAFTmSDBek1ewyAo7unVZNOjoxqWvRgCaTkELLER9F2REiPe/JjmBrRAkXNOco8TyOOMseofkG7VEgvPbE1QUvCUeur6fz7onwXB0IJcHT3PrSqO4bgZDuDZdPknifF4/J0Z5m6e0oJGHZvBVaRFfzU4tGInUanRRny9YMi6apQ3qKsPjRm4BKWqaSK7q5pAFY+ToKg5XMB2DoIoenuzvaMlXCJxVDnyRBcGd2dF9JLNIzLWHKAIeklNo+0mHR3oXyI90eA2Po9QtlCRcKIUZRYtpkXpktlPy2aNZ+g0Wpu5k2hhXR3lrSg+22xg8UWaQXpgg6EhL2S0d3DWxakj2RjSHpfKFrXSDGh9sjVBzu9ACLKuTFaLQsO7UWslW0ycjocaqq9It29SUF6TtJ2CLUh5tAlQa0YGqvz7cMmst/TwDax4BCj7tO6bRHpUYFsUIerTIN0iqQXxSBd9W1jok2gyRTOQVZINXWare4eQHcPVZPOIemW08AjXWYEZ1ZaH0tre/lyoZTQVh2GL5IexTFn7Ax6bx1aCq1Xd3cg6aYh9qJPKTHkSmCm3frNhaS3S5F0FQlLm4ljBelFEUlXpe5ebHjTsA0zorgYXccNHkl3rwVJ9gr+b3OaxhIzGNpOXguxztnBM6eRI6wNdN7GPk1yDnwSq8olIAGx/VdK7Ca94d6ztVq8ecoSYzAlrIC+WHunIADoACIAhUi6Ezlm4/SmhuDa9x52K0VuvSgwurvaccOdG13H+D3bYq5ZAXRaOgkuDQzASgySH0cDM7jVlgXpI9noRjLKMk+CUyUL0i3EuhXfhdXm8e0oLMgrVxtg72l2qzu/DUzTNLuXa+o16eQoth2SqbvHH4Ne2g6+7VCxkyijw67fUkV3lymRC0GFSnV3hoQ56O4pBRAlL9GmlAMX6nS46O4hxmWfQVE9jgWgV2Mi6bS2F5LzUoiWeY3LEkHU6kPIwW77F43ubn0mL85Xsr+LxgVVzTQRXXM67r2pJYYEEauqm+6uIhiUGaP3M+fWRtL5hEyUZJLT3Mk2p6aFooSl9fd5FlBbejcwmaMedRxWtiLUpMvWgpgnDQcip2l2Ant4O3ktxHoj1LS7RCXVCcbaNddcYNtFS276GcsorS4ELEjn5ylflhHhPtgsNK4DhwQ0iofOO30cEUlPPtetIL0uCw5TSpQwP8DWS+B9p1bWpNMhZTXp1OdVvi/y99qV5Elvr3gzWhakj2ST9ElvxUMe1Zhzw/cOZkipySletxCxFgIEqz6nFq8eVuV5eWaZm6RJYLfroJQtHkkfVBL8uQJbPQ/ki2zjULWh2bRq9+akqraXBctwIOnWNaPXUb2aLDna6u4dAu08pwgdchpz9hteFNcQNaKWsygL9AW6e4x6R+F68AmZlOnuLoQSYrunaLRQcrRZAW1QzQCJY6IwloMCO9wbW4AsyEyv5MAw7ZOezrg23V2GUHL3NhFSTI6MiUOfYcV0d9da2MElp2M+c652jB5IejKmgf2zrvNIurgvhmn5KNQod061zlMdAMK6AZgSXYwUy1RMkzB5dINjYzC6ezzhOKaVYFjXS8/bPlyFTziEP0+hBVuKjBjDKZTGxukJVY4Vb0zyeR06l6zl1guqrN4Sujtdt3mE3xKlzlltU9PaF10tH4FRBzq22rIgfSQbhwSl1Qs2DbMz1+CEwfiekRQdaMGCRQV02ILFU21tB7DZNByht6fgiBJnpFmLmpviyaNHdgs2FXT3Do0L9ADm4BUUBelMgIuvmeQ6JuQUbNisNpwKPzmCdIp09w/XnX+ayOy6Zb5VHpfUs5zEtNBFT7p7iACSnjurSS92Jg5CWeKHR/Wkmh7poFhFJp7VCeSKAGwHCIjmmJvs3nJ1/+y72FTTmuoMTICJtHMJOpJyv3IXzd4hWJcWa0QXkHSbVeR8XxxjpT8e64eq7hCm9JkjayG/70X5LmyeGvIkqAq0TBB90xALSRfVvh0Id0UdAMLWZMMOjBmDkBemVfzYNkzTnj+Aa89m74uxBrUZ3HxhLYH7Yj3rYptMN5KeU3QfDOdcp+IglT4W8Kh27+jnMW0avQDk8qxsRRU7MI7JgSlKd08HSRe7FXkLx2UxerBlQfpIthJHLxpFmSeB6kI3iaLdIsp2PJp/bjbd3XvB4t/XvPPiFzVvJD3ta2bTIiU16fVhJq6nAh1pY4rGInpUUEQRZ44pL3KmWN2d/m2Z0d1FJ5vWFW8dqLr+NonZdHfeQbauI0yULGchrcBFRNLttkthaJB2wCC5L1xCMo66u3g93Krz6sXFZGwNd9IvjjNrl2lwNOJKP7rLpCNFz1AtyalHNoZIOoNlABhOke5OEThXTToRrEsrAWMLLrnbo2lcwlJFEGrT3cWadFX9lV1aLMUOFnTlY87TBpunXIKKE+bUFARd/N/meCS90gsYjVCMIbbnCy0NbRq6quSSa03Ol4G2sdY48SjiYcct80E634KtNsjuQ5SELUseGVwNPyu/7I3lj4pdGrjnuNoHGA11SDpDjilrwrrXpsHQ9fTo7nIBSLpftgJjoz5jrs6DFZbPaz0Pqel5SOnu8ZI8/63W8iD9iiuuwKxZs1Aul3H44Yfjqaee8nzvK6+8gjPPPBOzZs2Cpmm49NJLm3eirTCG+o2uzJO0TyWXZS+0UKCNOV60Do9bsIR62FaKMvHCcQ5RlaYJx8nqMAG061R5Pf4Y1Flod9ZxF53oUfwxAN4xlam7q6nbZq3QGN1drEmnSPfWgapSVNumu3PIMU12wEaU1VOArWtquJNcYUUh7XZQcgQuDiVR3rM5/b7xNo3YjeBr1YFYVGy71pdS98VrPKGDIPVbByqSv07P/MWAelNTd/dMYFqCdVpKCUzGCKvLkXQVa7KLiePqDqFGcMpFAebFGuO2PaTz1GMtUMFw8KxJB4Bhm77sKxzHUD2e7m4FbvVhph2RPClMjkVB7Z6iz+mxIQ2DK7fSC4CeE5B0Om49TvkQTeqUuuRIeozPdAlAAmT9UFaTTo6sP3fHREDLWa+lRe+mPo0j2caC9HSSA1HOTed9Xmtv1KzrEVU0MnhMchSeOV5EcRSBjq22lgbpN998M84//3z86Ec/wnPPPYf9998fJ510EjZu3Ch9/+DgIGbPno2f//znmDp1apPPtgXGL/ApiY6kYUILtprbEaf1m60QjbCzrO7errm6nfGrqfY0A0xgH0iQdFW9w4NMqu5OKZgAuvOEtj1QiU/fdokl0WDKWsTzinqKuunuHQLSo8IpcLMCRHV3GmhVGwb6E1wzp9n1oJxToOdYkoAKqClXd2fOvkfveT04YGJsjbqESsndlyi3nwU7kt7rQp/0lOqWiwaHUBZlzmz4z7RRLC65xFH3J3QSgUXV7Iyw5+WqKQVSpbt7qsqzca33pZKQMrnWVm0Ca0RTsn7Q5JJD3Z2WyzDhODXoYkGy7wmMjxhdCIJq0pMh6fbPOq/uDgBD20IJQhqy5FKX7T9S0CDpUmmLSHLMAo4NqYJZIDPDNDkmlzh/0KhibIkM3Beh5Iolnw1rbpS6BGZSnASVzcSBe/0YVrd+0HPPN9z7S65qzx+1SXMHku7R5aWVdHdd0idd6Kai8NTENdsao3saOVb6RlU802praZD+q1/9Cueeey4++clPYq+99sLVV1+N9vZ2/O53v5O+/9BDD8XFF1+MD37wgyiVSk0+2xZYyU3XHA2TmtVXwxTbURRpENa6mnSWZRWQdFs4rrOUBwBsG2wulZRR8oLak6SNpNN7x9ek6zrb9KeWyRu2JAgQ6D1o96B4UsGsgWrD+afRxmGbdXoCXMzJdrZQsq5Xrj6ItgLJ4qsMqqTq7gB7xiiCr9onsOnuHuyEEMGw6zOEMoT+WIJTNt1dEqRzdadpCQbJEEpB4TpGra+U7l4bxPh2Mp829zc3SDf4NUpCd0+vowA5uvqzW+Om2W6wiDo0KgLGs4qMOkpaI/G4brq76NznFTn3LsXrgk1316vxtFhsFgnXboxbC0oF4l4OJVjH+Wubc7HMtodC66WaBuWxTDui2FBTl+tuLdkuD2xTobs7hUtt9tvUDjLelv7wzBu2vzAkXaxJj0PdtxkxHki6cro7lzgtE6o+rxOi8j5Qn9dmB4olfLS8stldgwDOH+evh4xFk0LSQkyMWUE61wovQ9KDrWVBerVaxbPPPosTTzzRPhldx4knnoj58+crG6dSqaC3t1f4N2osYcuLVpldp8sFupwzb9Pdm35qHPVHVrs6gAmdZOPeHGFDU2H0vmpeNelNF47j0COAbfqT28iKvzVBgODqA+3Y0LpzZN4kpfO6qdkdjoCS/KiC7l5yIukc3XA8oycrDNINp0NofS/Lue+2VGaTMB6k47rKIZwt2MT3+X+GF909fr2jWJPOB/7kR+VCek6RIqH1WzJaqNTZBzCpRO5ps5F0sQOFt3BcWiUW8vrG3lRZEmKtL6fPAdshVyoc52jhSJH0ekIuP2OvNNyOulaNF7hI52nBfo4ntJN1L1lC1z4f3WyI939oeyj0VaTe8owX8v2ZP6KI7s7quLlSOr7Vm+o4TZindP/h2G/TrCm7OcJ9YPfWg+5O1/ko30UoO3Ah6T3KBPzY/a7xc73bes0eV+V6YSfbaE26o8tLC+nupsvntcEKPa2kBb9XUJFAGqQLpQ0jP55ptbUsSN+8eTMajQamTJkivD5lyhSsX79e2TgXXnghxowZw/7NnDlT2WenbnRRrA8jD5q1b+H5hDRXfQ4gpbu3IqvoCtIdKB6t94ySdVZ5XjknlZTR3ZsdpMv79k4skXm4JUEAzdq7OIN06z50WgHmlv5kddxykTPV6sPkWHLVpNtt61IJ0qkTxbfpAtjmO9EK5FSjrTSxJgTpstZvvjWi5CjQ3fnANgbDwRaxkqi7m43UhPTo9cjXJePGVI5m6vd8bWu+RNogAZhQIPe0ZUE6j0ha50QQbet9KdV7evVnT0uvxTA51WxNB3IFgr5aatFUnyPJnGJ1zC66e4cwxvaEzC7WFpWnu1uBi1bti9W1g3V64AN/ur7CxFQaHCbYS+mzoGnkPAUb3h4qoSetSeeeUxtJj32a1t87nlvuGqPax8ojotSGhxrX4OjudP5oGvt5SjsZb2uE+8A0Phoc3Z0Jx/XFE/ekwbOsXEYhI4axmyhrpNjJzj1XjVfaETimqyad+jRWkF6n6u7qxgxrbmDKfk41DklXGTAL7facJSb8Hj8K4plWW8uF49K2Cy64AD09PezfqlWrWn1K4Y0G6eDrpkZ+5omeYofOtZXRdbYw5BRlruMY27AlwnGo2PWezaeSSjKPQPPp7qbVc9WUC6FNKJLgTwXdvY1uaLTO09rYKA2+bpjoHYqPBLvEkgS6ex8KVlQxXE9Ax6TODGuhZJXhcAJTNEhPcs28xhUo0QB7xsYXyP1TzQihTnxemuQaQJelPN7rozwu/wxJ/XgkKiU5lnjWBI96MiG90B8ZclzqmLtbW8XtwexqwVZoJ043vbd5Mo/6K3VUEszdqGYHO7Cd7K4dyDFFMSBbiJRbG9utns0p092F4EfTyD9rXnVqyUtKgujudC1M+hzbCUtZYixejbErKC2Iz9yUNroGJdgreGX/YQcLkkPS/Z5rsSbdCtK455QmC5POH1cvekfJTVeZJLT81sY4Jqi7F2wEnbHfYpSosZIbK4FB1N0l3YZizBeXACSglBHDxhGQdKu0gyuXSCMo9WrFmmPq7q3zebUar3FCrgfPolG5fMp1IOyadBp4toJZMNqsZUH6xIkTkcvlsGHDBuH1DRs2KBWFK5VK6O7uFv6NGssVgBxx+uliORomNV0U2l0UPovuzrKKraD+kKOwgHNO9UQrSN/S7CCdzzwKbYZ6AdNsKpJedvZcBdg9HEeD9AROo93T2lmTbgvHdVnaAJsTIPYuJN1Bd5+oICEj7VfOH6uDnBq3ujnlQo4dgkHj8sQRTMJ4kJmcqm7T3SeGKBexW1u51WYJw0F8XxizhfS489Jz7Hq0wdLBSCmAtFkBcoprpBZs1lpQ4FWzAbZOdWoV9rnNRNOZbgaPpHfTID092jmrqdQ5mj0TIUqxFt6Q0FcBO5moJUfS2byl64eDiUNLgpLuR/Se5KTzNF45HRPm5JF0XWf7/KQiSSAlSTAIpQ5WwpoZV5Pu91wL87bm/v6Fuhrfyr4e3BrEXeNJbL9RvSbzTC73PKXstyj7HJuXDR6NTqruzt1LHyQ9KdrMEHtJTXradHdXxxpHlwaV4rFhzXRdD3vP1jjhuGpdHawtLVGia7ZRQwHpMNvejNayIL1YLOLggw/GAw88wF4zDAMPPPAAjjzyyFad1sgzSsmyNpJWKKJHNbsmnQYuIspHF6xqC7g/0pp0zqmmQYbq4CbIGl4bmGkIojPNQNJddZgAu4fjChbdXUFNuo0eifOD1wZIMo7LMXWInE3uIk7Tpr7495qhnh4ZdCL0RdBllQEVnQZCD3iAbb5jLLR1c59iujsTFuTF+KIlPqTCPhKRzChT3S3a1Ckc28yU+uOy6yFBz3gRvCjq7qzO3SEKSMV+av0Y1578+Yhqtm4GHyxbQfpwD/uuqpcoxrwwq4BhBSPd08mx0sf0BtJQzWa6GXQdBDhWEVkLk/SrZwwQU+7cl6zxtw5WUU+wX9q9knm6u91RIQ791NXikq1BVpBestagJHR3QavFgaQP90SiuxdRBxpV+xxpTboiJN0WfJQxhPoxScF+IzOhLCPvRtLpPI0mHGd9hGdNehwknRyFFmzlseTI1aQnRZtZPXRdhqTbvpVKX9olIOsQw6WsqM39laaj6eR6mNAkPq9W7ceYtgI7N1Um3Gtn20MAhTpt/Tby45lWW0vp7ueffz6uu+463HDDDXj11Vdx3nnnYWBgAJ/85CcBAGeffTYuuOAC9v5qtYoXXngBL7zwAqrVKtasWYMXXngBr732Wqu+QvpGNxJDTZuQZpit3u1csKyaYyt436x4swpjbNOXZBXFmvRmI+k+VLDhHmVZ5jDnwYL0XBFMIca6h915KuqWIHhm1DB5T1HUBlnZQTLEnhztgFJUyZ7cSdD6JE4TdWpdwk/UYTUbmNhBrqHKOWUjx066u0XFtUpNtgyodQpMV+KDQ8GNGia1k+/qd03tDgvywDYOImsL6ckDhjaQ800S6MjMpu5zCtdc0s9u05WARsxEAd3JxGYi6TY6Aq6tDoekp4Ros5aNtKQAkCoFp9LaSkojJnNriiWimWT9YIwYF6uIjFFsDEHTSDCfpOOITQHmkFGJwGGcLgR2kE4TY1ZCl7J5EiV0yTGn+9PdwwhViho59nOaUxQwuLtW8OhzP0PSN6lG0g1JCzbu53FWkB5lrWDrKa3r5oP0arxuGdJymTEzyLESLuESxkzZXKf6C3yQngK9u82VrKfAFFnLh2tqW7GGPbcSatBMStHi9uxKvxKwwml2uz0uoVvqYmywksXQqLdCPXqUWUuD9LPOOguXXHIJfvjDH+KAAw7ACy+8gHvvvZeJyb3xxhtYt24de//atWtx4IEH4sADD8S6detwySWX4MADD8Q555zTqq+QvlmLC6NkjYIo3e4Z6QxcyKbYblFPe4frGK41r6aSnBs56qw+R3SqJ6RESQsytsGbNTvbb5U6YLiH9VhtCt3dKUIDsHvYqVtB+mA19rm46jAdyuQ8RTxJHbfLieRRXwBTLUEdFU623efYgaQDmFymatwqM9U0kOO+G8C+X4f1jNUaJnoj9McNO64uE+MDMLWNCgsGI+k6H9hKBP3iKU1zgT/A1pwJheRaCjJzUfeFhENfLOq+zZKQ31tUB1IRIwwyqW4GFyyn16+cHJneQL4MtI8nPwvJAaXDElaRz1o4uUzXj+EEY1CUlyL24vqh1Ycwvj15xxEXe4VrPYpKH4p5S58jwn7sqsFmYllk/o+1gvTBagOD1XhrkKAS7ULSt4cKFul379Cs+5QrAvkiV5Ouhu5O4w2R7m4HthOtpHAadHdXLTQdH/Z9iLL2sf2l7g6wUOlFMU/aQFYiUKRZglfn1g/KiBlW1x2CJQNqvEggrcHuZXNdZecTOv3spB7V2SFrRa4+hI5i61pniiWM7fa9rA1gShdB0jcmWMecJm3Bxt2HsTky1rbB5l6L0WgtF4774he/iJUrV6JSqeDJJ5/E4Ycfzn43d+5c/OEPf2D/nzVrFkzTdP2bO3du80+8WVZyULJGAT2ELpK0DtQZhBWNIbZQqqZ+BZ4bFSHia9O4mnRGs26ycjLd4FkNGGDX8HBU0qbS3SXoUYfltJomsD3mAsvo7k5lcooG1wY4JD0JYk8DSg5dzZeZOvO0MnFIk2xOjOLovGa5AlO+nli02talSne3rh3N3DcG7bp+hU4hC0r5EgKqeg1gipWQ8GPJuD6DZ7NU+lG2+itHcextijiXfAPY+jmpSBzVjSlQTQFnTbqNnsV5bu22bg6WRMlep9IQIww+L3LUhdpwWzguLQE3tl7w4nz0Wih07mXjlp0MGYCr9SXzMwkyandpcDr3XMJSRekP1Typux3muFRswwQKqEM36/ZncseyOcie5bhlN4IAlQRJ10OUgTFmn7OHtcO3SorquZkF3LoGE1NKyZkXMjM85yllv9FOH1HU3a2PkCHpXH19lO9C56BAdx9Dy1YUqrtTqjWvO1Qe4z53lfRur1asHPAwMaVyhzDnRgUokSsCubwNTAGYboEVG3tT8BNgAjW3rsHEAhlrU19lVJTwttJaHqRnFmCsbmr01HAw9W4PurtWG2QLpWqnOfjcTOgwoPEOMKuH5Wtqm3tetiPKqc+2WWgRR3dP+/4Ljqmkvi1XH8I4q8Y6boDA6O6M4kkRGG5DU6AN4KJVM5VsK3CzAspEdHenky1cM0uNuxiMLkc1sgma7rplhrbaToFKmr1pAhoM6LRFn8Mxn1QKdghtIRtJ//pGBTt0keRCFKdBWg/KndcEK0jfpNARAWTUfY5GXO1H2UJPBqvREcq867twjJ8WtIoU6KpMDMh2slOju9N7y+pjbfoqGZf8qLrWs2GYcuE4636MtwS5kji3jFbM1kK3pgUTM02wFtoUYMk8rfSxIH1Db/iEJXH+ufc71gKtOogJHdZ+GvPcWes4XQMqlnAcY29wwnE+t55+RgectHzK7COvq2v5yY1TaGNJ4YlWjf6W/qryemhbOK5k/8IRpPcNh+8GwbpWNORB+tRusv5sjDJfWLmMaQfpDEnv4UqDQn+k53kDTrq7ndSb3G35niqDUkZ3d/g03HOclnBgkBmmaXfSob54vgxoZG+a3kHBCvU16W0653tw92GMPgxNIx18tmZouq9lQfpIN5rttRZLlQqMaZnptWBxzitdKJNQBeOcl2ly5wVAaCHFOb/bB2uoNVHYjtUY8709afZ3uKdp6u4Nw2Q9pWXoEd/3O+5mY7ct897QxivQBnD1BnYEsirQVVuUyJsWS9uhqe2TbqKABnQ0hLHsRMcAm8tqBWGc6v9iKcuEEK3fGgZJlLFAn9cKADC9g1zTDRHWBjuwlddxj81VIn9mGJPTiO1gmtb7RZljjCXhmYDpx3gr+GkF3b2ocQJclO3TqKJNI8HAkOISJpYIYyUFXRwy1staKVZqatdrw+SEoCTP9bi8CiSdlq04BOqK9lo4IQZq6TRbTEuCpFf6MaWbJAeizFPDdCJ0BfuzAULxtuZ/XP0Zxt7gW7CN3ZEch7aH2hfpd293lleVRFHJasNIJALI1iC+a4WmMabeOEvMs26Y2K6wDVtQWUYZFeQjdoNg30WGpBt1TOskz9z6CEG6zTqrAYbFvqA16RwjJkkfeX4eaALN2u7xbrMAVNK7ydFPQLYVAJBpmjB4n5eysjiwYpoFVqgM0um97mBJPA1867d8bYCV8ahMlrwZLQvSR7qVaNsdMtmbTZWJYzaS7hTDsWsqW4Gk24J2dEyNLKZc8mBse5HVuW1rgQMsqKmyIL0XeavgM22hDSEIy7vRI9SGmNMYN0BgQTqluxfdQYgKbQDKmtANB82RChsV7JrJuPVpLHBxImEAm/djrHrowWpDmQYD2XhlKBYVxhvg2gmqRQza+SRXXny2af3jNp8kF3Hu+XNvJzWiFmV+Rnt0hNIVyBXE6zHGCtI39qoV0mPoMq8kXLRpxCz4iYE45Z21vhzjZ3wLynJYba/JfZfOqQDI2rRDmZxLFDQ21LiUSmpIkPThXpYIUT5ugHAcFdFMFDy7kHSHiKbAKkqesLTRRb5eui+WeJRhAu2aI5EEcPvpACYmLMtgz5fO1aTTIJ1D0v2CdPq4d7jK7yzhuFo/Y4dtSMKKsMbJ850eAKFDDx1HfeJU1iqQzCW9PoRxEZPezB+p8TXpdiJ1Byuwi3K9GNosE4Cs9KK7jTCoeoYSzHNuGrD2YoL+Qi8HEKmnd5ddwJQ1B+rDmNxZUD5ukJlevjhgl4LRIF3h+tlwBunFTpIYEO4DTQw2D6gbjZYF6SPdLIevy9oMB6qNlvRajGL0AXUtWMzxGEhloQwypsCpcefFLxy1QeRgMJSqmQIfTCWcp5dxSDptuZQ2cmYKNenurDxqg4kV8JlwnJPuzjumCoSxhBZKgCsZ0GYOo92iI8edh3QTlNPdyXjtWhWFnNq+1kKdmV6wUSzuGaO1rJsUzmPD4AQh822c+j8Zt1OvsCSX13cVEDhNt6+ZdV+mWeJzUam3gMRBZh0lyLkM1RroU7h+MvVpFqR3Cr2RaZAe5bs0XN+FzlubbjqhFcJx1hpF6cHIl0lyxVo/p5RokJ5O3X9RSr3txbQxZG1al0JyoOzDkOnKJQ/SGWvCowUb6kOY2GEFdgnLcnQY0Ouc08zR3Sdba0WkZ45/jjnxSJ4FwNDD2Ei6pCadBem9yGvk937tXJlGjuY4VwmTIEmix+704AzSefE4tX4PZQfK5ymXWI+YLDEMII86cpThUewka701Z6a2WSy0SPOFHG1tiS6gbSz5ebgXU617sL4nuRAjwAXpxU7WJ50g6dFZI2HHddWkcz4UFaptJpLu6mxAn03ALvuzwAqlNfoMEHMkxrgyJcYyy5B0X8uC9JFuXBaWCkElWcSaYe4+6U66+wAmd1GEqfk1lbZj4TgvwNpIm98rnQlf8WqqdGMZ3o5pY8j1WpfyvfdE0vkNPyGyQ539oqsmnQrHcS3YEgXpEtYEIJZdxKAj8+aJhAFsfmm1IeVJFlJn5mAIAGJNegpIOtEskH1XMm6uNsAlueTjighcB1jrAisIncxQmmgBQwF15JiIlUMcqmGvnyrXHLu1lUQ4rtrPgp/1MVgBLiSdZ5q0IEhntGHTUdtrOV6TLDGgnqGa0q4dLEjnheM4p5utjduHlI1JxvUX0bTbHCbvdMFaKbI1yn6mJ5cNNk5ccycsObq7aWCqNbWi0t2ZYroQpNuMuYldakqjcry6+5iZ1m9NTC6Sz93SX/Fsr8gCFQ8knZTfJQ/c7JafcrV7vvZfVZDOAl9NNk9pYn0o8l5gmCZHVYY9V6wjfdY3RhD+ou9r4xkxHBAxZYzKIN2UqorzNekqASI6bNl0JEu4pMkUK/m8KaaIYhyza+UlvoK1N46jIm4q90WqA0HXB5q45tbtKVQbIEPSfS0L0ke6cRsJXcRU0/pUm63e7UN372r+A2o6s3t0wcqXmBI3acPW/F7pdssTOZI+lW5gvWodUac1TP+eqwRJTxb82Ui6Q92dmx8TLPRo22A1dm9rUTClnQsG3fMw7oZtmCZBHGCdo0RsT6ixVxRUCbRzSXacTzYpVXfnx/WiuLJx5d+1YXidO7kvEy2tgGhUSgf9vyAi6bwOhso1R053t64FV7sZZc0m66eJXMOJQtjX2F6jmojKOLt2OByvDnMQbQXCTFGZSKaPv1Q4brjXXhsVJzC921GSOVtGBZpG5kDcVkIN00QODeSc2hLceDRIT/IcN3iRN8peKXaAlipMo8hoRB0Il+4MIKxBtnBcMrq7xtekd0xk403IDSGvazBMbyTQte87nydOOyKJb2XXcXNrgWMc1XXJLgRXiqRH7xDQME10aZQx02YztUp2fT0V/gqNztOA0eQZMdZzXB/CtE6ydkQJ/N1jkGMRdWi07r3YAZQsX6o2gMkdeTaOKqP3vuRMYOs6uw+TrW4yKhHrIHPT3d37LdVr6avUMRRB4NTPPBNjnPggBepUM6/ebJYF6SPdBEpWOrV3qo0ipWUXYm0HR0kRzFjn5aS70/PhRDQEx6IFDrAdpHcD5bHk5+EehhalzaIwDP+eq3E2fNcYrI7b2T6MbiAmxhUNaBrZZLYNxhPZEZ1IN+orBunxrqtpwlbWdY4juWaqeqWbfFAqQe8FNoJKurvJZeUlATZ/Tb0orkJNugSBo+JzG/uGw6M0pokOnv6fL1qfmS57h5yeaSPpDhG8aW3R6/2oWrNOEz8OcT5UbOG43uF60wQumdaIB5KuVXrZHhVFUCrITGcCs8ixjBoV7EATIX0VpcKahEbsXeubqw8z8aMk5TJSIUZdZwEXbfWW5Dk2TQ7VouwVbt+bzCXGwmo2CEwlno0mIOlqhONyfE06tzfmKtsZVd2LZcbo7iwp7Cgfqdq+VZK6XNYHnBeOA7g1SD2SbgeH3uruhO4eTWXfMIFOWtZCfVCAfZd8zU44hPVH6b20tSW4IB0EndetwD92NwCnaDEgIukAppajJ6TCjuuiuwPsPkywukEkKVuJaq5SDyFIJ9ekzRxmrRJVXRN3G2a6V9hBeoakh7MsSB/pxom70M1IpQOUhrGadC86c30IkzuaL6LhT/2xkyGt6JVONzCR7s4j6VbdZcpBuimI0HjVtyUVjiPHkheSDtrqLVnZgWlKShsAB909Gc2x4VQ7z/FOkn3NxneoDZhFursH1VRByYDTTFk7F37cWnAbQ8Mw7Ro5/txLoshbrREeoSSf6RAiBITANg2ngJaHaKAQToeFnpDvNaUUPfghrADu2kn6pI9tKzRd4NKb7m7Xh6uo7fUat8Aj6VxQOLFA1KsbhqlWDMr0qkm3E2GJmTiGae9HgFSsk7Zw3NwfX/SwwSex+MSYde/GW8rj1bqB3qFwmg2m6fXM8WtQwtIoWU16uduuZR7azpgU67bL5xxjbrkCBrd2hBK6u1dNOoekq0JTGc1aqiPjLlHbGlY4zjDRCe55oyYJssI+6yxwMzgkPZdn61u+1seuT1wwwm63Z/19rkRYAPkie7YmFck12KywFZ7dilUSDBdo8tnuBqG6XaT3eXmUeALsvmoK/CD3uORotz10I+mTMiQ9lGVB+kg3rp6JCmtsGOE16Yzu7qXuDmBKu03hS7utGDsvJnzkTbXlxV1akfHMewXpTUrQiO1c5Eg6a8GWINutw0DBpMkA69rrOTvIrQ0oEagrSwNZG11VQXdnDlKuZAupAaKIm+IaYk/KOP2eVRu9VzmPRXaCPDkQ1PpNaAkjCajzdfszwm7gQs2tB6o3uVu9U+Cq3XQosVNWQBTBOtPkArdckTiygPBddF3jkljNCdLt1poO573spp6rDNLtBCZXk67nGBKU4xLY63rUlQOJ64e81ndSUk0LgVJftktyADaXxlnOfaVuxBaNJc+HhL1i3cNSYwBj2kjiPGwSS1yDZOtrcno3U6X3QNJFvRb5vWeBipO5xSdrYwjnycbRYUjKVPjARHVNOtX/kezZ9Oc4wnGmiU5NgqTzQXrEIIuuHwKSDgh+TlLGIBMsk2klUKp+boiVqajq0W13rJHcB2uPG2u1bKzWDaXipf7nRY7SJA6XwI7T3cF/XAd7RUZ3b4F49Gi0LEgf6cbVM9l1ySM7SLeRUoczny+TejiQzL2mkfc2S6CNIekyFE+gu7euvRGrZ+NFVSq287t9sKasbkhmDdPkKFuymvQhGx2JHTw7kUIJXZsLMpO072mXUsLdrQDjIhtCUoN35Pkxa0MssaEqSDdNj7YqfLLJGrOvUlfc+s2/hIBSXL3mR4MPbD0EpxgiGzpggI0UetTHplFi0zAcugc0SWONWzYG0V2mgnVhaaEcQunhVAGwdQ6apJ1hI2FyujsqvEKzehEiW93dKUJkr4+qmEZUNdu/1ldFkg/y9ZYbp2wOo8PqQhHnXtPv0uEs8wKkz0f4xBiHWAawebb7tGT0M7pn52EAVSuBXR4jIOlBgZ3dEtajJt2oY0oHSY4kSeAJCUxAQnfvt0uBFD2zdiedAB2ZiMJxDcNEJ9OesCnpfL/xqBpJ9FxLjBFjfRaX5EvKxKFrVCcL0nkWABmnkEKPbncrVj5xTu5DyRxGpyVe2iwAiK6dglArNc5XYMlGRbGFXXbgZK/Ya/YUrgVbs5gFo9GyIH2kG68UPEroIXZ9jsPR5Grg8g07u9usTJpbzMJN/SF0d/Wq2GHPTehLysSRetBdzrN2YWkmaUxPdXeuvs26Pj1D8RwvF8VTcCxs2nTS+yDWT3tsTqwWMT7Sw8oD8k4n23aSVAvHiaJ4kvZHZgPdhQaKOT2FcWVZebdj7i3kxNPdA6jpIec6oeF7I4WCgrPSemk+UJGsJ1W+vVN4B1nKVuA+E+CC9CYlORkqQ+nuEsXeySnQ3e0EJleTDkjF49QF6eQoVXdnug9Diuju1t/6rB8TEiDSnu2QAIGKHVVYUViDPJJtY9sKrJd5nAQlvQ+0BS05ZyeS7l8K5hIqdSLpAKZaHSU29cWnIgvlVdDs+ycIx6n1eUym/0P3IBn7zaa7h00OmCY8kHSuRKAr2rPOwJsG1xoNEJN8CYEoeu86ZfOSK8thz60yAT9rOLZu8/fB9mlUMymCz8tZ4smtMUJsoTaB7a1fwrFKrDWNlLXF0x36b7AsSB/pVnQj6SNdOI5mM1016fzP1X5Wk9Is8Ti6YHX4BQjVvkB16jSMXrMcC9K7BRqYBnCOaHoK72LbIQl6ZDleSephDT6g4lXXAQ5JH2BIcBK6u7x+2n6mkiPpplwsBuDqtAebT3cHaf2mWgVcCCo8Ka7B6u7yz7CTJ5EDW6+a25TFKr0pv/HrtEVBLtkaNQAYBkuGNKsNG1N3Z46XM1i2y3JSCdIbDpo95/DtwNBUNWujS79E0icdtSEl64c0EQCI60eCPcne9/yC9N7IdalCqYdHTbquayyZFCcwYcgoLbHIl0l9Md0bh4Lp7rY/4vj+es5WibfKUqoNA9tjBgwCA6bobi3JC8dtHVBT5mfX2wew36gmSsiEXsM0beE4AY2OX5NO1w8WpDO6u7pkG6uFls11vle6auTYMAGYHj6vm4XYLN/Spv/77CcVNS0IhXFdwnFuunsxr7O1IROP87YsSB/pxokFTe2iE7p5ddxxjCaiGd1duoEP2nUwTWIGUNX5dooEeiAKtuBW8wQ+6DDSmnSjDtQGm6LwLtZhyjd83vGKg9AKCDe/mfH/r/K90uM7wH6tR/jAbUtMbQSxht8LCVNPd/dMpuTydl1/tZ9z7tVlyP3p7oPBwnGC0rQ8CI2KyIq91yX3umIH/iqRdNEx551Z3gGKRiM2BbaC5PrAFNgZTQvSaUBgOINlHglTr+5O121b3V1Gdydzca2itdFV6yvpky4Kx8UPKsoa1ebwXguT1HbbSss+6GKVn6fhS0zk+hQi4yOJgCW9D93gup4ANt19eHtgCz7GimDJJfe5FhsD7HkKW2LjNM/2lNxaML69yMr8VDy3jEJO55Cg7m7PU7oPDNcMDFaD66ENvgWbrCadawm8PoJuCACUDEeQrjDJ1/BF0u1xaEJKHZJuil1eJDXp/HMcd72Ic16Af590ge6uuibdcDxzXJAOIHKJzX+jZUH6SDdexbZYg24JXjSTih3V3PU5HvXATe6VzujufugqF9iQDS29+m/e6OaS4+nuxQ5AIxR3soH50/qUnIdA3+Y3GluZH4aRqB7WMDycGX6cmu00xc06e47Di5x1lqAn0EYwDFPe/oYfU2hbp24TlNaZAR4Bszq6u5SqzjEtbLTIrZ5r+AYMPEU8Yn2sJzpvOQW1AUzuJMJYA9VGbAEu17hmcL/6qI6nZ//pQhvT9EC1X3kJReB5MdqwA2GT1JRujKBmH2QuurszOTDcqzyB6a+azSHpKoUn+fVWGGcwkQ4I/S4dzvpQ/meub3FYR900TTliya2vAGz0MMY1MljQZSWGaOKa0t2HtmOHseQ6ebXgcyPpHsm0hAGDoBMiBQD6kM/pSsv8XEi6B+OjvZhDKW+VPoWYQ6SMx084rpfR3cNrbZBjkTFiHMJxgqZFzKQXVXdnQbq7Jp0XLVNXk+7RShHg6O6DyjUJgs/Ljz1qJ7BVC8fZz5wH3b0+DNSrqZSgvdksC9JHuhXaWKCWrw9yvSlHcpBOjiVnX1JAKlTTrPocunC0+9V7VvrRXsyjrRBfqCeOGbIgXdOUKp+GMU9BMv7n+jBrwxYrsBVqGT2C9CrvmCaoSWesCfkczOkaa48WZx6KdFUnkm7XBKrua+0ZHAJiEqIjPgLnNW5ZlpXnrikNHhuGu4WauyWMh3AcCxjC18f60t0BdGhVJsClTiDHq9aXr6+P+l08dDM4TQ+SYIrWVimpMYaUCx2xEW0a6FUbhrrSDrY2OmvS7YCBUZ63K6K7G37Bj4QNpqIm3bl+cHT3REg6S077aCfwjnqsjgqShF2jCjRqic6dsig6TRqku5H0iZ0l5Hxa8Llq0r38kYQBg+GZtJAzC1Ssyb7aCfR71oegaVqkcYlwnKxPup1woAyGLQNVVOvBe5pbANItHBfEiggyej06pbpDXE16p1rfk2jTWPdAz5O2b9SEZJva/TjI7HVMFqTbrIikjCCn0fvA6O50nSlycyklMdc3m2VB+kg3TRMQptGg8M5qjwzZpmgjbs1+QOnC4VufUyU0HOoAq6JDBRl1RoQgHeCCdPXiSNLzcLYEosY7qUKtc1y6u4djKqDPSfuxezjADqQnCRomZNC9kLDqIMa0FViJYtje36HH9XTuBzCxS60CeBh190JOx9h24qQ4UV47YJA5DTKxtQjos8xBdqDPKvoh80Yccz/Kb19kVoCnsB7/uZW+ptPdmcPnaqFkI1TFvB65fV6QkWFNd006R3en4mFeaGr0MR00YmkLtkFM6iSv9w7H66AgtGBzrYX2+jEhgUggQ9N86e59kZNJoh6DBJ0HhJaMcRgfjL5sOgO7seQ4tB05XcMUaw2X1aXb5XcSurvQUiyZPyIkTguy4JDs7SrFw2jbt6JmMYOEZJI1Z2vke0fZs8O0YBvXXkAhRza1MHOGMSydXRpYkq+H+TgD1Qb6hqNrA9D50qFL5nrZjaSrbDnGgAdn2Ruvs6M4ORBkvj4vL6raZSdc6gpABFaG4Uzo5vL2szHcY8cAIzieabVlQfpoMIkI0YgO0q2No0BpwDKKTW1QuVhFmPMCglo1kQ2k2QrvhmlCg2GjRcwZkSDpvWkKx3m0YNN1ru/qQGKn0a6R8qJqJ++THqanN4BEySLPGn5ASDjkuL7WKoIqw+ADOcc15KjnTDBIKc3ev4QA4NAixzVlToO0BZtb3X1TXyWU00DomZLzcqDPkxilNfn6SVtbyftP86rZ0evry7KuBIDgWDVf3Z06Xly/ckCgnQNI3EbJaaaVbNOolDUb105gTuqy0VQVKJWrv7CMRmzU0F00UbRoxHHGJW3eJOVFgLB+TExAk3WLOPEBNde3mKN7hylVML20JfJFQLeQRK4lYyy6O6UvwwtJ7wEATBvrXQrmWabB/xwjMeg+V8iZBQ4AYJJCNLVhcPs1IEfSG1WgUY+0ZxuGiS5funs/NE2L1HGoQenudadwnO3jtBfz6LJaVsa5D+4OPhLRu2EbSVdVaknWbOrvOv0A6vMOcXT35q7ZUnV3ju4+oaOInK7BNNVQ8T07KgAO8cHw8+e/1bIgfTQY3yudTuoU0dSk5lufI+kZ2qyadFefdA96KgBbWbyJKBWrGQQk9Z49ialgYcwwPNq5ANI2bHECThJgUucuGEmP2+fbNL30BxQi6YZPTSnXqgmwW2apoCeLqI0Hks5RolVsvHZQKishsJNvgF2H6mSiuEpOPOjuEywKK9EKCD73hmnKg2Xhc+2AWQ2KRY4dATXpUeu0BYTS695W+lkpQ7PV3Usu4Tg7iQxAOdtL6NkMzb4GHJLOo6lrFVDe6X3ypRED0OrDnMMfN2EZTHdPUrZiK177oGmcwOFQLZxmQ8P00IHg/8+hh5tjiowCQAeluzuR9OHtAODLMiMBg+lG9QDp94/djpNPYHrUvcM0WdJCxRokJHkAedtUAKgPcUKsYZB0LgHjgaQD9nUPg4QyJN0zSCfrh13WFyfp5bO/CDXpagGihl+XBom2RLNLPOXtWu3kta5r7NxU+OMsyelM6ALifWhyDDAaLQvSR4PxipoRFVhbYYLKKeAZIPH1fM1QUTdZVtGfagtwirRNzHiyGjC9YIuQsQ3M7ge7ub+KSj0dQTv/GmtVLYF4pNBJ57WVULvLeUanixOIkI1TFgxy99o0E9WV+mfQaZBOnBKVQl+G13cDhM1XZQ2cjS76IemWI+ohWGc4E2UeaHxO11jwE2atE2jnXtej0p+Y0sobSzgEOOb0e4Rt7ySyFbzurS1wuW2wpoSiGHxe5Ggj6Q4nuzYINGpsj1KVTCQBA4eC0roRDhkDoDSJ6VuTni8BsM4hoXhcw/Bbb226exLhODsx5o9qtRfz6CoRFDPM8+FZgw1I52kcJJ3Rlyndnc41Hkk3DExjgmPuBI1hmCiijhwoE8NLI8cCQGIr9Zv2NZbR3Y0aUK8kbtvnHNOuhS6QtnLU+IC9NhSJmSa0YPMJ0tmzHmaNtuZhoeEo6eM0Lchn0oRL9GQbXQaD2w2S8x6sNjCgQETU5OnuXmK4HJNrc3+1KT4v61cuSwRycQXxgxQmsL2E4/hxU0iWvBktC9JHgwk00JFPdzdNE2V+weL7YHNUXLooDNcM9ClSW/Yz14LlgSgAUIpAhj03oQaMXjOOCjauvcColapUSd3n4VGTDohIOtvw4zlenuruLBEwAE3TkqnIe6HNbOM2kzvZpolSiOsFQGmvdMPwqOsGhBo4lfPYvzuCdU1NA6gPeyYHqPaCVGmaq48FEKmWO1THgOpA5DZTvmM6qZUeST+hTjtEACBS6B3fhXOsxlntnAASqKdtrM7Qq185IFAYlVFJeZZRSY7IADblWUUbNsME8qgjr9H+b9yzrXFofm0guaaFZwtHt3Bcz1AtlEgXbzQYkCpeO5LTkyI8HyK92xtJT0LvZucODyTdNIBqn++9F4QYAYdgrLvvd3wkHf6dHgCg2s90QlTR3T3LrTQtdocRk69JL0qC9GofYBiR6O6sDLJB/RyncBwpXUjShs1Nd+dr0m0V+Y5SHu1URFRRUFry1KaxGXUTuYRt73AzfF4HMCUDK2A6ui2pSR4Bkpp0QAzSu+xnrlntjkebZUH6aDAWQNriYSMZSSeKtV6iVjbK11bM2Zn7JtSkuPrFCtQfMUCIQg1TdW7SGjBG6+uBpmm2inFKlHdfQTKOtpWE7u6fdbYDTAA2zTNi3S2jZsv6TfM/V5M52abp0bIOcAXpqpH0QEp0zXaQtw5UXO3Qopr9/ARfUy9lfrfT4FHXbpqRarkN06Pmlv8/L46lYL1xJS08HBEA3HcJU7tpyq8xICRsc7qGsW2k9rcZlHdKGy46KYy5gn2eCtooycbtlN3bsojA+aGpUc3kEUpAEkDbz3bScpm2EDTZMW0F5PR4rCKGRkuRdHoNSZAehVVEOipIElT8GBybR9aSMfDcaU067a1N73mhbK+3Q9t9O58I55kvE/Eqdp4Sdfe+4VgBg6ATws9TPcc9H31MbFBVyY3n/gM4EuvhfRrijzgEIp0/1wYi0t0hlvS5+qQnL5dxdw+R16QD0eZ6kDVMj7pv/v+1QZQLts/bDMq73aJP4is4RFX5gDmpNQyisVSStj3kGA3ddtKiZyj9RPNotCxIHw3GtUpQ7QClYULm2kcYDFCrdBp8Xk4BHW8kPWn7rzjnZiPp3fYvuOwvYGeZ41DBgsxVh+mTEU6KcAequ1eJgxC3zZSb5sXda13n2ij1c/2B4zkFJU8nm6vTNk0OSVfhFPjQ3Qv2MzbOGtMwk6vK2+1+ZNeUc0Sr/Z50d391d+u8jTrQqHLIVvB9aRimvOYW4MTWOOE4hXV3vjRiC6FkrIAQ67anOB8/RtVZQtGE9ZPShk2r1EaGag/z4qZqzonQqunaKB8T8K9Ljj4mF/xAs8uPqPFBegL6stgn3Zlss9dbXdfY+hEVgWXzVDanOAAAgL0Whrl3Rh1lqn7vowNB52jdMCM74uzcnTXpgFCX7lfq0BCCZw8hRq4spdYwYzFTPOnugJAMsJF0NTohnrXQ/HlwHVnCjCuyV7jAPF8mLcYAgX0Qlu7uW9Ln1LSI8RxTplY7ZAiuyLxRqYkk3gePpLnD522GeJxhADk0UISF2vuIqqqsDxe0awDP+1DK51gnmEw8Tm5ZkD4aTBA3IQtY73AdQ9V06pKTGmlHEW3BaoZwBF3Aw9Sks6xzs+juXn1JObo7gFR7pRPUwrQdL78ayQ5b1C1qfXzD4MXHPJy7mqgSHjUIcWfUg+vE4tWUetStAvb1Mg2gXlHaMssw/ejudh/nQk7HOI92aNHHdCLH3uN60t391Hf5nyv9rFd6WCplGOotq7tThBYAXiJ4YtLP/i5h6e5BCQeL8dNE8TiChHHJQSltuJdjK6irSZci6Q62wg4+Ct9RTWiNli+LJVuAQCNOSncveXaHEPfKCTFp47ZCus8zZ9WlRtG8KRrcefjoYhTzOsa00TUo3rm3mw4kHbDr0oe2YwdLr2V977CrBZ/pCxp4lKXEQnF91kbmw/Vx7KYqagm1JMR52uZ+A+vIMsQxGoLvQdGs2KUevD/CB3aVvkjrmmdbN3pPG1WgNmwDUQmQdOle4BC4jJSQCjFum2fZiigg28xe6cK+yJ8LNe5eTlJYH94wTXuv0HR5LTxlmWXicb6WBemjwThUprucR1uB1NKMVMq7IGrlGaRb9DqFasthzgvwQCDpNa4Pk3YlnerqxsKdGzz6kjrqtcaoc0Rl5+CpFAsIjml3Wx75mPRLsQ+01/ywkPSYiL2vqqkwjh2kD8QQkTGFFmwe1wsAaoMY36ku8WP6UqIdJQMe7dCiWsPpAPlRXD3aLpFEmSlPnug528HhWyKF7MHbEcTe4Vq79VXqGKwmqwlkSsJSkSIx6ceCn5Dfxbu+Xuy53Mxe6YStQGnDbSJtuGyj2hQJ2zKgRuBSRNIlCcxqH2A0lArHCTWmUoRSEd3d9CkN42iyAGKLx4UKXIw6UB/mWEXB34W2VzKhSTpbOBMMVNU65rkbjtakgICk+7Xga5h+SLoYMCSpyzWEDhOOkhuuddm49mLs0gXXmAbfwq/kfoPQkcWeP0F0fspcMPluCtQ4JHTKmPCBbsOEnEJf7AITYhzusZk4MdTdGVOLIemS8phGlQj40edWiTaAX5mg7TcBYEyKZvm87LnXdPccEXqlq61Jt8X7OsUkp0t8MHwy/r/RsiB9NBiX7dI0TXmLG9UmCqh4IaVkwVK5MASfl4kSarbKq1RMDEC1z6ZZD1Zdmfk0zFNNtYlIukC9BCQBtJ0RTiLqJiZxPHp8W/NjfEzhM+qDeLc3sjenTk5EJurGKdJVHY5qLg/kyPnzYnsqAiqhB7wL0ba+G2MjWNcw4bi0TXWg+n+13x7T4RAaJqFM24JcXkhxPyfyFgZJ51sregS21r2mSc6kCIoLSZdqXPQTgaUoNemGKW8Tyf+f0t0TqH5HNZOvDS85gxC7PnxcewHFnDqBS6E9pQxJB4BKny+aGtVM04chAwgod9Ig3buFo7OtYTwEzu5CIEkmOdgrrA1ZiGRSyVJuNgsdbqaBI1EY+9xp0OWsSQcEJD2na8yXcCawhQSejwo9gES90glFPCC5Vu0TSheSBmq+3Vj486gNCmUHvUP+Cco2i7lgOgMsQNrnuq9SD0xwm3zgxidbdF1AuaexJF8ltkhim6w/Nz/Xh3vthIwiJN32aZzPsejTJBFSjGpkL+GS+a7n1E5gT/JIrMcx0+Rbk4ZNjI3MeKbVlgXpo8E82l6MZCTdWziutTXpIvWHWzzyJVInZZ3beEs52VRQyxvGTCFI57O/YpDO6i5TuPe8Y2pqOSIIxZsD2YkrrickcQLmx0QmdhOP7i7t6S0ZJ25W3TeDzr/GOUkqgnTdqKGgWSilSyFfjqQn1VcwTBM5NFDSJPVtgFQsyqliS3qAD7v/RvIZUWjTQg2lz2dqmsYFIkmvBznKBbm4Z7gW7bsIdHfnnHIg9CoTP0EmUBidSGHZRtf4a6xijzIFlhE3br4E5CxkqNLri6ZGNTH48UfSk7QSDSXU6WQVxVhv86jbiCs/TwV9jr5IFGAqCmU41wHAFfxOirkGMW2RACQdsBPY67aLei0Gv+Z40tBFxkucUg3fRKFjHFV+j6CJEiAcV8rbomVBQqw0yDV4ZXdqnD/aWcqjoxiO2Wl4ARGA0Ct9fEcRxZwO04weuNlaNJI1Wc9xTKRexTXYPKPOuR+LzzHdG5vj88KblQWIwokKWyIL+7xnkC623GuGePRotCxIHw2mMNvbDDN4JCggCGtmPYqwYOWKIl0TEDbSfE7HuPbmoVQNw6teywtJVy8cJ9S3+WblxZZiUR2vBq9o7HRmHEj6hJhIYcMk6qJhBbgmxdw4KTsDgIeT5EYytg1GVzl2fazBPS8+NemAusx9I7C+zb6m5UIOnZZDyM8P0/UMOhJB3FpHaxPD0KZNo8EhBt4iVkC0+nDfMV10d+565MuAZvUs5mj2Yevrpeg8ILCqgOYG6aQkxwtJp8rJzjZKKSLpgJAc8ENTI4/pV2MKCMk3ISEVgFA6zfBroeWsZY2JdAnzCfBFtqIksBjd3TlH+TEc63hURpRhkLZdrN8y3Q8BAUkHgGkepWBirbhX5weqbh9/3orCcf6I/URFvdKFFn4BSDoQfj/toHR35/UChPp6AIzyHnTNRB/Hi4nTkyjJ17Dmi7SDD+BQFldXakmS9V5dXqxzqA8BhiH0Sk/bTD+RXkAopaXnVW0Y2J6wpadId/culwCymvQgy4L00WAlsQ5xaoKanWaYYXq0OeP/79gUm9WCzbP1FyBSVBE/CI1qpmnCMMG1YJOouzsUjDf2VRKLzjjNl3oJSJD0eAE0acFGnRn/ADNuqzeTr9XzHYdqI8RDUIQMum+QPsSSPoaJxO1GilaQbmh5IF90/FL8bnHr+p0mMGRkitcu0T+3Y97wa78HCIJrYznadJAjVTC5++al4OzoBZ0USbfrHyUBgKYJ49LE6qb+SiAVW6S7e6lEU7p7M5WCeSTdgYSVRIXmKQpLsgwewXcicA6Fdy80NapFUc0uF3LoLlttlfqjIn/cM+VHd+e6Q0QtWxEYZDpXgkONF6a1HOb+EJoNZUZ3lz3HDkZUAqp+J61jBjz2xu0AvFt3+dLdHb7VlAh0f6cJyRBPFXmR4quU7h6ApAP8fuo/bju95tIg3dG5ImTSU/RxnEi6qL1jgxHRE1JtfgkpLqkXNzEfOK6XRgwA1IeaKhznWzoFCPstr7SemGXml1jNkPRIlgXpo8GcmcuRjqSHortbNemKHOaw5+W5iQKu6zxBUS1vkFFmkS+S3qgAtWFM7Cghr2swTfV0KVOgbvujwgAi9V3lzTA9em0LYwyIjml/NApWw4keuWjD1NFwIOkxaiZZBt3vmlkqx12WM59UaZ3Wgxoyx8zpICtq+WIKdE5ZHaoYQMqckcBn0IOaHoTSlAxOxMpLf8ChtJ40c09ibR9aX9FGKCd0FKFrxGkKKt0Qk5zeNftAs5F0vqbUA9EeFltFqtijBATfE0mnQbocTY0zZtlrjQJcwU9cwbGGIFDnQZOFSdS54yLpBkRUy6vG2KHPEeQ0l03ye3mQ7pincZF000Q33RfzbWJCktLdGZJO5txaX7q7D8JtmpG0I9zn6qfuLpYsqgrUiMChRzcW/rW6yH7zuw+maaKDJmCcwTTgCrKmjgkZpHt1sAFcybYpMVvNCkwt2V7A9Uqne8vWweQq+75JPZ6JUx1kz3Gz6O6+SHpKzFbyLAQF6SKSrqIt6pvRsiB9NJgD4Q27KLbKhNosLwSzUQEaNRYc9QzVlCgB+5np5/wCEsdCTS1vkFFETrqBFTuJKicADPdA1zVuA1N7/w0+4JRSPB1095i95IUA2ivrbBpAfZiNUakbGIjQclDIbOfLpB5NGEdEm+MiG0QRPwwtVnSSkgZVBav9kZH3QbFYMkVNX15BrE664QeLRRmGDw2Of81R2hPEcGD1sfk2b3Ec6ogw1oQaBzmnWckjn4A6n9PZ9Qga1zQMH+V+MeHQXHV3jzZegCAcB9iIpBKldR4J9aTZi0h6UgS/YQQwZByskSTrR7juEEOJ9Dk8adiAS5iWOc0B17AtDN09IZJumKatCM6LxgE23Z3VpJM1yTnnxHaVHgg3zMg6GLJz9aa7iz6cOiSdFziUqbt77dl+QTqX1JEG6Q66cshe6Z5dGgB3r/SYSb6GYYrBoSshZZ/7eEtl3zSTs8x8y2N03X6tNiD0SU9a+x1kpp+vBbhaeqqalw0/9krZSXe3kfS0r8dotCxIHw3mQtLDLYqtMsPPmeedu+pAJEprUiMLuEemG3CJu0xURBMOMipyJkXSeeXTlBXexZr0EHT3mAECoYh73AfeuakOor1oq3FHSQYYpo8uAiDJINtlBFHMtwUbP7blJNlBVbK5bgelMpTPQXdXhdoIG77fNXWgZ9w19UWJATeVMmRtYtmwmAV+QYhytCBIBM8pShXO8SyYFeg08PdC5KgooEKdgyAzIzheKtleQn/lgOTAVA80Nc6YYYXjAGBSV7z6VqGVosu5z3F9rgdY66Yt/dHuNUly+DHInMhWuLWw7CXGxo/jCNKjJxiAbta2yxGkO5B0Jqrq2Bcbpg+SXmi3k+C8eFZ/JdI1Nk1TBAE86e5ikK5E4NBXO4HOH5okDr4PDdNktHQpku7QxZgSsmSx4VXSB7iZOCzZFj2p47lGAQILQNc1VpKlAjku+QnIcp1x6Jpda5iJy96CTPTpfEo8K47yUwVlGMHCcWKSp1KPrunx32BZkD4ajHdcTVOo4RiJmSeB7u7cwPNFQUVd07REvUmjn5dHRh2QBBnNqR0yLKaVd72Wh8K7YvE43jHVQiDp4+PWSBo+6u5C2zKxx24UJNgweEp98L2Om0FuGKZ/qyYHqj0+ZomA02iQbvrS3UXhuMQ16QaP+gUHwww9474rUX0NR3cHOCGngPtSZKie7B6IaIGqGjjhu8jYGh7J1UDqPl9f76ml0AeYJsZ12DoH25vg8EkTifz/U6C7C8JxAQicF5oa1czQDBnxGYtXLuMn/GUnA4QWWsPh7zWpSw0TuFhoWsgStDYayIVgxDB9ioh90huGiS4tHJK+w1h7zvG6DwTB9VhzNE1IptF9oNYwI3V1MUyggDqKtOOGl5YEo7srasFmhCy3iqAjQ5JitCbdj+4ejdlp+q4fYk361JgCuYTu7jPXHeUxk2Mm15zmC0wBXNnbIMqFHCt7S923FNoh+yHpNEhXwzIT2BheidXaINCoC5oemXic27IgfTQYneRGHagPs4Wl2jCaQnOMar50dwDOvpHNqtER62H9soqOmvQmIekdnllmucK76nIHwTH1Q48com7R1d0N/wCa29D4caLM9WDUVwwok9HdaYmAjG7owT5IOKeKlO7u93wZNaBeZfN4qNYI7GXrZ2KSyw9JF59rEUk35f2aXZ9B7ktYRLbM2kH5aE04kPSkz49Yg+qXtKCIQbjvUrJqfY2crEzD+kzTAGpDKOR05uAkZWcEmWGGp7vzIl5JE8mk524Akk7p7mPVlAIJpT8BwnFAgvVD6GMsc+7t56GUt53ZSAlLoWexRAjM2T2GIaPe15BXjdZ8S8fEhF3UNcjk6e4BSPqkzhJ0jSQx3B0l/NYc+zkt5HQWQEepSydrI59c80APHcGQWrp7iHKrEIwG07RL7zTfmvRozE6hBVuAtgQTR45Bd/dMyACu9UIVQEQYDX7aAJzWDvj1ImXf0vARtANc+62qnuViYtWjowLgSpyr6AbyZrMsSB8Nxk/qSj+K+XgbSbMssO2Dq+1Jk5B0IyB5UJI7FlEpelGN1aR7UTqpM1KhWWZyTVOpSfelzjmSK53x6O45g6Pz+s0PqhIeQ2XfVyEb8BRM2RxCfZs3IzQSZiHpFMlQJhznQ3cHgNoAOkp8yUD8ccXEh981pb2RbdG/8J8hR5+DMvv0eph+NfoOdL53uI7hWnwdjMBaX6dydEjBurIfK6DQDsCqs3S0c0q9LMfga0r9heOo0zVcS05hJMheQE16RaxJd6KpUU2sSQ8OfuIGXTmDe3+IjhpxarvFxFhwmVcYMVeR2i0L/MVnLu4a1DAQAknvAUwT+ZzOnm1+bwxk77io6OGeU974dc3UC+6OGx7Ccb3D9URaPMKeHQJJD1PCx7dK08rBQXrYmuKG4VHSB3h2sdkQkS0q0qxlyvQe7b+S6pPwz4OUUScm9VS14As+r7DdVMREsoqkhWfZQb5or3UOynuGpLstC9JHg+k6l1EXF8aRKB4nCkyFobRaC1bK30V0qoOF4ybGbDEW+bwME4CP8qlnr3TFNelGQB2mY6Oh9MvBagNDEUTd8g0fOi8/TtVB0YsQ2AaLBIpzcHxHEZpGNttISYdGDXnNqleQOtmU7q5WOK7IlJUlDoGjpATgOxXE33yFDV/m7BfEa2oHFPZ3Fel3wZT5sLRpFtj6fWZ9GGjU0d2WRylPtr4kzhkJfsJ8F2d9fUjqvszZ03VXMqRZ4nEECfNC0kXaebmQw5g2MgeTqvaG7ZMOeKOpUU1Ud/d5rhMycfIGvxYGO/dx2l6K7ZD863SBcJoNgjBUiPWVP/cogYnB1Ud7Iulmg91/m0lh06SD2Tvy5zTK2iDSe4N9izFtBRRyJNmWhKnXMDl190hIegDdnaGg3e43OOeLdb2C+mubwud60N0dNPRq3cC2CD27fftzy86daRAkX6P8k/WiqOokCcssDRM76UjOy8HwoGU7Sc/LcAr4eY0bUQfjv9GyIH20mEcd0EgUjyN0dz8RDTWiXdHPK5pwHBNZaULdUAk1u54tdE26erp7FOpcZymPohXsRGEb5Bvk7xtagdSgu8Zx1tHFQ4+iKPnnczq731Ec7XyDe68fkl6lNelqAirf9keAm3quYPMVA5fg51qG+onquyESeCGDdFtp2udeA0C1X2jtliRzbwhq58HrSWjqPuh3kVwfwFPhPSk7I8gahk+/cj5YtkQ2GGU14TqlmYa9bge0bsrndHad1yYYV2ipFGItjB+kW6UNWh7IFSTjJFdJF7ppSJ85p1hjMPVUSNiVZCVL3Hlb82FijPIow+Rr0sc4xmiz9UuYwrt7bwxOUshbNEYBQBpBtGLHGJqmKVmTTZNr4edbbiUm1rcNVj2ZJobB092D+6SX8jn2uX7+qNDz3rOkbzsACGzRKNo7RuiadFHNPHkNtokSo7uHKI9pEpLe8Gs/CLj2ElUtkcUSmxBilSEFYv8bLQvSR4t59EpXjaaqMN8+6YAyFCL6eQWhq3TzEWvSByIixVGtwfcPBSRokXdNukpF5/B1mGSj1TQtlgI+RY/qOcncAFyB2oQYYzT4hEyIgBKIV4+V45EwKZIuXjNVARVFjqXzGPAUbkoyrkhVDw6w6fMzWG1gsEooz+FbwoioVu9w3fcZ9L0eEmbBFAWJweCe73LBuiAknSZgPO+ts1d6sxg/fv3KWfBs2mVMirqQ0FIG33EtZAyILzrFWzCSLg/So/ZczjfIGI2cJMCSjBOn7aXJ9yz202xwUYD9atJtJ1zzS7bBZD26J8YRADVNb3V3TXMrvHeT68X7RWLgJqPmi/t+nEBFoLsHtLmjpsLvMYyAxKkjOBzXXoCmkfvnJYzHd1PQnCUGgCvAAsLpfAhdGgKSbUC8VsNiJwOfBAOrSSdjJA2Wg31Lealg2ki6aQZoXniwWvsrdbZnx7FGEHslQ9JDWxakjxZzIH9TWe3IyAvSTV5EJZSCc3Nq0qPWpsVFiqOaoHpa7CKUVuG8ROVTntKZhL7sNKFnbwj0COBrrMOfR8FC0us5ifMLuKhhE2KMISBhIeYgEM9pojWldb3k7skKuOmqHVQEL9l9K/lRogFvVDvBMybU+YfQEugs2bRyGkASxCk89bSzlEd7kdSy+jlrZb+ezfxYjgAySeZepNH6UfrEhMOWgYpvIFfyq0kHpKUaQDOE43xQmXzZToQ4ex0nTCS3m8SxNfW8Gy10CE4BwA6WZsfa7fHHDa5JF53ucVzP5SgsmaKV5DO81kK2fojP8aZIdd1h6e5iGyY/zQYeoZOirXygkoQF4FeTDoh16bAV3tcKQTqfsA1Tkx8nOLQTIdKkBd3D60NAgwQ/kxR0jxF1ZCRziLXwI/tPPqdjXLt/Uq/BCbzpIWrSATug9kOkDR6McGlaiOUyAM/EiTJfgoLDdJB0oUuDX7LeSXdPG0kPYhQ6WBGdnHZEkmsilDb4agNQDZPgxOB/q2VB+mgxL0XNEYikN6Jm75okGhG4WTsCBB4pTlPhnd8UXRlmwIWk8wI5Ku9/YE0675haYi52SUAEJL0RhKQ76O4xxmgIbd6C7zVgJ4uiXFNKdw9GwshcH9dBApmtA1VU6+ERN6eVGWrjgbZ6td5JgKSbEenuPKWTIhXBiujuzwhDE2/z69oASNSVk2fuhaRfiDk2rr2IQo4Ecn6JIF+nCoCzCwVt6xe1FWJUE+o9nU62pnn2Ok5Sk25yiQGz2OlOhNFaeAkClwTBN4NYRY41KqdrjPETKclHuxIEJizjd9QIz/gg8zSMZgO/l2qyZ07Q0XEIsaqqSQdsJN2iSctYFFG//xSKCkdB0gUAwCcRwI3D1saEbJ5wSPoge2lCgBCrgKTLrrmg8UGeEcpM8nvm8mbVp6SPWzss38Jmi4ZnxJhmUAmSs/bdvgdJulCYQseaYEZD84TjghB+bu6bpqMULBnDw1/AL0PSw1oWpI8WcziZU5gjMvImdfDC4EC1rAd0c793nZQKExVpfQKEih240TZSyzb2u9+vyAwT3oIqgEv5FEinLl1An2X3jW0+JtmgwW34EQKEgmHVpHsF6Q7nLk6AGaxqyo1hbc57TiMb+D0vrw+9YVMkvaF7Beni5jxtTBsmdZVQa5i45+V1ocaQWTDd3SmCmNwpCHZ2RbQAcLdhE+iIvmqz7uSJn9Nc9nMI+POtqETSA+ofHQilrmuBgp8iAyQc3X3OZPL/R5ZsQl+E/tlRTSjLkfZPdqIj0ZEwpxlcOyhTdm8lSDotB1q+acD9/gjj+vdJdwc/cZg4BcNimMjQN2EcWssaby30Z3yI1zCMZoPBJUH1oGfOWg+mjyPX8cnXt4ZeXw2/PumAjaRbdHdpTXrDR3gQ8ETSo6B6gSKS+RJXckNV5Mk1TqKdILYADS7LAOz9dNW2Qff7Idaku5JxgOijWEEW9UcWr+9zv9+yssk9j16tFM0Gmy/TYiTbfNk+gGu9oPeg2kjWhUJr1Pw71jiS9bZwXLqJVTOsDpNpsHk5cxx53/xlW2KP2wgr4DcsIukbFLTsfLNZFqSPFnPUNE2NsZE0y8QWbMHKrxM6iyjmdTQMEy+s2pbaeQWLu4i1aQBw/O6TAQDXPbo8tcXDMEx0UkckBJIOpKPwbphAyY86x18za9PfYSzZfKIs6AUa2HpStZ31W5QiXg3dMksQjvNrwWbUAasu9L0HTkcpr2Phul48v2p7qHGo8JMnkk7vZy8JyHO6ho8evhMA4A/zVoQaQ2blQLRVFI6jAdOLq7dHqpnlTXx+/Ojug4BB7tMkRx2q0E84ZBkCPfcVm72DLt+uDZLPpZToF1Ztj50YDHTMSxK2RoDCuyD0E/RdrPXgrbtOxK6TO9E3XMdfnnwj2peIYKZf71vAJcoUVijPz0S15oAaU2t9PnKXCQCAh5dsjM3OagS2tnIHP9TxXr09PPLHlPw96e60OwTdK6MnAviAOozAIRCMbPHBkJTezZ+79cydus80tBVyWLS+D08s3xrq3Bt+fdIBF5I+zXqueb0W3Ri2AyjpXiDu+zRg2NRXCa35wifsPK+Ho/Z/n+lkX79rwVpsi8mCEZB0X00Ue04evjN5Pv75wlr5Zzbqdq9x2TXPFezElfVd3r7XFADAva+sx2qP4L+NCsYWOgA9J/6y2AFo1mvOJF8EIIrQ3UPUpFf6ANNEuZBDd5mI1yZhcoraNH4sM3crRZW6Qk4T2ZEy4KUd6NqB/LxyHgDgA4fOBADcMH9FbC2mwGSJixlchq6Rlp1LUwTERqNlQfpoMcdGSoP0LQPVRH02U7FG3aY1+dFirSCskNNxxgFkobjukddTO61AdXdH+ycA+ORbZqGjSByLB17dmMp5NfxqtQCPIJ1c11fW9rjfH9MCqXN6DqDBqHXv3n/IDOR0DQ8v2YQXQga2RYakh6N4TuosYYcxZTQME399KlwQIjimfuKFALvf4zqKeNf+ZB7+af7KUOMwdWbd47vseCRxPja+AmxZBgD48OE7opjT8fwb20NfM6cxursX2upAtY/dbRLGdxSxausQbntudawxxa4NPokPgM0P6mg9+TpJ4ohOVAD11BF0/fGJlVKnwQxKyAifS67HCXtOxpi2ApZvGsCdC+TOapAZgcq57tpNSgtdtdUDxeLKATxLGSbvRY7LHgRAEPrPHjMbAPB/j72e2n6gGxW73aAfIku7UFj3ftW2wdjnJKL3PmOaDRaI7L3DGBy041jUGiZuempVrHGFJJ8fkt6oshrjg3ccBwD429OrQid080EJS0cyYNaEDuR0DW9sHcTzb4RLaAeiWhJRs50mkO/371fWe34mo7uXwrF5xrQXcObB0wEAv3883D5vmkAX1WsJgaRP6iJ6LbWGidXbrDrsBpc0CVGTPrGzBM3SfFkXMsEkCmJ6JS1EZs079pqCvaZ1o69SxxUPvRZqHKcR7QQ/sVc6f+z15v2HzICmAfOWbcHKLe7Ep8HNAylowL/OJRzesusENAwTv3tshfRP2ixtCaMgeY4l5TLUx1m6oS90YtkMZDfR9cJwdRBJQrXOWSV8hpbz6NLg0KbpLDJdoUU+7IOkJrQ8lc19TQP2fBf5eeE/AQCn7jMVM8e3YetAFbc8G2/9NBsNO9ETgu5eLuRYoifs2vDfYlmQPlrMseGNbS8whci7FsSnzaZhemAfbJHuDgDnHk2czH8vXO+LmCUxsS1XsHAcAIxtL+JjR84CAFz20GupoOmkzUz4mnQAeMfeZEG7/fk1WBMBufEzknX1oc4BLqdxpwkdOOMA4nj95v4locah6u6NfIBzZ6FHuq7hCyfsCgC4cu6yUGi6SHeX3Otc3v6O3Dz82BEE5b7rxXWhaicDkfSOicDs48jPL98GgDiS79x/GgDgDzE3pDZLAVwLQlutTbCjlMfnj9sFAPDbB16LFTQFMmTyZUCzthQrwXKWlZX/5wtr8fwb2ywnKoSIE0zmWJ550AzMGNeGTX0V/OkJd/LE4OoQNU/qrai03l0u4DNWYHvp/UtQj8EuEFpbhVCqB4CDdyKB3B/mrZDOY36N8kTk9n4POS5/GOjfBAA4/YDpmDamjI19Fdz+3JrI3yWMFRtcYiEEbXrOlE5M6Chi+2ANlz8YLwgRa0xlytxuBA4AzrbW7L88+UaseyvWpPvQVwGmXv6RI3ZCuaDjpTU9mL88HLOI0t1NT00LR8Kyq4T3Hmittw8sDTWGKaBaPg6zUQPqZO598qidAQB3LFiLV9f1uv5ERNLD0d0B4BPW59736ga8sUWeqOKtYXBIurMFG+BC0gs5HYfsNB4AcNmD5PoUrSC9ppfdCC7g8q0KOR37zyCfe2XI4LnB7zeBuhhkDdJ1Dd86eXcAwI1PrIy1j4dum2rUWDJpxrh2HD1nEgDgb8+4gzDN8n+qpkSokX0X99r22WPI/nLT029gu0Q5vmyQ+9iQlcoArvXjoJ3GYkJHEet6hqXnKTNR3V3WGrDNnkdrngEAzLTKMO5buCHUGDIr0I41XgKyLEgnz0Ipn8PJ+0wFgNgJmjBmGAFlfwCw1+nkuOguoF5FPqczf/zaR5bHWj/zPLNAWjIhsq4A4BxrzFufW5O6oN5osixIHy3myDxpmoZPv5VM6t8+uDTWg5SW0cy1AV2+yEsQ6zlTunDCHpNhmsD1jy1P5byErKIfkt6oMEEUADjn6J1RLuhYsGo7HnttcwrnxSPpMkqfiFABwBGzJ+CoXSag1jBx+YPhnLUgCxQGA1wqpQDwxRN2ha4BDy3ehAUhkGGqaOyJpBdFxxQA3n/wTEwf6x2oOU1UNfWi1budyP1njsX+M8ag2jDwt2eCEWc7SPf4LgCwz5nk+Mpt7CXqBN/90rpYJStlP0cEACbMIccl97KXPnrETpjSXcKa7UOxEMZAurumuRze/WaMxfsOngEA+J87F6IehD7n2wBYTo51X4p5HV9+G/k+Vz28DP0VsXZQUJ0Pot5yug6fOGoWJnQUsWLLIG6LEdgKra2kAaQ76ffRI3bC1O4y1mwfwo3zV0g/kwoQSQW5AGDCLsAOBxL0+FWCfhTzOj79VjKnrn1keSraHmWD3I96rt3dgQJwIWHlQg4/OWMfACS59vKa6KwfAQWWOXua5qpvBIBT9p2KCR1FrO8djuV8B7a2ypdhz1O7veIHDiFJqWseDreHUSV/wwtJp9+t30a0v3jCrsjpGuYuDsdeEkQ0/ZB0gM3VfWeMwWn7ToNpApf8e7HrT8ygTin861wgt+vkThyz2ySYJqHTBplp1O22fyVZkG69ZiHpAPCdU/cAAPz9udV4eU0P8lZyqe6VFJYk5y84hXzGX596Q5qkcJroWwTR3e1xjt1tEo6YPR7VuoFL7wuX5BbH5fqk+4m9AiyZBAAftJKntzyz2uU7mpaP2Q+POQlIFd6PnjMRe03rxmC1gT9KmGisS4MX08Dh57QX8/iSlZz/zf1LQ7UEE1t/eawXe7+X/PzCXwCA+dF/fnKllFkQxnQqIOvFqJP4NHRPu/uldb61/EkssOwPAHY8AuiYRK77ikcAEH9rfEcRq7cN4V8vy9k0fkafORIDSK6JpHXmITuNI75X3Qjl4/23WBakjxaTLIpnH7kTJnQUsXLLIG57Ph30JI6xrGKu7J9VrIoLIs3e3fLM6kgKsGEtUEys1G0vKOtfZC9P7CzhQ4ftCAC4LCYi5H9e8O4fCtiOSH2IIR0A8LW37waAXK8wqETweQS0cwGktZg7T7TR9N+GQHdY2yEvp0kiylTM62zDvvrhZYEbNkF9qQBXuJpJah+10PQ/P7kyMNih9fWe6swAsMdpQK4IbFwIbFgIgDjBh+w0DrWGiT/FqCO20VaPa3jAR8iYa54B1jwLgARNXzyBOAaXP/Ra5HozQZk9SFWeu6bfOml3dBRzeGHVdtz23Gr/Z1DXXSwAgOgF7DyxA1sHqrjBUctP0BML1St53OuJ5FnB8rnspY5SHudZ7ILfPLA0stq+2NLRB0nnkn5txRy+/g5yLpc/+JoLceJpxJ7zFrATPy/biZ8PHbYjofBvHsB9C6M7VkFGkfSGl5PtQMIA4NR9p+G0faehYZj4xi0LIl9jMYEZDoEDCFL1wcPs2sqo1ghaCzVNuk6d89bZ0DXg4SWbQgV3bP3wWm93egs5Lp8LDJAEcVT2kiAcJ3vmcnkbhR3YxF4+/x27IadreGDRRjyzQqwhb9SGuDpvj/kwjqyjWPGY8PIn3zILACkLcCbcnFaoc2uzbwu27eylg3Ych3fvvwNME/jJXQsZaODdTcStRXP47Ak4dd+pMKzPCGLQGbxeg2cQap3rNps9pWkavnUySQjc+txqLN0QLVhrNOooadY1lCV68iU4k54AcOKeUzC+o4iNfRXMXbxJ+BN9kJT1DWgeazxgP3P9dgmgpmn47LHEh5MxhToo3d0TSXczBj98+E6YOb4NG/sq+P3jK7zPxzJDYN543IcDP0qOC+8Ahnvw1jkTccxuk1BrmLhYkpAKY/YcCycgCwB7TO3GqfsSND2M3xTHDC7p6wlW6DmO8n4HALJPfdxiI109d1lkBmmRT4zJYgAJkq5pGkPT/zh/ZWj9oTe7ZUH6aDFJy6iOUp4tipc9uDS2IJRqoy22vJFSUUSD2hGzx2Pf6WNQqRv40xPqBZCENilezgpdrJ7/s/CrzxwzG8Wcjqde34onQ1IZw5pYk+6jmgwIaNGhs8bj6DkTUTdMRu1LYmJNesC96xPreCma/sCijXhptT9iVmB096D5IQbPZx48AzPHt2FzfzUw0yoGlB6bE3Wa1r8kvPyu/XfAmLYCVm8bwsNL/HUI8iYN0oveb2obC+x6IvmZQ9M/YTmrf3lyZST6OaHiBny3zkk2Lfqp69nLZx0yk1HHZUhu8LgByuM0obTVRhInd5dZcuCel9f70xEBKdMmn9Px1RPJZ1zz8DL0DNlMF75rg+71mfu9nxyXzwV67ITmR4/YCZO7CLvg5pCUSmqiqJlPTTogJhwOmoE9pnahd7juooHzwnqa170F7Hu7ch77Ph2lPM4+kgRGV8VwrIKMor6eZSqSRDIA/O/pe2N8RxGL1vfh8ojUTtOAP5IOSBXeAeLg6xrwxPKtWBIx+DEFhNJr/bDG3bqMvbTjhHacsi8pZbnukWA0vWCtH57CcVP2AqYdQAQuX/o7e/lLFpr+UAg0nU9ieXY/mH4wOT5xJXtpl0mdeN9BhAXzi38vFucThwZ7Juz2+yA5vnK7MCeOnTMJsyd2oK9Sx63P+rOVSnUyTk0vyWt96RrOIekA8O1T9kApr+PJ17di2RrCpKjnApD0YXHfuuCUPVHM65i3bAv+E8DGME0E0913O4kcn/sj09sASFLhpL2nwDDJdY5ieoNL8sn2bE0Dxs0iPy97iL1czOs48yCS6LnpaXHda3v9fgDAAuzmPfCMQ8nx5VuFl0/bdxqmj23DloEq/u64t2W/Lg2AtFd6Ma/j628nJQFXz10WKLBnBPVJB8hcn7g7AT1euR0AYU5oGilzi6MTw7o0eHasEenu1NJG0xtGg/ODfJK+POXdKos4+8id0FbIYeG6Xjy6NBqDtMiSFgF7xaDoS5+yz1Q2f/75wsgBHltpWZA+WkxClQKAjx0xCxM7S1i1dShww2uWBWeu6XcRN0VN03CuVSd643x5zWYSC6S7A3aW9aW/C1nPaWPa8L5DiMMS1dEMPq+AmnQ9J0WLAOB8C02/7fk1eD1hLb+oFOtx72YfS47zrxAcjdmTOvFuS3QtqFayaAYg6fQabF3ONgyA1Ap+2Qr2rn54OQZ8UBhSXx+A+u73AXJ85BKgZlPOy4UcPmDd6xsDBOTy1ubsi6QDIvJpXbeT9p6KaWPK2NxfjaQrYXIJCM+6ZQA47DPWmLcyFK6Y1/EVjjoepWWXWELgcU13P5kcn/md8PKn3joLO01ohwYjGCnumEiOVs0gtXfttwN2n0KC2/971A6ARBErDwdw3CwLlTSBF29mLxN2AWFoXPHga5HWHFGkSDKuh+5BTtdwwal7AiDzixeRMzlqsu+9HTODiBLCZI4mQCj85YKOBavD10WHtZIRgKQ76O7UJnSW8JPTLdr7Q69For03OCRdD6pldYw7fWwbEyOS0W/9zBBqfT2e7T3eSY5Pi3OdivjdsWBtYJ1xiQbpXklRgLBiAOAFO3E8a2IHTrfEVoNQOJHy6nHv3vYDcnz+j8DGV9nLXzlxDop5kpx+eImNuJpV8r2GzKK8zhsAZh5Gym5qg8Ic1XWNJSj/MG+Fr7p1oWHVR+c97j0TjhNF9KaPbWOaE8YwCX5qXvvNhF1Je7TtbwBrn7dPf3w7zj2alJD87F+v+iZSA/UpAGDf95NAactSF7vgmyftDl0jddHPrgzf4Uar86riHnOI+jTP/l54meqFPLR4o92BwTTRufxf5HX9SO+BDzqbHJc9CGxbYZ9CTmfX7LpHxbIbhqR7MWI81o93778D9gwpsBcqIaVpwAEfJj9blPc9p3XjTCsh9bN/vRo5wZljwJQHkt5OxE+xZbkATqWNpov6UD5J353eCrSNJ0HzyscBECFdyka65pFl3n8rsYKFpHs+c1P3AaARxupm+57mczo+cdQsAMD1j76etWNDFqSPHmPKoOIC1lbMMcrmZQ++FplOmIbZIhoem8YEcr5Y/5KwKQJEWZJm0uLUifqZ0aijxJRQPZyVWccAY3YkCYRX7xJ+dd6xuyCna3h06WYX/S/ReRkcRctzA6NUsO3CywfuOA4n7DEZDcPEZQkXecOEf9shADjqyySAX/Ms8NoDwq++eMIcaBpw/6sbfB1xm+7usWns9BagbRywfSVxGjl7z4HTMWtCO7YOVH0DaCOM03ToOaT9SO9qV1BJKe8PL9nkW6dG6aqml4NEbbeTyXXbugxYt4D8bU5n4/x+XvgNiXcIPZFjgCAG0w4gdOvnbmQvv+fA6Zg9qQPbB2ueSrwyC0V3P/QcIh73+sOCs1/K5/C9U/e0Ax+/z6BO5eO/FZI0uq7ha28nCYb/e+x1bB2w27oFtj8CgP0/RI4v/EVIMJ116EzsMKaM9b3DkVqYNYKYOYC0Lh0gtahHz5mIasMQ0DMiQEVr0n2+C8Alfmw0a0JnidVFX3rfUqVK70z4Ke9xXu1WcmXdArKocXbaftNw6r5TUTdMfPPvL4YutRDp7tGQdMAWkLvtudWRElKGEdChBAAOO5ccl9wDbLPXov1mjMWRsyegbpj43WP+wpAF63kwvdZCANj3fSSIXP8isOEV9vKXTpgDXQMeXLTRVwvErFft7+I1p3Y8giQdTAO4/8fs5R3GtuFsa426+N+L7bZmAwRZHoJHUAKQYIg+y8//SfjVmQfNQFc5j9c3DwjBv9PKdRJgV/Me9378bLLecOsqtc8duwsmd5XYM9rwQvU6JtrMlCeuFn71+eN2xaSuElZuGcQffOjWYsspn3lKGT2OgHnXyV14/8Hkuf3xHa/4JqAFs+rM68h7J0sO/Big54FVT7JyKzrmITuNQ8MwbdR77XMo9K/BgFnCE9oB3uOO3xmYfTwAkzADOPvAoTMxtr2AlVsGhe4A7SZF0oOSbaLvoOsavk0F9ub7C+wZYbQSAGD/DxLByVVPApuJ33T+23dDyUpIRe3kUwjS2Zl+EDB2J+JXvvQ34Vdpouk6V4rjuUcBJKG8x2nkZ0vlHQA+/dadkdM1PP7alkgMA5bQ9Xrmxu5oM0uevk741VmHzURHMYelG/vxSEQE/81oWZA+WmwCyQpjwyuC8wsAHzl8R0bZjNsyQaXZ6t0ejseEXYD9ziI//+cHgsOcz9kCSNc/ulxpD0m9zqsTeyweug4caCEXjgBx5vh2Vgv48d89hbtejNe6yWkELfLpBQvYQXqve8yvnUjQ9H+8sAavJegxaRghkPTOycChnyY/z71QuHe7Tu7Eu/Yj6M73//GyVOEVAIqUIu41RttY4Nhvk58f+pkQ4ORztojYNY8sY4Ga+7tw7cK87nWhDTjOGufRXzpaEHXgWEvgyI86XGB094AgvdRpb0pcUPWhw3ZEKa/j5TW9uOzBcN0DDJ7u7vXdAOIkUzT9md+x3uX5nM7mzJVzX8PcxeEcksAWfQDZfOlm/+Q1wq/evtcUHL8z5zh5OQ0HnU2Qh22vAwv/IfzqpL2nYu8dujFQbeCndy1EvWHAaBhc0sLneux1OpnXW5ayOn2AJBDonPrlfxbjnpfCsRoC+6QDQDehPmPpf1y/+o5FsbxzwVoWZPGop+5VX89/H00H1j4nlBece/Rsgn6u2IpP/O5poTQgiZVo60RZCyUA2P0UUle66VUXDRYA/vf0fTC+o4hX1/XinBufDhWoG4ZdUqB5JTC7rT6/r/xDWI8A4KhdJmCXSR0YqDZwexTdFo5F5YlQTtqddG4wDeCZ/xN+RcvQbnrqDfQMel9/uhb6Bunt422GioX8AaIWyKX3L/HcKwVH3S9wOfHHJHBZci/w+qPs5c8fvys6S3m8srYXf336DcA0MebJSwAAz2t7eH8eQBJjNBjaZNfPd5TyOMtKJv3mAW9RsCKlu3sF6d072MmqRy4WftVRyuMbJ+3OnlFPfwQADv8cOb58K9BnU9s7Snl86yQSIF724GueAaIZ1N6V2sGfJMeFdzB2E7WvvX03jGkr4KU1PTj3xmdCsXqoYFlN90mWdE0Bdj+V/OyBpv/tmVVk/lgB2oPGgd711ey7fIIcn/+TkExtL+ZZcuyndy1kwV0H9XGC6O7b3YlSJrDXMHCJs/SCt0YVhaCEFAB0TbVL0CyGyg5j2/Apy/f8+b2LIokx07I3zyBdz9l78ZPXCOvUHlO7cZpVIqMaTdctpkVVK8rFPnnb6wxyXHQX8xVmjGtnDMlP/eFpPBG2awVl03oh6YB9PZ7/s+B7dZcLOOtQogF1PceY+2+1LEgfLTZ+NrDnuwGYwMO/EH5VLuRYe6XLH3wtlApmmlYIorsDwAnfJz23VzwKLL1P+NUHDp2J7nIeyzcP4IPXPRFLFVhmuTpVnde8HS/AokJpBA3cJqK13z9tTxwxezwGqg188S/P48d3vJKYvWCYpi0c57WB7XgEOT70M0F5HiAiZG/fi9S0ff8fL0VCjMTzQHBNOsCh6c8Ay0Q0/Wtv3w1dpTxeWLUd771qnhSFLgUh6QBwyKeBcTsDAxuBeZcJvzr9gOnYxUKCP3DNfKzrcTtOYrs9n43igI8C43cBBjcDT1wl/Ipu2Dc9vQpfuekFaVDBgvQgJB3gVN5vZ5v0+I4ivmLVWv/qviW44LaXAp0Ds15jyFgw2vpeQmPrWSUovZ+27zS8bY/JqNQNnHvjM7j7xeDA1GgY4a7p4eeR44KbBBqqpmn4ztuIU1jPtXk7DcUO+zMe/aWAymqahu9Yysu3Pb8Gn/j909jW28f6d+teaCtAkCyqOcEFOwDROzhqlwkYqDZw3p+fw//euTDwuRbRM4/7cMTnyfGxX7vqZvfeYQzeY7XTOu9Pz+KVtT0OBojP8wGQhNnOVvkJJyA3c3w7rj/7EHSW8pi/fAvef/U8rFXQprHNoH2OvZD08cBbv0J+fuinQF1MoE3sLOHajx2MjmIOj7+2JVSgbpgIRtKP/CIRSVz2ALD4HuFXmqaxtoq/feA13B9S6V3nBDp994rDPkuOz90oBPbH7jYJe0ztwkC1gQvvedVzLhXNAEo9tf0teu6LfxMCIr6zxsm/eQS3P+9W685Z4ms1FOR13dQmzrEDr/t+wJ678R1FRh3/3u0v43fXX4b2VQ+jYubxG+1j/ufdNcVOTjqS3p94yyy0FYig5AevfQKbJH2qSw3r3L2CdAA4+hsANODVOwWkGADed9AM7DLGQv/91oYZB5M6a6PmCmTPPGgG9psxBv2VOt5zxeNS1oKgoO+3Nu5wAOnMYNSE8gUAmDqmjBs+dRg6ijnMW7YFn//zc4FrEKUz1zQfTRTAvq8Lbhbo1qftNw2dpTxWbhnEQ4s2sCD9nsZh0GWCX7ztfiphz/SvB5b+W/jVJ48i5U1re4bx/qvn4fpHl9vq7l5I+i7Hk+Mrt7l0YjRNw7ctgb3bn1+Dd1/+OB54dYMrWM/xQoN+NdiADcYsuIkFpecdtwvGtRfw2sZ+/OiOV0L7UhRJN/wSGwd+lMyNjQtd5Q48mv77x19X1q0pZwFTVT1gLwGAnY8hiZL+DSSpZtkFp+6BfaZ3Y+tAFR+9/kn8cf6KQDChSBO6XqwrgDAxJuxKBBsX3CT86pNvmQVdAx5duhnXPrJsxOhttcKyIH00GUUXX7ndhaZ/8LAdMbW7jHU9w3jbLx/G7c+vVopCR7FCmLZUY3cEDrccnPt+KDgenaU8/uf0vVEuEOrRuy5/DN/6+wJs7Iveqoo3nS1YHqrz/LnR2muHMz+uo4g/ffpwVmLwh3kr8IFr5gt1pVHNMEx0BSkYH/ddEmxtXEjqwR32jXfsjlJexxPLt+LMq+bFUns3DCMYSQeI43XIp8jPc38uZIV3ntiBv593FKaPbcPyTQN4z5XzXDV2tCbd9Muy5osE2QGAeb8Feu0gMqdruOZjh2DamDJe29iP910131WPbxghA8pcHjjhe9Y4lwGDdhnDsbtNwk/P2Ad5XcMdC9ZKEwJ2n+MQQfqct5MkTM8qYPXT7OXPH7crfnL63tA1khA498Zn/Ovth+2sc84PtQFIoEfrB5+6lr2s6xqu+ujBeOd+01BrmPjSX5/D3572Z+GYjRoLhn3Rop2OAqbsS6iYDirkjtb0zgehxIedQ0p8Ni50OYBHz5mEqz96MNqLOTz22mZ85nc26ufriAN2LeLLtwqdEgo5HTd+6jCGgP7u8ddx1rXzfYPbUG2X9jsLmLQHKVNxJJsAgqbPntSBtT3DeN9V83HPS+s59fuAawRIVd4B4JjdJuHmzx6ByV0lLNnQj/dc+TgWrg1WG/ezshlQkw4QRLJzCqlTfe4G168PmTUef7ACkTCBuijO53FvJ+wCHPkF8vO/LxD0JQCSgJk9qQOb+ys458Zn8JkbnwmsFdeshG4VBX8EareTyH4xtE0QdtM0jTneNz29Cu++/DHp9ac16YFB+py3k4BoYKOQGJ09qRM/fvfe6CzlsWRDP7528wIc/8u5+OMTtjqyZiUPKl7lZ7wd9x1yndc+L4hcnnfcLvjsMbPRoQ3jHat/AwC4tvFOrNF3CP5MSnlfcJOQYJ4xrh1/OudwjGsv4MXVPXjvVY9j2SaRCVZuBCDpADB5D2Cvd5OfH71E+JWua/jQAaQeeOqkCf7nSdH0p/9PWBt0XcMVHz4Iu03pxMa+Cj5wzXwXiy4U3Z0aRdOf+b2rLOSAmWPxu08cinJBx4OLNuJrN7/gG7BpDCkNQL1nH090OSo9wn1tL+bxbkvb4Fd/vBXYtgI1vYS5xgHBQXq+aAe6z/5B+NW4jiLu/NJbceq+U1FrmPjp3a+izQzwcXY6iqC5pgH861suVsyBO47D90/bE+3FHF5a04NP3/AMzrjicTy4aAPzdWlQWtOKZG/3s91OJmV1feuYqF53uYBvWMyJPz/5Bo6/5GH87elVgb603YrVx29qG0to9gDwlMgy231qF9PB+Z87F+Ldlz8eSZvAy+j8qAXND4DcT8q44Cjvk7vKuOWzR+H0A3ZA3TDxg3++ggtue8m3lIrS3X2RdF230fSnrhXu98zx7QxN/9m/FuFdlz2GZ1eqKzEdTZYF6aPJpu5jIUFyNP03HzwA08e2YV3PML528wK858rH8bTC2umwZmcVA5yCo88n6qybXgUWiMHwew6cgQe/fhxOP4C0UvnbM6tx/MVzcf2jy2NnGam4Ry1MVvFACyF44c+ujTSf0/Htk/fA9Wcfgu4yQY2Pv2QuvnnLApeTEcYCW7ABQMcE4B0/JT/P/bkL4d99ahdu/uyRzCk//YrHQlOTqJmNKnK0rY4fkg4Ab/kKcSxXP03EYxzncvvnj8K+08dg60AVH7ruCVz/6HLMX7YFq7YOMpVoMwgp3Ot0YMZhRHho7s+EX+06uRO3fO5I7DyxA2u2D+H9V8/DK2ttxoXZqNoBZeA47wGm7ktqWh/7lfCrjx6xE/50zuEY31HES2t68K7LHhf0CIpRkPRCm00Fd9CBP3bkLFzzsUNQLuh4aPEmfPDaJ7B6mzzRkn+B1JevMiZBywcgKICVUNGIsvkmu/65mNfxmw8eiA8dNhOGCXzr1hdxzcPLPNvOaXy5iF/iQ9PsBNxT1zGUAoCN4gQxANrG2WUVj1zicthO3mcqbrWSQYcPPgwA2GJ2BTtmOx8DdE8nQbMDdc3ndFxwyp64znqun39jO06+9BFcNVfe8s+oV2xqpdf10HOENQQQpgbXsgggDtDtn38Ljp4zEUO1Bn50xyvBfW152/OdpF55o7sMau8dxuD2L7wFu03pxIbeCt571eP4/j9eirVGAUCbhY4YfkFIsQM49lvk54d/4erQAJCuFM5A3avlZoNvbeWXgDn6G0DXNJIcmH+58KuucgF3femt+NyxuyCva/jPwg048ZcP4+qHl3k6mhqlEQc5t3qO6DAAxPHm5ump+07DlR85iCnbn37FY7j8waXC/mULxwWsUbmCLXTpQGDPPnIWHv/OCfjmSbtjfEcRq7YO4Qf/eBlvveghXDV3GSqDJDlQCbPvdU4mazsAPPA/LOFRyOm44NQ98cChz2KGthmrzYm4on46dD0gkAOAOe8gfZgHNrpYcwfvNA63ff4t2GlCO1ZtHcKZV80TuqeUaJBe8NgXqR3zTXJ8+TaBVg/Y4o6BCby9TicaJQMbBaE7gAQNt553FE6w2Edf/Mvz+PV9domBEZbuDpDEWqmblPO8/rDr14fPnoBrPnYIijkdd7+0Dl/72wJs9ng+KN297kd3B0hAdNDHyc/PiEyBb7xjd5y45xScknsKAHB/bT8MohzIjgZgf+bS+4DtYpK3u1zAFR8+CD85Yx8U83pwK0WA+Dj5NuCNedKSmXOOno1Hv3U8PnvMbLQVcliwugef+sMzOO6SubjiodfQ20N8gFDIcb4E7EufKVsz4SOH74TffeIQzJ5IEnvfuvVFnH7F45j32mbvsrcwrVgBOyhddLeL1n/he/fDT8/YB2PaCli4rhdnXjUP3/r7AilTMKzlLFZrNUyCDrBV3hfeIfi9bcUcLj3rAKaCf9PTq3D65Y9j3jJ5zThD0oMSzft/iCS1Ni8R2qMCwP87Yx9cdOa+GNtewKL1fTjzqvn4zq0vJroeo9GyIH20mYCmLxJ+dfjsCXjg68fiWyfvjs5SHgtW9+D9V8/HOTc8rYwyHsZsqkvAZtU2znboHvqZy6HbYWwbfvPBA3HreUdh/5ljSR3q3a/ijCsfD2zzJbMcj6QH2R6nEepPzyrpRgoAJ+41BXd/+Wi8ZVciEnTLs6tx4q8exuf//CwWrNoeXggsqAUbtQM+TFQ460PAv77hClwOmDkWd3zxrdhvxhhsG6zho9c/iavmLsPG3mGPD3SYQPEM2OR80HSAtN26+bNH4MQ9J6NaN/DTu1/Fh657Amdf/BfsVCNiSvXyeP8xNM1OTDz/JxeVcca4dtzyuSOx17RubO6v4oPXPIHzb34Blz2wFM8u5epPgwJCXQdO+CH5+anrhBZdAHDE7An45xfegj2mdmFzfwXvv2Y+vnHLAqzvGUbBpEh6iEw1YCOfL93i2qTfvtcU/PXcI1hC4MRfPYzLH3SIfw1sQXHerwEAv66fiVwuxBI+bidSLwwQ1gonzJPTNfzsPfsyReoL71mEYy9+CFc/7G53QxG5OnL+tFmAiF21jQd63hCDYapyHnRPAIKO5sukrGLFo65f7zmtG3d9fDa+WyRq7VebZwZ/pp6z9TAW/FX6lrdbz/V+M8agd7iOi+5dhGN+8RD+77HXhTpRnW+n4/d99ngnEfGrDZCEg8PGtBXw+08cylRtQ9FmqbWNs2srn7jKlVCcPrYNt3zuKBw9ZyKGa6S15dt++TA+9YenfZ1OmZWp8JNXTTq1gz5ul6o4SkioOQP1o37+IL7/j5ewwsGIMfkEphdNFiAB/Nt/Qn5+9JdAj9jppL2Yx3dO2QN3f/loHDprHIZqDfz8nkU44ZKHceuzq12JKd0KTqt6iCTYgR8j83T9S8AbTwi/OnXfafj3V4/BO/aaglrDxCX/WYKjf/EQvnHLAtz67Gp7/QhabwGbBbL4HoHxA5A59IXjd8Xj3z4BP37XXpg+tg2b+yu46N5F+Pv8RdZ3CTEGQJ67zqlkfbrqSLsjxZZlmPoKEXl6Ys7XUdFKmDkuxGfmCjaC6BCQAwj76rbzjsIBM8di+2ANZ137BE769SO4+N+LYAyRtSowSJ+6L7D7aQBMcv95o4nBoIAhV7ATg09c5drTusoFXHf2IUy9/DcPLMXBP70P59zwDG56alU45hZA5ipNuDio9dSO3W0SLvvwgcjpGu5csBZvvehB/O+dC20VdnrKFvBQD6K7A4TRoOfJesrRycd3FHH92QfjsxPJa48V3mK9HmJPm7ALSXzCdJUzAHa5ye2fPwqTimSud40Z5/15Y2cCR3+d/Pyf77sENwEijnnBqXvi0W8fj88cMxtdpTze2DqIi/+9GP95gaiQh57rlAmw6G7hmTphjym496vH4Hun7omuUh4vrenBh69/Eu++/HHcsWCtCyhi7NGgZP3kPUmJkmkQxgZnOV3DR4/YCQ9+/ViGqv/tmdU4+qKH8JWbno/p85K1sxY2SJ99PFln+9YCfzydMEkttX1N0/DZY3fB7z9xKAucP3zdk/jcH591MTfLYWOAcre9rnFMP4AwWM46dEc8+PXj2PW46elVeOtFD+ELf34OTy7f8l+h/p4F6aPNpu5rtX4xgUd+4fo1qU/fFQ994zh86LAdoWvA/a9uxDsvewzn3viMgDamZaHo7tQOPYeoXvatA+ZfKX3LwTuNw+3nHYWfv3dfdJfzeHlNL06/4jH8750LPcXJZEYXrFALeKGNtEwBpI4FtZnj2/Hnc47AbZ8/CifuOQWmCfzrpfU4/YrHccpvHsX1jy73zIJTMxt1dNAsvJdwHECC1nf+miBnS/8jUJKoTR1Txt8+eyTetT+hJl107yIc9rMHcMYVj+OKh17DwrW9nvU9mlCzH2KDZmj6UwKFjlp7MY9rPnYIvn3yHjh6zkTMmVDEZcXL0a5VMN/YCxP3PCZ4jB0PJ1oMpgHc+21R0AmkzvWmzx6Bw2aNR1+ljtueX4Nf3rcEf3+CoCk15IMDSoDQSXc8EqgPAzd/xNXShyIp7z1oOkwT+Puzq3H8JXNRr1h1dmGQdIBsghN3I61Ofn8asFVUfz5wx3G4/fNH4YjZ4zFcM3DJf5bg5EsfxcNLNqHeMFB58EJo1T68YuyE2423BlMSqR31ZQAaqUu/8khg6f3sV7TO+4fv3Atj20l/+J/fswiHX/gAvnbzC7jukeW4c8FarFxPVJgrWkjWAK2DfNJSTO7fBKx6yvp9iAC0c7LNaHE63paNe+T7aDcHsaFrH+zznq8HfyZgOwVL73Mh29Rmjm/HbecdhV++f3/sOL4dm/ur+MldC/HWix7Cx3/3FC647SU88gphs1SDan01DXjbj8jPz/zOxYIBCIr/43fvjZ+dsbcteBjmGgG2o/ncDcSxciSZxrQVcOOnDsNfzz0CJ+45BZqlCP7h65/EB699Ai+u3h5qmDYWpAecV65gswce/40roKR26Kzx+NM5h2O/GWNQqZMEwvG/nIvP/fFZXHr/Evzm/qX4w7wVwZ0vqO37PvIM1wZJMkpiu0/tws2fORK/eN9+mNJNxFa/fssCnPqbR3H/wg0sWNcsBCoUTbR9vL1XOBxNAJjUVcI1HzsYv/rA/ugu57GuZxh/f3Y1vn7LAiayqgUxlwCy90/ZF2hUpSgjQBCvT7xlZ8z95nG45P37Y5dJHQxJDh24FDuA91wFdEwmgoR//yRw3QnA7Z8jY+/yNrzvI+fh8W+fgBs/fXi4zzzAorwvuVcQZqM2obOEv557BN5z4HTkdA2LN/ThioeWYaiPrMP1oMQQABxroekv3SIIKbLkf5jE4MGfJFo5616w1yrOcrqG7522F35x5n7oLOWxbbCG+1/dgD8+sYIrfQlxrpTyvuhu6fUAiEjmjZ86DPvNGIPhmoHfPf46jr7oIXzn1hdx67Or8fKaHtQrNAgLMU87J9ttAx30dGx8FYXty4BcET/6+tdww6cOwxUfPjD4MwF7nX/uj0LZIm977zAGu1uxea5tjP/nHfUl2yd81J3UpDaxs4Tvnronnvze23DJ+/fHITuNY2wGX5o1b1P3s5+pWz4u+BfFvI5zj5mNB79xHM4+cieUCzpeWtODL//1eRx78Vxc/uBSPPX6VgzXGijQtrJhfF7KMnvuBpc/A5Bn4Rfv2x+3nnckDt95POqGiX++sBbvuvwxfOAagiZ/+g9P492XP4YjL3wA773ycTy8ZJM0YGX0fz8aPm+FMmG4AsDrjwD/OA+4ZA5wyyfY83Dc7pPx0NfJNdE14N5X1uPEXz2M/3f3QlYeRoE6w68mndqhVpeMxfcI7fyoje8o4hfv2x+3fI5cj4Zh4u6X1uGsa5/AKb95FL++bwnuW7gB63qG3pRBu2a+Gb+Vj/X29mLMmDHo6elBd7dPQDSSbd2LwDVHA9CALzxJVGY9bNmmflz2wFLcsWAtKFiwx9QuzJ7UgdkTO7HzxA7sM30MdpvSCS2swx9gd//yHJzWdwuW7vIJzPnYb4L/4KW/A7d+moj/HP114C1f9aRbb+qr4Cd3LcQdC0hNmKYBu0/pwqGzxuOQWeOw9w7dmNhZQne54KLi3XHzdXj3q9/AG+17Y8dvzQs+r7XPA9ceRzbtzz3qe52pLV7fh6sfXoa7X1rHRF/yuoa3zpmIfaePwZwpXdhtSidmT+xEMU9yZPNeWY6jbrE2xO9vDA6QH/x/JEHTNQ34wlN2CyLOTNPEn598A7c8u9oldFPIadhlUid2m9KFHce3Y2PfMFZuGcTQxuW4o/F5VFBC6cchW5D8+3sWvVQDjvkGcNwF3q1g/vMDYN5vYZTHofcTD2Ps1J3CjbFlGXDlEWQjnbg78N5riQAPZ9W6gQcXbcSyTf14ffMAKusX47It56Ka70Lx+6vln+u0ja8Cvz8VGNpKWpd97HbigDvs+Te24ad3v4pnV27D7wsX4fjcAiw54iLsdvLnwo3Tuxb4wztJ26DuGcDH77DbElpmmibuWLAW/+/uV7HRElSapa3DfcVvoaA18OHqdzHP2AevX3hq+Od2xePAP79AaJYAcZxP+n92r2EAw7UG7liwFjfOX4GX14g1tHtpK/Cv0nexTR+PcT/0by0FgKCZl+4HmA1St8szB+acBHzkb95/S237G8BvDwSMOvChm2xGAEBaJN78EYIOfeZhq/dqSLvubQRR2vlYcu31PPk341DSjom7prWGgVufXY3fPrAUa3tsJGsXbQ0eKH0T/XoXOn8YYo7deDqh9O3/YRIEyazSD1xIxOTw3bXhAgvTJA7fvReQALU8FnjXpXZbKYe9vnkAv3/8ddz09Cq2Rr17/x3wzZN2x8zx3s7tI//7dhxjPIU3jvp/2PEdX/Q/J8MArjkG2PASScSecrFnbbdpmnhi+VZc88gyzF3sbse1pPQxIpT4tVdIf3g/W/cicK2FVB35RZL01HPk3s56KzDjEPbWoWoDf5i3AlfNfQ29wyS4GNNWwNFzJmK3wefw5dVfx5rCLEz/3gKv0cRxrzmajPPRW4FZR0vXwcFqHc+s2IZ5y7Zg/rLN+OnGL2Jf/XUMvf8mtO19iuSDHTb/SlJ3P3Yn4AM3EBEyHzMMEy/++3c44Mnz0Tv1SHR/7l7f9wtW6Sf6J/N+azNgckXg80+41qtQdv2JpDxqv7OAky4kJVwS2z5YxUOLN+L+VzbgA0u/jmO157H68B9hxinnB4/xp/cBr91H1pep+1rshvmklOm0X9lIuZ/98wskMb/3e4D3/8HzbbWGgZfX9OCZFdvwwvK1uGKFVcp0werghBIAXP92kuDe/VTg1Is957Zpmnh06WZc9uBSPL1CTB6/W38cvy1egaUdB2PONx+U/r1gy+eSdajUDXztZVtR/aELgYd/Dux2CvDhm3w/wmX1CvCrPUni+b3X2SwBp/1yDxJ4f+Zh1/7tskV3Azd9mAASX3gy9Hxb+8St2OHeT6E27WAUPhviegDA6mfINan2A7ucAHzwr1L/c+tAFX+cvxI3zl+BLRzLrJDT8OPc7/ER/T9Ysvt52O1DP/cfz2gAvz2A7G3vvszWjPGwl9f04P8eex13LliLuk9t/FG7TMAFp+yJfWfYSZB///nXOGnpj7Gk6zDs9vX7PP/WZVuXE7/8xb+RbijUdjkBOPY7BDwB8Xd/ctdCPPYaob3ndA0n7zMV71z+E5xSfxCL9/k6dn+fPGEq2I1nAMsfImDCO37i+9ZF63tx4/yVuP25NRhydECY0FHEXjt04+L37Y+pY0ICJy2wKHFoFqSPVrvpI6RVQsACT+21jf347QNLceeLa50sLgCEcnbKPlNxyj7TsM/07kQB+38u/ijeMXAnFu9+HnYPWrAA4tDdcjZRZwUIVfLUiwm66WFzF2/Ehf9ahMUb5H0l87qG8R1FTBtTxv4zx+KgHcdh+Lmb8MFV/4vlnQdj9jdCLOCmSRzN9S+SVkf7nElq30IE6z2DNdzx4lr8XRIkA4CuEfpcd1sek43NuHX4XFRRQPHHIfpC1oYJDXHrcqKOedKFwG7v8Hz7ht5h3P/qBty3cAOefn0rBjyEmnbVVuP+0rcwlO9G2/dDtvKrV4B7v2P3GZ91NHDm/xE6PG/LHgL+eAb5+aw/k1raKLbsIYLk9K8nG/cJ3yMLuldCYN0Ccu+6pgFfXyR/j8zWvwzc+G7icEzdDzj7n9JA3TRN3PPyeky9/X04yHgZW06+ChOO+HD4cfrWAze8i9RidU0DPn4XMHFX99uGawxRvCz3K5ySexoPGQfgy9p3ccq+U/GL9+0ffkyAUD8f/IlFQzYJWva2HwAHfES4lqZp4vlV2/HvV9Zj3fZhrO8dxsStL+DKynfQ2zYT3d9+Odx4t3yCq+/UiIjajENIADU5oH0TNeo0AwRZf8dPyfN4xeGElvfWr9kig2Htmd8Dd31V/rtd3w68+7d2ay/LKvUGnlmxDWu2DWHN9iHo657DV5Z/FpWOHVD65qvyz+JtzbMEkdR0EjDs817bSaa29gUSZALAD7cFt83hbfNrwG3nkOQiQESYjv02MGUv+elsH8Iv/70Yt1mtyYo5HcfuPgmH7zweR8yegD2ndSOna+gbrmHllkEMXn8qDjNfxsrjfoOdjvtE8PksvQ/48/vIz1P2JfNszjt8RTsXr+/Dbc+tRn+lDhOA3qjipy+fQH757ZVCQsnT7vqavR4JppH1+7jvCHO9Z7CGKx9+DX998g0WrB+vP4/fFy/GitLumHWBG1GV2u9OIbW0ABF52+1kYI9TLQqpPPnRuPww5DYvBj5+p0UbDrCBLWTt799A5tHhnwOO/653UFgdIKVk8y8n5/Phm8N9F976N5L2Zi/8lVy7owISNF5Gk/EAoZ4f/hngyC/Jg/VGDbj767b44Nl32GKufrbqKeD/JH5DoQP41D3AtBDr5fqXgasJ5Rtz3kGQ3VlH+4vNDmwGLrYCyR9u9d6XeFt8D/BXqwwgXyYI61vP953jTyzfgnteWofFG/qweH0f3l75D35RuA6vjz8aO3/5ruAxDQO4/GDiO7SNJ90nDjsX+P0pRKTzjKuBAz4U/DlOsxLwAAjz7W0/svezRg147QHgb2cDjQrwpeeCg27TBP50JhFJnDCHlEXu/Z5gVtyLt5A1cOdjSfI7rK2cR8arDZJ7ftafPMGS4VoD/3h+DR5esgnPrNyGTX0V/CJ/DT6QfxivH/AN7HzGD4LHe/y3pIPChDnAmdcHJy0ArO8Zxm3Pr0atbmJydwmTOksY31nEPS+tww3zVqJqMSRP3nsqjtp1AvbeoRubHrwSJ6+8GK+MORZ7fy3C9aBmmoRV8vT15Pk3Ld9x9vGELTXjEJimibmLN+GaR5bhieWENXVF4VKclnsKCw/4IfY6IwTDjT4L+TZSbnPkF6R+F2/Ux37hje14ZW0Plm7sR8MwkdM1vPI/J6FcCPEMtsiyIN3H3jRBOkPTLeueDsw8DJh5BOndOml36aayrmcIi9b1McRx2aZ+PPfGdqHVx+SuEmaMa8OkrhImd5UxuauE2ZM6sfvUTuw0oQOFgDrYuRe9D8cN3YeFe5+Pvd7/o3DfxzQJZfrf3yPZVoA4yzsdSVpkTdiFtKFzIEsb+4bx7IpteHrFNjy9YitWbhlgjpbTPph7ED8vXI/FY96K3b92d7jz2vo68O/vAov/Zb2gkc1iztuByXuR6xwg+rNkQx8eW7oZSzf2YcmGfixZ34c+Tr17jrYa95W+hV59LLp/6KbCSm3V0yTTPGAh3nPeQYJ1SaDHm2GYWNszhCUb+rB4fT9WbRvElK4ydprQjj3MZdjjjncR8Zyvhwg6eHvxFuDOr5C6284phBGxw0EE3awOAFe9hQTYh3yKUPbj2OBW4M4v28mcmYcTJ3W3k91O8BtPAL87icyZLz8fbZwNC0kAPbiZBBcfuIF8jvN5Mk2Y170N2tpngQ/+xRaFC2v9G4Eb3k2EE9vG2/Nq52Nc83zotcfQ9qfTYGo68LnHoXkEXqHtjSdI8LvlNfL/qfuS+bPz0d5/s+xB4I/vAabsA5z3eLhxBrcSau742SQ4dwalYaw6QJxA2ou6cwo539fuJwm9z88PFgd0WqNOaigHNhPHw6iTFmnP3UgcydIY4OQLCTXeyzl//VHghncSdscXQwZyf/u43fs9XybMgD3fTZI1r94JbLCSH23jgG+viPadAOIQz/05EUA0rTV9j3cSCuP0g6V/8vKaHvzsX69i3jJRaLKrlEcxrzPU6B/F7+MAfTlWn/x7zDjivcHnYprAE1eS86lYrIyZRxBa8k5vCXfPBrYAFxO9BPxgS7AwIEB67j52KREHNBrk/vZtsLsEzDqaOMZdU4U/qzcMvLBqO+Yu3oT6S7fhO/0/x4axB2HKVx8KHhMgZQYP/C+hdA9vt1/PtxEEao/TyFpFg9J6FbjsYKLb8On7gZmHhhunfyPZk166hfy/ezphMXVMJghgoZ3M61duJ+dC+6Qf9HGSfGqlLfk38ND/I0lUgFDDD/woKReYfjB51ga3Eurx648A0Ajb54jP+wfJvP37ewQ9n7wXCcqn7kvWrCDhOOdnzL8CgOUeT9ufnMOORxAWg/Nctq0EfrMfudffXx9+nNXPktKMlVZLrvJYkjCdeSgw/RACvnh8b9M00f/oVeh68AIYe54B/Sx3NwWprZwP/ONzNrW42ElQZD0PfPM1svZEteoAcM+3SA2zaQBaDjj44wA0Mg+HrJKXfBn45rJw92Lza8D1b7Ofpe7pZL8/6GPe50iTr7ufBnzoL/L3eNnrjwJ/fj/R/Nn9VOCMqwKTgqZpYtXWIei3fQoz1twD46QLoR/5+eCxhrYBl+5P1PYBcq8P/TTxAaLuZQBWbxvEr/6zBLe/sEYA4c7J3Y3vF/6MBeNPwv5fDsFc87Otr5OyswV/JfslAOz9XuDEH5HOAQAWru3F7x9/He966Us4Rl+AN475FXY8IQR7xWgQ34LqPxU7CQPryC8CnZNCnd5wrYHF6/vwxtZBvGv/EF0nWmijLki/4oorcPHFF2P9+vXYf//9cdlll+Gwww7zfP8tt9yCH/zgB1ixYgXmzJmDiy66CKeeemqosd40QTpAaoCevp5QumiGi1r3dNJ3cvbxxEHunEIUViVq0P2VOh5atBH3vLwODy7aiOGat3o6pUpP6iqhq5xHRzGPznIe5UIOOU1DTtew3/yv4m3G43hl/+9h7/d8K9p3qvQRp+6Jq9zfCRrZcGcfR7LqOx4lRSgq9Qa2DlSxpb+KFVsG8NzK7XjujW04dP1f8b3cH7Fi2imY9dmIlK51C4ha8SJHtlrTyfWdvBcwZW8iDDJ5b7JoeTiUpmliU38FvUM19AzWUHj9fuz38LlojJmF3NdCUCupDfcShOOJq0jfVb1Agiw+qdE1laAIxXbivBU7vR3dlfOB358cL7AFiKru384mQSc1LUc2usEtJJj5zNxwqtVeZppE3fieb3MiZJ2k68Ge7yLXYLiHoJZPXkWC7PMe8/9MmW1cRAJ1mgQpdhIUmKK/m5aQwIo6EB+9Ddj1bdHHGdhMqF4buL6wuSJJQIyfTVD2rinAszeQjLZKR7teBZ6+Dph7ke0s7HwMGbdtPNA+gSB0tSHSy3T9S0QHYcahwDn3+392GrZyHnDHl+zEAgB87B92f10VtmkxqcNb8yz5/6yjiTDb9IOIo84nGRbfC/z1LJKM+kzIQK46SOblgpuBzYvdv9dy5B4c8XlfdkygrXuR1HMuvAMs0Jh+MJnDY3e0/u1E1qv28TBNEy+t6cG8ZVvw5PIteGbFNjGR2D6IP+O7mGxshHH2ndBnh0B9qQ1uBR6/FHjyGqL5AJDndNr+ZJ7POBgYO4swFzonExRy6+skKbTk3yS4jhr8yOylv5NEYrWf7IWnXgJM24+IpPFrUm2IJGvu+Rawy9uAj7n1NnytUSNB4qJ/EdpuD1fmoemEalwdIGs2tc89Rva2KPba/cBd5wPbAxK742YRZ/rIL3pSzJtqpkmS3nMvFPthj92RBCmv3kVKgYqdhJW1+8mtOc8ty0iS6fk/k8CNWrGLsFMm7UECKtOwWvDdQtbMby33/kyZmSaZ5/f/CNjkYH3RhOTYHUnAPmZHMlc3vEJ8ktVPE1bFfh8E3nuN/PNl1qiT4PmxXxEEHYg31522YSFw/49dbTPRMZkwEQ/+OFlzwtrgViKw9tS19l4MkDKxSbsRn2LcTgA0ch9WPAYsvpuotp95XfTzX/YQQXTpOjVuFlmnpu1PfLwJc8h4TkT/rx8ic/pdv7Fr9INswyvAY78GXvmHvRYUOoCJcyz/zfLjOieT9ap9IplfPh1dXl3Xi7tfXIeFa7ahtPYJnF25GUfmFmLx9Pdh93P/z/PvItm2FcQXfuEvAEzirxz2GRJrrHgEWD4X5roXocEEPvBHuz1ikBkGuYYPX0TYqwAADRgzExi/M/FLxu9MnoOuHch+0TWN7Be1IXLPaoOEaTpxTvikXgtsVAXpN998M84++2xcffXVOPzww3HppZfilltuweLFizF58mTX++fNm4djjjkGF154Id75znfiL3/5Cy666CI899xz2Gef4JrEN1WQTq06AKx5Dlj1JFmkVs4jaJDM2saThb9zsn1sG0eQu0IbKloJq/uBbdUctlTz2DisY92ghiVbG3h1cx1bqnlUUIDpozl4feFinJh7HosO/Rn2OO0L8b7TxkUkINi6nGzYW5bZ2VhquSJxNDsmAR0TybE8hiyguiXmpOdIls6oo/H6o8i9PhfmgR+Ddvrl8nGDbN2LJEhc/zJpe+QQGGOm5UiA3L0DSZh0TrEDZbqxr30eeONJQtkFSB30Z+VK8r62+TVSp7j0PyHerJHr1DWV/OuYbAftvevI5jp5b+DzIWr2ZVYdIEmDN54gQeWAVWOaKwLnPhjdEfWy7W8Q8RuJSrpgs44GPhGCBiizTUuAO75Ini3eoRZMI1S1s/8ZDyUGSMnAsodILeXS+7yd7kIH8OXnXAhgYhvYQhzmZ34nSYxJLA5Kocpqw0SPYd7lwCGfBE65SP0YjTow/zJCE244hCnH7kgQJ6NOanaHtsabY6ZJHJEX/0bu+fjZxJnZ7eRAml8k27SEOIIv3ux9bzunEMd50p5kHS12wii0Yc2AhvKWVzF+/aPI8Umk8+Z7Uuh9rXednTjgHW7e9Dx5jgZFVB+7vh346N/lfxPFNi8lJRiUsUCt1E3GHdpmJ/8AwkL4oNjyLJKZJhlr0d3kH3M+OZu8N1kbw4jHOa06SGjGKx8nz0Z9iBz1HEku7XMmqVsfiQ6raZK5/9LfSEKD75YwZibRoIiiM5GWDWwhYMird5LEmnNN4G3yXoTZE8cadeDVO0gni9XPkCAuzHqs6cDpV8ajqRsG2fMX30MoxiFK+ULZiseIH1DqIiyJnY8Nx4LxstowmSfzrxRBAC877LPAqW5h5VC27EHg7m8Qv1Nmep4wuDomkblg1Ih/Wu0H3nMtsP9Z0cbr3wQ8fyNhAfSEKDPUC8SfylnHcjfxMcfMIMfqAEnAUL8SgHHSz6EfeV608wqy9S8RBX5H6zRmOxwIfOTvZE+JYjRp9fBFwNrn4p3b9zbEW0+bZKMqSD/88MNx6KGH4vLLSdBkGAZmzpyJL33pS/jOd77jev9ZZ52FgYEB3HWX7RQdccQROOCAA3D11VcHjvemDNKdVhsigfqyB0lGv289ybYa9eC/DWl1vYx6royaXkJVK8M0TZQaAygagyhZyo6191yHwv4eIiJxrG8D2cCWPwQsfzjcgiazt3wVePv/JD8f0yTXdeNCkkHe+KrVr3iRmHkPMj1PgtdjvkVqGOPamueIQ7h1Odk0ti4nSG1tkCzcYTZ8gDAVznYrx0c20ySlC+teBMZMVxegO8dY9RQJ1lc8Suh05THkX9tYoqI7/aBkYzRq5FputO4xNDuLP2GXWPQ0TzNNghS/MZ8ENX3ryBwb2ExKBeI4YmFt81Ky4Q5uJcHn4BbC1ii2E2eLBjL7fYDR21pmjXoypy+MbVlGHPO1z5GEmlcy6IjPE2r8SLae1YQps32l9e8NMqf9ElxOm7ofqaN/y1eTBX2mSc5h1VMksbxuARFT7FtnU/T1PEHZdzmeIHzT9g9X5xvGakOElr74HvJsUTo4b3qBJMNOvpAwdFRZ7zrCFit22P/CdJ94s1t1kASLL99G5sA7f00AhJFmjRpZnze8QtZLo0aCZGjkuMdphJ2hwqqDJKmzaTF5fntWkWOllyTUpu1H9tSp+8ajqI9WG9xKrslmi83Wu4Zce3ofih3AW75MEp9Jx1n/Ilmf1i0gCc8tr/n7duc+6FlWFGhGg3yfLctsYGrb62TvH9hMyu/o+hjGSmOAvd5lJ0nSSNSZJmH0PPQzcn6zjib+487HqAET+jcSVtXW5eTfttfJXtG7hhydCbNcifhjX1kQTr+kRTZqgvRqtYr29nb8/e9/xxlnnMFe//jHP47t27fjn/90Bwo77rgjzj//fHz1q19lr/3oRz/CP/7xDyxY4KYKVyoVVCo2qtzb24uZM2e+uYN0mRkGoeb2b7D+bSTHvvWEHlwbsv4NcsdB8TVKAQpjbePIgpV0ofQy6uj1rCZobf8mgs5U+snG2agSR96oW8rNOfKv1A0ccZ5LFEqpGQa5tvxiMrBRvJaNGqHHzzycBJFhVJyTmGmSazLcQ+5533riFA9sEvvB6joRnIqj3ptZZm9mG9hiKd1q1pqik6TQpD1GJlIZxir9xOHduJBQbYd7SEKvOkDWqu4dSJC8y/HpB02NOlkn+zeS9SeMQnZSM00SNPdvIJoE7VaZR3nM6L2nmWWWWTpmGMSn27KUrJW5ko1qd08P1ARKPPbwdst/rBIfslEh7J+eNUDvanI06kTrZNcTw7XSHa1mmnZ7z0KZlERFEVptoUUJ0lOGIvxt8+bNaDQamDJFVIKeMmUKFi2SKzKvX79e+v716+X1ahdeeCH+538UoKaj3XTdckDGR6sJ4s0wLDqdI5ivWkhEqcv+R2nnaZmmETSv1YiezHQd6J5G/iFmVlW1aRpZsDsnk3+qsv2ZZfbfYh0TRkZNr0ordZKa8BkjYJ3K5a3yoCaK/mgaoYtK2lhmlllmmQmm68DYmeRfK8ZWWQo12k3T3nz7scRaGqQ3wy644AKcf77dX5Mi6ZnFMF23KXqZZZZZZplllllmmWWWWWaZKbeWBukTJ05ELpfDhg0bhNc3bNiAqVPl9QxTp06N9P5SqYRS6U1M+cgss8wyyyyzzDLLLLPMMsvsTWMtJfAXi0UcfPDBeOCBB9hrhmHggQcewJFHHin9myOPPFJ4PwDcd999nu/PLLPMMssss8wyyyyzzDLLLLPRYi2nu59//vn4+Mc/jkMOOQSHHXYYLr30UgwMDOCTn/wkAODss8/G9OnTceGFRD33K1/5Co499lj88pe/xGmnnYabbroJzzzzDK699tpWfo3MMssss8wyyyyzzDLLLLPMMktsLQ/SzzrrLGzatAk//OEPsX79ehxwwAG49957mTjcG2+8AZ1T7DvqqKPwl7/8Bd///vfx3e9+F3PmzME//vGPUD3SM8sss8wyyyyzzDLLLLPMMstsJFvL+6Q32/4r+qRnlllmmWWWWWaZZZZZZpllNmIsShw6OprKZZZZZplllllmmWWWWWaZZZbZf4FlQXpmmWWWWWaZZZZZZplllllmmY0Qy4L0zDLLLLPMMssss8wyyyyzzDIbIZYF6ZlllllmmWWWWWaZZZZZZpllNkIsC9IzyyyzzDLLLLPMMssss8wyy2yEWBakZ5ZZZplllllmmWWWWWaZZZbZCLEsSM8ss8wyyyyzzDLLLLPMMssssxFiWZCeWWaZZZZZZplllllmmWWWWWYjxLIgPbPMMssss8wyyyyzzDLLLLPMRohlQXpmmWWWWWaZZZZZZplllllmmf3/9u48Jqrz6wP496IwDAgiDKuKK8UNiCulVn+tEJYaV1qXkorWSlW0ti4hmrq2qUYbbdpYusQt0WhL41brElDRqogL4i4Rg0sLaNWiiCLbef9ouG+nIGArc+8w308yyfDcZ4ZzOZ6Z58yde9UJNulEREREREREOsEmnYiIiIiIiEgn2KQTERERERER6QSbdCIiIiIiIiKdYJNOREREREREpBNs0omIiIiIiIh0ornWAViaiAAAHj58qHEkREREREREZAuq+8/qfrQuNtekFxcXAwDatm2rcSRERERERERkS4qLi9GyZcs65yjSkFa+CamqqkJ+fj5cXFygKIrW4agePnyItm3b4tatW3B1ddU6HKoDc2UdmCfrwDxZB+bJOjBP1oO5sg7Mk3WwljyJCIqLi+Hn5wc7u7rPOre5I+l2dnZo06aN1mE8k6urq67/cdH/Y66sA/NkHZgn68A8WQfmyXowV9aBebIO1pCn+o6gV+OF44iIiIiIiIh0gk06ERERERERkU6wSdcJg8GAhQsXwmAwaB0K1YO5sg7Mk3VgnqwD82QdmCfrwVxZB+bJOjTFPNncheOIiIiIiIiI9IpH0omIiIiIiIh0gk06ERERERERkU6wSSciIiIiIiLSCTbpRERERERERDrBJl0nVq9ejfbt28PR0RGhoaE4ceKE1iHZtKVLl6Jv375wcXGBl5cXhg8fjpycHLM5r732GhRFMbtNnjxZo4ht06JFi2rkoEuXLur20tJSJCYmwsPDAy1atEBsbCxu376tYcS2qX379jXypCgKEhMTAbCWtHT48GEMGTIEfn5+UBQF27dvN9suIliwYAF8fX1hNBoRERGBq1evms25f/8+4uLi4OrqCjc3N0ycOBGPHj2y4F40fXXlqby8HElJSQgKCoKzszP8/Pwwbtw45Ofnmz1HbXW4bNkyC+9J01ZfPY0fP75GDqKjo83msJ4aX315qu39SlEUrFixQp3Demp8DVmLN2Sdd/PmTQwePBhOTk7w8vLCnDlzUFFRYcld+VfYpOvADz/8gJkzZ2LhwoXIyspCSEgIoqKicOfOHa1Ds1mHDh1CYmIijh8/jtTUVJSXlyMyMhIlJSVm8yZNmoSCggL1tnz5co0itl3du3c3y8GRI0fUbR999BF+/vlnpKSk4NChQ8jPz8fIkSM1jNY2nTx50ixHqampAIC33npLncNa0kZJSQlCQkKwevXqWrcvX74cX375Jb755htkZmbC2dkZUVFRKC0tVefExcXh4sWLSE1Nxa5du3D48GEkJCRYahdsQl15evz4MbKysjB//nxkZWVh69atyMnJwdChQ2vMXbJkiVmdTZ8+3RLh24z66gkAoqOjzXKwefNms+2sp8ZXX57+np+CggKsXbsWiqIgNjbWbB7rqXE1ZC1e3zqvsrISgwcPRllZGY4dO4YNGzZg/fr1WLBggRa79HyENNevXz9JTExUf66srBQ/Pz9ZunSphlHR3925c0cAyKFDh9Sx//3vfzJjxgztgiJZuHChhISE1LqtqKhI7O3tJSUlRR27fPmyAJCMjAwLRUi1mTFjhnTq1EmqqqpEhLWkFwBk27Zt6s9VVVXi4+MjK1asUMeKiorEYDDI5s2bRUTk0qVLAkBOnjypztmzZ48oiiK///67xWK3Jf/MU21OnDghAOTGjRvqWLt27WTVqlWNGxypastTfHy8DBs27JmPYT1ZXkPqadiwYTJo0CCzMdaT5f1zLd6Qdd7u3bvFzs5OCgsL1TnJycni6uoqT58+tewOPCceSddYWVkZTp8+jYiICHXMzs4OERERyMjI0DAy+rsHDx4AANzd3c3GN23aBJPJhB49emDu3Ll4/PixFuHZtKtXr8LPzw8dO3ZEXFwcbt68CQA4ffo0ysvLzWqrS5cu8Pf3Z21pqKysDBs3bsS7774LRVHUcdaS/uTl5aGwsNCshlq2bInQ0FC1hjIyMuDm5oY+ffqocyIiImBnZ4fMzEyLx0x/efDgARRFgZubm9n4smXL4OHhgZ49e2LFihVW8ZXPpiY9PR1eXl4IDAzElClTcO/ePXUb60l/bt++jV9++QUTJ06ssY31ZFn/XIs3ZJ2XkZGBoKAgeHt7q3OioqLw8OFDXLx40YLRP7/mWgdg6+7evYvKykqzfzwA4O3tjStXrmgUFf1dVVUVPvzwQ/Tv3x89evRQx99++220a9cOfn5+OHfuHJKSkpCTk4OtW7dqGK1tCQ0Nxfr16xEYGIiCggIsXrwYAwYMwIULF1BYWAgHB4cai1Rvb28UFhZqEzBh+/btKCoqwvjx49Ux1pI+VddJbe9P1dsKCwvh5eVltr158+Zwd3dnnWmktLQUSUlJGDt2LFxdXdXxDz74AL169YK7uzuOHTuGuXPnoqCgACtXrtQwWtsSHR2NkSNHokOHDrh27RrmzZuHmJgYZGRkoFmzZqwnHdqwYQNcXFxqnCrHerKs2tbiDVnnFRYW1voeVr1Nz9ikE9UjMTERFy5cMDvXGYDZOWJBQUHw9fVFeHg4rl27hk6dOlk6TJsUExOj3g8ODkZoaCjatWuHH3/8EUajUcPI6FnWrFmDmJgY+Pn5qWOsJaIXo7y8HKNGjYKIIDk52WzbzJkz1fvBwcFwcHDA+++/j6VLl8JgMFg6VJs0ZswY9X5QUBCCg4PRqVMnpKenIzw8XMPI6FnWrl2LuLg4ODo6mo2znizrWWvxpoxfd9eYyWRCs2bNalyJ8Pbt2/Dx8dEoKqo2bdo07Nq1CwcPHkSbNm3qnBsaGgoAyM3NtURoVAs3Nze89NJLyM3NhY+PD8rKylBUVGQ2h7WlnRs3biAtLQ3vvfdenfNYS/pQXSd1vT/5+PjUuMhpRUUF7t+/zzqzsOoG/caNG0hNTTU7il6b0NBQVFRU4Pr165YJkGro2LEjTCaT+lrHetKXX3/9FTk5OfW+ZwGsp8b0rLV4Q9Z5Pj4+tb6HVW/TMzbpGnNwcEDv3r2xf/9+dayqqgr79+9HWFiYhpHZNhHBtGnTsG3bNhw4cAAdOnSo9zHZ2dkAAF9f30aOjp7l0aNHuHbtGnx9fdG7d2/Y29ub1VZOTg5u3rzJ2tLIunXr4OXlhcGDB9c5j7WkDx06dICPj49ZDT18+BCZmZlqDYWFhaGoqAinT59W5xw4cABVVVXqhy3U+Kob9KtXryItLQ0eHh71PiY7Oxt2dnY1vl5NlvPbb7/h3r176msd60lf1qxZg969eyMkJKTeuaynF6++tXhD1nlhYWE4f/682Ydf1R9iduvWzTI78m9pfOE6EpEtW7aIwWCQ9evXy6VLlyQhIUHc3NzMrkRIljVlyhRp2bKlpKenS0FBgXp7/PixiIjk5ubKkiVL5NSpU5KXlyc7duyQjh07ysCBAzWO3LbMmjVL0tPTJS8vT44ePSoRERFiMpnkzp07IiIyefJk8ff3lwMHDsipU6ckLCxMwsLCNI7aNlVWVoq/v78kJSWZjbOWtFVcXCxnzpyRM2fOCABZuXKlnDlzRr0q+LJly8TNzU127Ngh586dk2HDhkmHDh3kyZMn6nNER0dLz549JTMzU44cOSIBAQEyduxYrXapSaorT2VlZTJ06FBp06aNZGdnm71nVV+9+NixY7Jq1SrJzs6Wa9euycaNG8XT01PGjRun8Z41LXXlqbi4WGbPni0ZGRmSl5cnaWlp0qtXLwkICJDS0lL1OVhPja++1z0RkQcPHoiTk5MkJyfXeDzryTLqW4uL1L/Oq6iokB49ekhkZKRkZ2fL3r17xdPTU+bOnavFLj0XNuk68dVXX4m/v784ODhIv3795Pjx41qHZNMA1Hpbt26diIjcvHlTBg4cKO7u7mIwGKRz584yZ84cefDggbaB25jRo0eLr6+vODg4SOvWrWX06NGSm5urbn/y5IlMnTpVWrVqJU5OTjJixAgpKCjQMGLbtW/fPgEgOTk5ZuOsJW0dPHiw1te6+Ph4Efnrv2GbP3++eHt7i8FgkPDw8Bo5vHfvnowdO1ZatGghrq6uMmHCBCkuLtZgb5quuvKUl5f3zPesgwcPiojI6dOnJTQ0VFq2bCmOjo7StWtX+eyzz8yaQ/rv6srT48ePJTIyUjw9PcXe3l7atWsnkyZNqnFAhvXU+Op73RMR+fbbb8VoNEpRUVGNx7OeLKO+tbhIw9Z5169fl5iYGDEajWIymWTWrFlSXl5u4b15foqISCMdpCciIiIiIiKi58Bz0omIiIiIiIh0gk06ERERERERkU6wSSciIiIiIiLSCTbpRERERERERDrBJp2IiIiIiIhIJ9ikExEREREREekEm3QiIiIiIiIinWCTTkRERC+coijYvn271mEQERFZHTbpRERETcz48eOhKEqNW3R0tNahERERUT2aax0AERERvXjR0dFYt26d2ZjBYNAoGiIiImooHkknIiJqggwGA3x8fMxurVq1AvDXV9GTk5MRExMDo9GIjh074qeffjJ7/Pnz5zFo0CAYjUZ4eHggISEBjx49Mpuzdu1adO/eHQaDAb6+vpg2bZrZ9rt372LEiBFwcnJCQEAAdu7cqW77888/ERcXB09PTxiNRgQEBNT4UIGIiMgWsUknIiKyQfPnz0dsbCzOnj2LuLg4jBkzBpcvXwYAlJSUICoqCq1atcLJkyeRkpKCtLQ0syY8OTkZiYmJSEhIwPnz57Fz50507tzZ7HcsXrwYo0aNwrlz5/DGG28gLi4O9+/fV3//pUuXsGfPHly+fBnJyckwmUyW+wMQERHplCIionUQRERE9OKMHz8eGzduhKOjo9n4vHnzMG/ePCiKgsmTJyM5OVnd9vLLL6NXr174+uuv8f333yMpKQm3bt2Cs7MzAGD37t0YMmQI8vPz4e3tjdatW2PChAn49NNPa41BURR8/PHH+OSTTwD81fi3aNECe/bsQXR0NIYOHQqTyYS1a9c20l+BiIjIOvGcdCIioibo9ddfN2vCAcDd3V29HxYWZrYtLCwM2dnZAIDLly8jJCREbdABoH///qiqqkJOTg4URUF+fj7Cw8PrjCE4OFi97+zsDFdXV9y5cwcAMGXKFMTGxiIrKwuRkZEYPnw4XnnllX+1r0RERE0Jm3QiIqImyNnZucbXz18Uo9HYoHn29vZmPyuKgqqqKgBATEwMbty4gd27dyM1NRXh4eFITEzE559//sLjJSIisiY8J52IiMgGHT9+vMbPXbt2BQB07doVZ8+eRUlJibr96NGjsLOzQ2BgIFxcXNC+fXvs37//P8Xg6emJ+Ph4bNy4EV988QW+++67//R8RERETQGPpBMRETVBT58+RWFhodlY8+bN1YuzpaSkoE+fPnj11VexadMmnDhxAmvWrAEAxMXFYeHChYiPj8eiRYvwxx9/YPr06XjnnXfg7e0NAFi0aBEmT54MLy8vxMTEoLi4GEePHsX06dMbFN+CBQvQu3dvdO/eHU+fPsWuXbvUDwmIiIhsGZt0IiKiJmjv3r3w9fU1GwsMDMSVK1cA/HXl9S1btmDq1Knw9fXF5s2b0a1bNwCAk5MT9u3bhxkzZqBv375wcnJCbGwsVq5cqT5XfHw8SktLsWrVKsyePRsmkwlvvvlmg+NzcHDA3Llzcf36dRiNRgwYMABbtmx5AXtORERk3Xh1dyIiIhujKAq2bduG4cOHax0KERER/QPPSSciIiIiIiLSCTbpRERERERERDrBc9KJiIhsDM90IyIi0i8eSSciIiIiIiLSCTbpRERERERERDrBJp2IiIiIiIhIJ9ikExEREREREekEm3QiIiIiIiIinWCTTkRERERERKQTbNKJiIiIiIiIdIJNOhEREREREZFOsEknIiIiIiIi0on/AzRMJTTdM8shAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_losses = history_bert['seed0/fold9']['train_loss'][0]\n",
    "val_losses = history_bert['seed0/fold9']['val_loss'][0]\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# plt.title(f'Training and Validation Loss for Round {round_number}')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f'history_bert_01.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1757df13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"bert_res_01.txt\", 'w') as file:\n",
    "    for i,item in enumerate(test_report_bert):\n",
    "        file.write(f\"Experiment {i+1}:\\n {item}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46814214",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history_bert_01.txt\", 'w') as file:\n",
    "    for i,item in enumerate(history_bert.items()):\n",
    "        file.write(f\"Fold {i+1}:\\n {item}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
